# CLAUDE_ADDED: z_styleæ½œåœ¨ç©ºé–“å¯è¦–åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from models.beta_vae import BetaVAE
import sqlite3
import warnings
warnings.filterwarnings('ignore')

try:
    import umap
    UMAP_AVAILABLE = True
except ImportError:
    UMAP_AVAILABLE = False
    print("è­¦å‘Š: UMAPãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚PCAã®ã¿ä½¿ç”¨å¯èƒ½ã§ã™ã€‚")
    print("UMAPã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯: pip install umap-learn")

def load_and_preprocess_data(data_path: str, target_sequence_length: int = 100):
    """
    ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€è»Œé“ãƒ‡ãƒ¼ã‚¿ã‚’å›ºå®šé•·ã«å‰å‡¦ç†ã™ã‚‹ï¼ˆtrain.pyã¨åŒã˜å‰å‡¦ç†æ–¹å¼ï¼‰
    """
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­: {data_path}")
    df = pd.read_parquet(data_path)
    
    # è»Œé“ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    trajectory_data = []
    subject_labels = []
    trial_info = []
    
    for subject_id, subject_df in df.groupby('subject_id'):
        print(f"è¢«é¨“è€… {subject_id} ã‚’å‡¦ç†ä¸­...")
        trial_count = 0
        
        for trial_num, trial_df in subject_df.groupby('trial_num'):
            # train.pyã¨åŒã˜å‰å‡¦ç†ã‚’é©ç”¨
            # 1. è»Œé“ãƒ‡ãƒ¼ã‚¿ã‚’çµ¶å¯¾åº§æ¨™ã¨ã—ã¦å–å¾—
            trajectory_abs = trial_df[['HandlePosX', 'HandlePosY']].values
            
            if len(trajectory_abs) > 0:
                # 2. å·®åˆ†è¨ˆç®—ï¼ˆtrain.pyã¨åŒã˜ï¼‰
                trajectory_diff = np.diff(trajectory_abs, axis=0)
                trajectory_diff = np.insert(trajectory_diff, 0, [0, 0], axis=0)
                
                # 3. å›ºå®šé•·åŒ–ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°/åˆ‡ã‚Šæ¨ã¦ï¼‰
                if len(trajectory_diff) > target_sequence_length:
                    processed_trajectory = trajectory_diff[:target_sequence_length]
                else:
                    padding = np.zeros((target_sequence_length - len(trajectory_diff), 2))
                    processed_trajectory = np.vstack([trajectory_diff, padding])
                
                trajectory_data.append(processed_trajectory)
                subject_labels.append(subject_id)
                trial_info.append(f"{subject_id}_trial_{trial_num}")
                trial_count += 1
        
        print(f"  - {trial_count}è©¦è¡Œã‚’å‡¦ç†")
    
    print(f"ç·ãƒ‡ãƒ¼ã‚¿æ•°: {len(trajectory_data)}è©¦è¡Œ, è¢«é¨“è€…æ•°: {len(set(subject_labels))}äºº")
    return np.array(trajectory_data), subject_labels, trial_info

def load_model_config_from_db(db_path: str, experiment_id: int):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸå®Ÿé¨“IDã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    """
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT hidden_dim, style_latent_dim, skill_latent_dim, beta
            FROM experiments WHERE id = ?
        """, (experiment_id,))
        result = cursor.fetchone()
        
        if result is None:
            raise ValueError(f"å®Ÿé¨“ID {experiment_id} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        hidden_dim, style_latent_dim, skill_latent_dim, beta = result
        
        # å›ºå®šå€¤ã¨çµ„ã¿åˆã‚ã›ã¦model_configã‚’ä½œæˆ
        model_config = {
            'input_dim': 2,
            'seq_len': 100,
            'n_layers': 2,
            'hidden_dim': int(hidden_dim),
            'style_latent_dim': int(style_latent_dim),
            'skill_latent_dim': int(skill_latent_dim),
            'beta': float(beta)
        }
        
        print(f"å®Ÿé¨“ID {experiment_id} ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ:")
        for key, value in model_config.items():
            print(f"  {key}: {value}")
        
        return model_config

def load_model(model_path: str, model_config: dict):
    """
    å­¦ç¿’æ¸ˆã¿Î²-VAEãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    """
    print(f"ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {model_path}")
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")
    
    model = BetaVAE(**model_config).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    
    return model, device

def encode_to_z_style(model, X, device, batch_size: int = 32):
    """
    è»Œé“ãƒ‡ãƒ¼ã‚¿ã‚’z_styleæ½œåœ¨ç©ºé–“ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹
    """
    print("z_styleæ½œåœ¨ç©ºé–“ã¸ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ä¸­...")
    X_tensor = torch.FloatTensor(X)
    z_style_list = []
    
    with torch.no_grad():
        for i in range(0, len(X_tensor), batch_size):
            batch = X_tensor[i:i+batch_size].to(device)
            encoded = model.encode(batch)
            z_style_list.append(encoded['z_style'].cpu().numpy())
            
            if (i // batch_size + 1) % 10 == 0:
                print(f"  å‡¦ç†æ¸ˆã¿: {i + len(batch)}/{len(X_tensor)}è©¦è¡Œ")
    
    z_style_all = np.vstack(z_style_list)
    print(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å®Œäº†: {z_style_all.shape}")
    return z_style_all

def visualize_z_style_pca(z_style_all, subject_labels, save_path: str = None):
    """
    z_styleæ½œåœ¨ç©ºé–“ã‚’PCAã§2æ¬¡å…ƒã«å‰Šæ¸›ã—ã¦å¯è¦–åŒ–
    """
    print("PCAæ¬¡å…ƒå‰Šæ¸›ä¸­...")
    # PCAã§2æ¬¡å…ƒã«æ¬¡å…ƒå‰Šæ¸›
    pca = PCA(n_components=2)
    z_style_2d = pca.fit_transform(z_style_all)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    viz_df = pd.DataFrame({
        'PC1': z_style_2d[:, 0],
        'PC2': z_style_2d[:, 1],
        'subject_id': subject_labels
    })
    
    # è¢«é¨“è€…ã”ã¨ã®è‰²è¨­å®š
    unique_subjects = sorted(list(set(subject_labels)))
    colors = sns.color_palette("husl", len(unique_subjects))
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    plt.figure(figsize=(12, 8))
    
    for i, subject_id in enumerate(unique_subjects):
        subject_data = viz_df[viz_df['subject_id'] == subject_id]
        plt.scatter(subject_data['PC1'], subject_data['PC2'], 
                   c=[colors[i]], label=f'è¢«é¨“è€… {subject_id}', 
                   alpha=0.7, s=50)
    
    plt.xlabel(f'PC1 (å¯„ä¸ç‡: {pca.explained_variance_ratio_[0]:.2%})')
    plt.ylabel(f'PC2 (å¯„ä¸ç‡: {pca.explained_variance_ratio_[1]:.2%})')
    plt.title('ğŸ¨ z_styleæ½œåœ¨ç©ºé–“ã®è¢«é¨“è€…åˆ¥åˆ†å¸ƒ (PCA)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    # çµ±è¨ˆæƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¿½åŠ 
    stats_text = f"""çµ±è¨ˆæƒ…å ±:
ãƒ‡ãƒ¼ã‚¿æ•°: {len(z_style_all):,}è©¦è¡Œ
è¢«é¨“è€…æ•°: {len(unique_subjects)}äºº
æ½œåœ¨æ¬¡å…ƒ: {z_style_all.shape[1]}æ¬¡å…ƒ
PC1å¯„ä¸ç‡: {pca.explained_variance_ratio_[0]:.2%}
PC2å¯„ä¸ç‡: {pca.explained_variance_ratio_[1]:.2%}
ç´¯ç©å¯„ä¸ç‡: {pca.explained_variance_ratio_[:2].sum():.2%}"""
    
    plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, 
             fontsize=10, verticalalignment='top', 
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"å¯è¦–åŒ–çµæœã‚’ä¿å­˜: {save_path}")
    
    plt.show()
    
    # è¢«é¨“è€…åˆ¥çµ±è¨ˆ
    print("\n=== è¢«é¨“è€…åˆ¥z_styleæ½œåœ¨ç©ºé–“çµ±è¨ˆ ===")
    subject_stats = viz_df.groupby('subject_id').agg({
        'PC1': ['mean', 'std', 'count'],
        'PC2': ['mean', 'std', 'count']
    }).round(4)
    print(subject_stats)
    
    return viz_df, pca

def visualize_z_style_umap(z_style_all, subject_labels, save_path: str = None, 
                          n_neighbors: int = 15, min_dist: float = 0.1, random_state: int = 42):
    """
    z_styleæ½œåœ¨ç©ºé–“ã‚’UMAPã§2æ¬¡å…ƒã«å‰Šæ¸›ã—ã¦å¯è¦–åŒ–
    """
    if not UMAP_AVAILABLE:
        raise ImportError("UMAPãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install umap-learn ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    
    print("UMAPæ¬¡å…ƒå‰Šæ¸›ä¸­...")
    # UMAPã§2æ¬¡å…ƒã«æ¬¡å…ƒå‰Šæ¸›
    reducer = umap.UMAP(
        n_components=2, 
        n_neighbors=n_neighbors, 
        min_dist=min_dist, 
        random_state=random_state,
        verbose=True
    )
    z_style_2d = reducer.fit_transform(z_style_all)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    viz_df = pd.DataFrame({
        'UMAP1': z_style_2d[:, 0],
        'UMAP2': z_style_2d[:, 1],
        'subject_id': subject_labels
    })
    
    # è¢«é¨“è€…ã”ã¨ã®è‰²è¨­å®š
    unique_subjects = sorted(list(set(subject_labels)))
    colors = sns.color_palette("husl", len(unique_subjects))
    
    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    plt.figure(figsize=(12, 8))
    
    for i, subject_id in enumerate(unique_subjects):
        subject_data = viz_df[viz_df['subject_id'] == subject_id]
        plt.scatter(subject_data['UMAP1'], subject_data['UMAP2'], 
                   c=[colors[i]], label=f'è¢«é¨“è€… {subject_id}', 
                   alpha=0.7, s=50)
    
    plt.xlabel('UMAP Dimension 1')
    plt.ylabel('UMAP Dimension 2')
    plt.title('ğŸ¨ z_styleæ½œåœ¨ç©ºé–“ã®è¢«é¨“è€…åˆ¥åˆ†å¸ƒ (UMAP)')
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.grid(True, alpha=0.3)
    
    # çµ±è¨ˆæƒ…å ±ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¿½åŠ 
    stats_text = f"""çµ±è¨ˆæƒ…å ±:
ãƒ‡ãƒ¼ã‚¿æ•°: {len(z_style_all):,}è©¦è¡Œ
è¢«é¨“è€…æ•°: {len(unique_subjects)}äºº
æ½œåœ¨æ¬¡å…ƒ: {z_style_all.shape[1]}æ¬¡å…ƒ

UMAPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:
n_neighbors: {n_neighbors}
min_dist: {min_dist}
random_state: {random_state}"""
    
    plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, 
             fontsize=10, verticalalignment='top', 
             bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"å¯è¦–åŒ–çµæœã‚’ä¿å­˜: {save_path}")
    
    plt.show()
    
    # è¢«é¨“è€…åˆ¥çµ±è¨ˆ
    print("\n=== è¢«é¨“è€…åˆ¥z_styleæ½œåœ¨ç©ºé–“çµ±è¨ˆ (UMAP) ===")
    subject_stats = viz_df.groupby('subject_id').agg({
        'UMAP1': ['mean', 'std', 'count'],
        'UMAP2': ['mean', 'std', 'count']
    }).round(4)
    print(subject_stats)
    
    return viz_df, reducer

def visualize_z_style_comparison(z_style_all, subject_labels, save_path: str = None):
    """
    PCAã¨UMAPã®æ¯”è¼ƒå¯è¦–åŒ–
    """
    # è¢«é¨“è€…ã”ã¨ã®è‰²è¨­å®š
    unique_subjects = sorted(list(set(subject_labels)))
    colors = sns.color_palette("husl", len(unique_subjects))
    color_map = {subject: colors[i] for i, subject in enumerate(unique_subjects)}
    
    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig, axes = plt.subplots(1, 2, figsize=(20, 8))
    
    # PCA
    print("PCAæ¬¡å…ƒå‰Šæ¸›ä¸­...")
    pca = PCA(n_components=2)
    z_style_pca = pca.fit_transform(z_style_all)
    
    for i, subject_id in enumerate(unique_subjects):
        subject_mask = np.array(subject_labels) == subject_id
        axes[0].scatter(z_style_pca[subject_mask, 0], z_style_pca[subject_mask, 1], 
                       c=[colors[i]], label=f'è¢«é¨“è€… {subject_id}', alpha=0.7, s=50)
    
    axes[0].set_xlabel(f'PC1 (å¯„ä¸ç‡: {pca.explained_variance_ratio_[0]:.2%})')
    axes[0].set_ylabel(f'PC2 (å¯„ä¸ç‡: {pca.explained_variance_ratio_[1]:.2%})')
    axes[0].set_title('PCA')
    axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    axes[0].grid(True, alpha=0.3)
    
    # UMAP
    if UMAP_AVAILABLE:
        print("UMAPæ¬¡å…ƒå‰Šæ¸›ä¸­...")
        reducer = umap.UMAP(n_components=2, n_neighbors=15, min_dist=0.1, random_state=42)
        z_style_umap = reducer.fit_transform(z_style_all)
        
        for i, subject_id in enumerate(unique_subjects):
            subject_mask = np.array(subject_labels) == subject_id
            axes[1].scatter(z_style_umap[subject_mask, 0], z_style_umap[subject_mask, 1], 
                           c=[colors[i]], label=f'è¢«é¨“è€… {subject_id}', alpha=0.7, s=50)
        
        axes[1].set_xlabel('UMAP Dimension 1')
        axes[1].set_ylabel('UMAP Dimension 2')
        axes[1].set_title('UMAP')
        axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        axes[1].grid(True, alpha=0.3)
    else:
        axes[1].text(0.5, 0.5, 'UMAPãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\npip install umap-learn', 
                    ha='center', va='center', transform=axes[1].transAxes, fontsize=16)
        axes[1].set_title('UMAP (åˆ©ç”¨ä¸å¯)')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"æ¯”è¼ƒå¯è¦–åŒ–çµæœã‚’ä¿å­˜: {save_path}")
    
    plt.show()
    
    return pca, reducer if UMAP_AVAILABLE else None

def main():
    # è¨­å®š
    DATA_PATH = "PredictiveLatentSpaceNavigationModel/DataPreprocess/my_data.parquet"
    DB_PATH = "PredictiveLatentSpaceNavigationModel/experiments.db"
    EXPERIMENT_ID = 17  # ä½¿ç”¨ã—ãŸã„å®Ÿé¨“ID
    MODEL_PATH = f"PredictiveLatentSpaceNavigationModel/outputs/checkpoints/best_model_exp{EXPERIMENT_ID}.pth"
    
    # å¯è¦–åŒ–æ–¹æ³•ã®é¸æŠ
    # 'pca', 'umap', 'comparison' ã‹ã‚‰é¸æŠ
    VISUALIZATION_METHOD = 'comparison'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ¯”è¼ƒè¡¨ç¤º
    
    # UMAPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆUMAPã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼‰
    UMAP_PARAMS = {
        'n_neighbors': 15,    # è¿‘å‚ç‚¹æ•° (5-50)
        'min_dist': 0.1,      # æœ€å°è·é›¢ (0.0-1.0)
        'random_state': 42
    }
    
    try:
        print("ğŸ¨ z_styleæ½œåœ¨ç©ºé–“å¯è¦–åŒ–ã‚’é–‹å§‹")
        print(f"å¯è¦–åŒ–æ–¹æ³•: {VISUALIZATION_METHOD.upper()}")
        print("=" * 50)
        
        # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’èª­ã¿è¾¼ã¿
        model_config = load_model_config_from_db(DB_PATH, EXPERIMENT_ID)
        
        # 2. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
        trajectory_data, subject_labels, trial_info = load_and_preprocess_data(
            DATA_PATH, target_sequence_length=model_config['seq_len']
        )
        
        # 3. ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        model, device = load_model(MODEL_PATH, model_config)
        
        # 4. z_styleã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        z_style_all = encode_to_z_style(model, trajectory_data, device)
        
        # 5. å¯è¦–åŒ–å®Ÿè¡Œ
        if VISUALIZATION_METHOD == 'pca':
            save_path = f"PredictiveLatentSpaceNavigationModel/z_style_pca_exp{EXPERIMENT_ID}.png"
            viz_df, reducer = visualize_z_style_pca(z_style_all, subject_labels, save_path)
            
        elif VISUALIZATION_METHOD == 'umap':
            if not UMAP_AVAILABLE:
                print("âŒ UMAPãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚PCAã§å®Ÿè¡Œã—ã¾ã™ã€‚")
                save_path = f"PredictiveLatentSpaceNavigationModel/z_style_pca_exp{EXPERIMENT_ID}.png"
                viz_df, reducer = visualize_z_style_pca(z_style_all, subject_labels, save_path)
            else:
                save_path = f"PredictiveLatentSpaceNavigationModel/z_style_umap_exp{EXPERIMENT_ID}.png"
                viz_df, reducer = visualize_z_style_umap(
                    z_style_all, subject_labels, save_path, **UMAP_PARAMS
                )
                
        elif VISUALIZATION_METHOD == 'comparison':
            save_path = f"PredictiveLatentSpaceNavigationModel/z_style_comparison_exp{EXPERIMENT_ID}.png"
            pca, reducer = visualize_z_style_comparison(z_style_all, subject_labels, save_path)
            
        else:
            raise ValueError(f"æœªå¯¾å¿œã®å¯è¦–åŒ–æ–¹æ³•: {VISUALIZATION_METHOD}")
        
        print(f"\nâœ… z_styleæ½œåœ¨ç©ºé–“å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
        if VISUALIZATION_METHOD == 'comparison':
            print(f"æ¯”è¼ƒçµæœã¯ {save_path} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        else:
            print(f"çµæœã¯ {save_path} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        
        # ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜
        print("\n" + "=" * 50)
        print("ğŸ“– å¯è¦–åŒ–æ–¹æ³•ã®å¤‰æ›´:")
        print("VISUALIZATION_METHOD ã‚’ä»¥ä¸‹ã®å€¤ã«å¤‰æ›´ã—ã¦ãã ã•ã„:")
        print("  - 'pca': PCAã®ã¿")
        print("  - 'umap': UMAPã®ã¿ (è¦: pip install umap-learn)")
        print("  - 'comparison': PCAã¨UMAPã®æ¯”è¼ƒè¡¨ç¤º")
        print("\nUMAPãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´:")
        print(f"  - n_neighbors: {UMAP_PARAMS['n_neighbors']} (5-50, å¤§ãã„ã»ã©å¤§åŸŸæ§‹é€ é‡è¦–)")
        print(f"  - min_dist: {UMAP_PARAMS['min_dist']} (0.0-1.0, å°ã•ã„ã»ã©ã‚¯ãƒ©ã‚¹ã‚¿ãŒå¯†)")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()