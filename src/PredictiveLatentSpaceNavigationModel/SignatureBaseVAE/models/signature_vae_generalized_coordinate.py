"""
ğŸ¯ çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼VAEå…¨ä½“æ§‹é€ 

SimpleDecoderWithSignatureç‰ˆã§ã®å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«æ§‹é€ 
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np


# ==========================================
# 1. çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼è¨ˆç®—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# ==========================================
class SignatureCalculator(nn.Module):
    """è»Œé“ã‹ã‚‰çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã‚’è¨ˆç®—"""

    def forward(self, trajectories):
        """
        Args:
            trajectories: [batch_size, seq_len, 6]
                         (HandlePosDiffX, HandlePosDiffY, HandleVelDiffX, HandleVelDiffY, HandleAccDiffX, HandleAccDiffY)
        Returns:
            signatures: [batch_size, 5]
                       (path_curvature, velocity_smoothness, acceleration_jerk, movement_rhythm, force_modulation)
        """
        batch_size = trajectories.shape[0]
        signatures = torch.zeros(batch_size, 5, device=trajectories.device)

        for i in range(batch_size):
            traj = trajectories[i].cpu().numpy()

            signatures[i, 0] = self._calculate_path_curvature(traj)  # è»Œé“æ›²ç‡
            signatures[i, 1] = self._calculate_velocity_smoothness(traj)  # é€Ÿåº¦æ»‘ã‚‰ã‹ã•
            signatures[i, 2] = self._calculate_acceleration_jerk(traj)  # åŠ é€Ÿåº¦ã‚¸ãƒ£ãƒ¼ã‚¯
            signatures[i, 3] = self._calculate_movement_rhythm(traj)  # é‹å‹•ãƒªã‚ºãƒ 
            signatures[i, 4] = self._calculate_force_modulation(traj)  # åŠ›èª¿ç¯€

        return signatures

    def _calculate_path_curvature(self, traj):
        # å·®åˆ†ã‹ã‚‰ä½ç½®ã‚’å¾©å…ƒ
        positions = np.cumsum(traj[:, :2], axis=0)
        if len(positions) < 3:
            return 0.0

        curvatures = []
        for i in range(1, len(positions) - 1):
            p1, p2, p3 = positions[i - 1], positions[i], positions[i + 1]
            v1 = p2 - p1
            v2 = p3 - p2
            cross = np.cross(v1, v2)
            norms = np.linalg.norm(v1) * np.linalg.norm(v2)
            if norms > 1e-6:
                curvature = abs(cross) / norms
                curvatures.append(curvature)

        return np.mean(curvatures) if curvatures else 0.0

    def _calculate_velocity_smoothness(self, traj):
        vel = traj[:, 2:4]
        vel_changes = np.abs(np.diff(vel, axis=0))
        return 1.0 / (1.0 + np.mean(vel_changes))

    def _calculate_acceleration_jerk(self, traj):
        acc = traj[:, 4:6]
        jerk = np.abs(np.diff(acc, axis=0))
        return np.mean(jerk)

    def _calculate_movement_rhythm(self, traj):
        vel = traj[:, 2:4]
        speed = np.linalg.norm(vel, axis=1)
        return np.std(speed) / (np.mean(speed) + 1e-6)

    def _calculate_force_modulation(self, traj):
        acc = traj[:, 4:6]
        force = np.linalg.norm(acc, axis=1)
        return np.std(force) / (np.mean(force) + 1e-6)


# ==========================================
# 2. çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å­¦ç¿’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
# ==========================================
class SignatureGuidedEncoder(nn.Module):
    """çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å­¦ç¿’æ©Ÿèƒ½ä»˜ãã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼"""

    def __init__(self, input_dim, hidden_dim, style_latent_dim, skill_latent_dim, n_layers=2):
        super().__init__()

        # åŸºæœ¬LSTMï¼ˆå¾“æ¥é€šã‚Šï¼‰
        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=0.1)

        # ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»ã‚¹ã‚­ãƒ«æ½œåœ¨å¤‰æ•°ç”¨ãƒ˜ãƒƒãƒ‰ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        self.fc_mu_style = nn.Linear(hidden_dim, style_latent_dim)
        self.fc_logvar_style = nn.Linear(hidden_dim, style_latent_dim)
        self.fc_mu_skill = nn.Linear(hidden_dim, skill_latent_dim)
        self.fc_logvar_skill = nn.Linear(hidden_dim, skill_latent_dim)

        # ğŸ“ æ–°æ©Ÿèƒ½: çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼äºˆæ¸¬ãƒ˜ãƒƒãƒ‰
        self.signature_predictor = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, 5)  # 5ã¤ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ç‰¹å¾´
        )

    def forward(self, x):
        """
        Args:
            x: [batch_size, seq_len, input_dim] è»Œé“ãƒ‡ãƒ¼ã‚¿
        Returns:
            dict: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å‡ºåŠ›ï¼ˆæ½œåœ¨å¤‰æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ + äºˆæ¸¬ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ï¼‰
        """
        # LSTMå‡¦ç†
        _, (hidden, _) = self.lstm(x)
        last_hidden = hidden[-1]  # [batch_size, hidden_dim]

        # æ½œåœ¨å¤‰æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        mu_style = self.fc_mu_style(last_hidden)
        logvar_style = self.fc_logvar_style(last_hidden)
        mu_skill = self.fc_mu_skill(last_hidden)
        logvar_skill = self.fc_logvar_skill(last_hidden)

        # ğŸ“ æ–°æ©Ÿèƒ½: çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã®äºˆæ¸¬
        predicted_signatures = self.signature_predictor(last_hidden)

        return {
            'mu_style': mu_style,
            'logvar_style': logvar_style,
            'mu_skill': mu_skill,
            'logvar_skill': logvar_skill,
            'predicted_signatures': predicted_signatures  # â† è¿½åŠ å‡ºåŠ›
        }


# ==========================================
# 3. ã‚·ã‚°ãƒãƒãƒ£ãƒ¼å¯¾å¿œãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼
# ==========================================
class SimpleDecoderWithSignature(nn.Module):
    """è»Œé“ + çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã®ä¸¡æ–¹ã‚’å‡ºåŠ›ã™ã‚‹ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼"""

    def __init__(self, output_dim, hidden_dim, style_latent_dim, skill_latent_dim, seq_len, n_layers=2):
        super().__init__()
        self.seq_len = seq_len
        self.output_dim = output_dim

        latent_dim = style_latent_dim + skill_latent_dim

        # ğŸ“ è»Œé“å†æ§‹æˆéƒ¨åˆ†ï¼ˆSimpleDecoderã¨åŒã˜ï¼‰
        self.trajectory_decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim * 2, seq_len * output_dim)
        )

        # ğŸ“ æ–°æ©Ÿèƒ½: çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å†æ§‹æˆéƒ¨åˆ†
        self.signature_decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, 5)  # 5ã¤ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ç‰¹å¾´
        )

    def forward(self, z_style, z_skill):
        """
        Args:
            z_style: [batch_size, style_latent_dim] ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨å¤‰æ•°
            z_skill: [batch_size, skill_latent_dim] ã‚¹ã‚­ãƒ«æ½œåœ¨å¤‰æ•°
        Returns:
            dict: ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å‡ºåŠ›ï¼ˆè»Œé“ + ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ï¼‰
        """
        batch_size = z_style.size(0)
        z = torch.cat([z_style, z_skill], dim=1)  # æ½œåœ¨å¤‰æ•°çµåˆ

        # ğŸ“ è»Œé“å†æ§‹æˆ
        trajectory_output = self.trajectory_decoder(z)
        reconstructed_trajectory = trajectory_output.view(batch_size, self.seq_len, self.output_dim)

        # ğŸ“ çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å†æ§‹æˆ
        reconstructed_signatures = self.signature_decoder(z)

        return {
            'trajectory': reconstructed_trajectory,  # [batch_size, seq_len, output_dim]
            'signatures': reconstructed_signatures  # [batch_size, 5]
        }


# ==========================================
# 4. çµ±åˆVAEãƒ¢ãƒ‡ãƒ«
# ==========================================
class SignatureGuidedVAE(nn.Module):
    """çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å­¦ç¿’æ©Ÿèƒ½ä»˜ãVAEï¼ˆå®Œå…¨ç‰ˆï¼‰"""

    def __init__(self,
                 input_dim,
                 hidden_dim,
                 style_latent_dim,
                 skill_latent_dim,
                 seq_len,
                 n_layers=2,
                 beta=0.001,
                 contrastive_weight=0.1,
                 signature_weight=0.5,
                 use_triplet=False,
                 ):
        super().__init__()

        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.beta = beta
        self.contrastive_weight = contrastive_weight
        self.signature_weight = signature_weight

        # ğŸ“ ãƒ¢ãƒ‡ãƒ«æ§‹æˆè¦ç´ 
        self.encoder = SignatureGuidedEncoder(input_dim, hidden_dim, style_latent_dim, skill_latent_dim, n_layers)
        self.decoder = SimpleDecoderWithSignature(input_dim, hidden_dim, style_latent_dim, skill_latent_dim, seq_len,
                                                  n_layers)
        self.signature_calculator = SignatureCalculator()

        # å¯¾ç…§å­¦ç¿’ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        self.contrastive_loss = ContrastiveLoss(temperature=0.07)

    def reparameterize(self, mu, logvar):
        """å†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãƒˆãƒªãƒƒã‚¯"""
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x, subject_ids=None):
        """
        Args:
            x: [batch_size, seq_len, input_dim] å…¥åŠ›è»Œé“
            subject_ids: list è¢«é¨“è€…IDï¼ˆå¯¾ç…§å­¦ç¿’ç”¨ï¼‰
        Returns:
            dict: å…¨ã¦ã®æå¤±ã¨å‡ºåŠ›
        """
        # ğŸ“ 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        encoder_output = self.encoder(x)

        # ğŸ“ 2. æ½œåœ¨å¤‰æ•°ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        z_style = self.reparameterize(encoder_output['mu_style'], encoder_output['logvar_style'])
        z_skill = self.reparameterize(encoder_output['mu_skill'], encoder_output['logvar_skill'])

        # ğŸ“ 3. ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆè»Œé“ + ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ï¼‰
        decoder_output = self.decoder(z_style, z_skill)
        reconstructed_trajectory = decoder_output['trajectory']
        reconstructed_signatures = decoder_output['signatures']

        # ğŸ“ 4. çœŸã®çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã‚’è¨ˆç®—
        true_signatures = self.signature_calculator(x)

        # ğŸ“ 5. æå¤±è¨ˆç®—
        # 5-1. è»Œé“å†æ§‹æˆæå¤±ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        trajectory_recon_loss = F.mse_loss(reconstructed_trajectory, x)

        # 5-2. KLæå¤±ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        kl_style = -0.5 * torch.mean(torch.sum(
            1 + encoder_output['logvar_style'] - encoder_output['mu_style'].pow(2) - encoder_output[
                'logvar_style'].exp(), dim=1))
        kl_skill = -0.5 * torch.mean(torch.sum(
            1 + encoder_output['logvar_skill'] - encoder_output['mu_skill'].pow(2) - encoder_output[
                'logvar_skill'].exp(), dim=1))
        kl_style = torch.clamp(kl_style, min=0.0)
        kl_skill = torch.clamp(kl_skill, min=0.0)

        # ğŸ“ 5-3. çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼é–¢é€£æå¤±ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ¼äºˆæ¸¬æå¤±
        encoder_signature_loss = F.mse_loss(encoder_output['predicted_signatures'], true_signatures)
        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ¼å†æ§‹æˆæå¤±
        decoder_signature_loss = F.mse_loss(reconstructed_signatures, true_signatures)

        # 5-4. å¯¾ç…§å­¦ç¿’æå¤±ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        contrastive_loss_val = torch.tensor(0.0, device=x.device)
        if subject_ids is not None and len(set(subject_ids)) > 1:
            contrastive_loss_val = self.contrastive_loss(z_style, subject_ids)

        # ğŸ“ 6. ç·åˆæå¤±
        total_loss = (
                trajectory_recon_loss +  # è»Œé“å†æ§‹æˆ
                self.beta * (kl_style + kl_skill) +  # KLæ­£å‰‡åŒ–
                self.signature_weight * encoder_signature_loss +  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚·ã‚°ãƒãƒãƒ£ãƒ¼å­¦ç¿’
                self.signature_weight * decoder_signature_loss +  # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚·ã‚°ãƒãƒãƒ£ãƒ¼å†æ§‹æˆ
                self.contrastive_weight * contrastive_loss_val  # å¯¾ç…§å­¦ç¿’
        )

        return {
            'total_loss': total_loss,
            'trajectory_recon_loss': trajectory_recon_loss,
            'encoder_signature_loss': encoder_signature_loss,
            'decoder_signature_loss': decoder_signature_loss,
            'contrastive_loss': contrastive_loss_val,
            'kl_style': kl_style,
            'kl_skill': kl_skill,
            'reconstructed_trajectory': reconstructed_trajectory,
            'reconstructed_signatures': reconstructed_signatures,
            'predicted_signatures': encoder_output['predicted_signatures'],
            'true_signatures': true_signatures,
            'z_style': z_style,
            'z_skill': z_skill
        }

    def encode(self, x):
        """è©•ä¾¡ç”¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é–¢æ•°"""
        encoder_output = self.encoder(x)
        z_style = self.reparameterize(encoder_output['mu_style'], encoder_output['logvar_style'])
        z_skill = self.reparameterize(encoder_output['mu_skill'], encoder_output['logvar_skill'])

        return {
            'z_style': z_style,
            'z_skill': z_skill,
            'predicted_signatures': encoder_output['predicted_signatures'],
            **encoder_output
        }

    def decode(self, z_style, z_skill):
        """è©•ä¾¡ç”¨ãƒ‡ã‚³ãƒ¼ãƒ‰é–¢æ•°"""
        return self.decoder(z_style, z_skill)


# ==========================================
# 5. å¯¾ç…§å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆå¾“æ¥é€šã‚Šï¼‰
# ==========================================
class ContrastiveLoss(nn.Module):
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature

    def forward(self, z_style, subject_ids):
        batch_size = z_style.shape[0]
        unique_subjects = list(set(subject_ids))
        if len(unique_subjects) < 2:
            return torch.tensor(0.0, device=z_style.device)

        subject_to_idx = {subj: i for i, subj in enumerate(unique_subjects)}
        labels = torch.tensor([subject_to_idx[subj] for subj in subject_ids], device=z_style.device)

        z_style_norm = F.normalize(z_style, p=2, dim=1)
        sim_matrix = torch.mm(z_style_norm, z_style_norm.t()) / self.temperature
        mask = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()
        mask = mask - torch.eye(batch_size, device=z_style.device)

        exp_sim = torch.exp(sim_matrix)
        sum_exp = torch.sum(exp_sim * (1 - torch.eye(batch_size, device=z_style.device)), dim=1)
        pos_sum = torch.sum(exp_sim * mask, dim=1)
        pos_sum = torch.clamp(pos_sum, min=1e-8)

        loss = -torch.log(pos_sum / (sum_exp + 1e-8))
        return loss.mean()


# ==========================================
# 6. ä½¿ç”¨ä¾‹ã¨ãƒ‡ãƒãƒƒã‚°
# ==========================================
def create_signature_vae_model(config):
    """çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼VAEãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ"""
    return SignatureGuidedVAE(
        input_dim=config['input_dim'],  # 6 (ä½ç½®å·®åˆ†2 + é€Ÿåº¦å·®åˆ†2 + åŠ é€Ÿåº¦å·®åˆ†2)
        hidden_dim=config['hidden_dim'],  # 128
        style_latent_dim=config['style_latent_dim'],  # 16
        skill_latent_dim=config['skill_latent_dim'],  # 8
        seq_len=config['seq_len'],  # 100
        n_layers=config['n_layers'],  # 2
        beta=config['beta'],  # 0.001
        contrastive_weight=config['contrastive_weight'],  # 0.1
        signature_weight=config.get('signature_weight', 0.5)  # 0.5
    )


def debug_model_flow():
    """ãƒ¢ãƒ‡ãƒ«ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’ãƒ‡ãƒãƒƒã‚°"""
    print("ğŸ” çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼VAEå‡¦ç†ãƒ•ãƒ­ãƒ¼")
    print("=" * 50)

    print("å…¥åŠ›: [batch_size, seq_len, 6] è»Œé“ãƒ‡ãƒ¼ã‚¿")
    print("  â†“")
    print("ğŸ“ SignatureGuidedEncoder:")
    print("  â”œâ”€ LSTM â†’ [batch_size, hidden_dim]")
    print("  â”œâ”€ æ½œåœ¨å¤‰æ•°ãƒ˜ãƒƒãƒ‰ â†’ mu_style, logvar_style, mu_skill, logvar_skill")
    print("  â””â”€ ã‚·ã‚°ãƒãƒãƒ£ãƒ¼äºˆæ¸¬ãƒ˜ãƒƒãƒ‰ â†’ predicted_signatures [batch_size, 5]")
    print("  â†“")
    print("ğŸ“ å†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–:")
    print("  â””â”€ z_style [batch_size, style_latent_dim], z_skill [batch_size, skill_latent_dim]")
    print("  â†“")
    print("ğŸ“ SimpleDecoderWithSignature:")
    print("  â”œâ”€ è»Œé“ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ â†’ reconstructed_trajectory [batch_size, seq_len, 6]")
    print("  â””â”€ ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ â†’ reconstructed_signatures [batch_size, 5]")
    print("  â†“")
    print("ğŸ“ SignatureCalculator:")
    print("  â””â”€ çœŸã®çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ â†’ true_signatures [batch_size, 5]")
    print("  â†“")
    print("ğŸ“ æå¤±è¨ˆç®—:")
    print("  â”œâ”€ è»Œé“å†æ§‹æˆæå¤±: MSE(reconstructed_trajectory, input)")
    print("  â”œâ”€ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚·ã‚°ãƒãƒãƒ£ãƒ¼æå¤±: MSE(predicted_signatures, true_signatures)")
    print("  â”œâ”€ ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚·ã‚°ãƒãƒãƒ£ãƒ¼æå¤±: MSE(reconstructed_signatures, true_signatures)")
    print("  â”œâ”€ KLæå¤±: KL(q(z|x) || p(z))")
    print("  â””â”€ å¯¾ç…§å­¦ç¿’æå¤±: InfoNCE(z_style, subject_ids)")


if __name__ == "__main__":
    debug_model_flow()

    # è¨­å®šä¾‹
    config = {
        'input_dim': 6,
        'hidden_dim': 128,
        'style_latent_dim': 16,
        'skill_latent_dim': 8,
        'seq_len': 100,
        'n_layers': 2,
        'beta': 0.001,
        'contrastive_weight': 0.1,
        'signature_weight': 0.5
    }

    # ãƒ¢ãƒ‡ãƒ«ä½œæˆä¾‹
    model = create_signature_vae_model(config)
    print(f"\nâœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")
    print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")