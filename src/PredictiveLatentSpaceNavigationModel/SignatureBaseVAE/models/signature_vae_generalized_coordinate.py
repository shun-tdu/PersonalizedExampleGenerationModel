"""
ğŸ¯ çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼VAEå…¨ä½“æ§‹é€ 

SimpleDecoderWithSignatureç‰ˆã§ã®å®Œå…¨ãªãƒ¢ãƒ‡ãƒ«æ§‹é€ 
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np


# ==========================================
# 1. çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼è¨ˆç®—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# ==========================================
class BatchSignatureCalculator(nn.Module):
    """ãƒãƒƒãƒå‡¦ç†å¯¾å¿œã®é«˜åŠ¹ç‡ã‚·ã‚°ãƒãƒãƒ£ãƒ¼è¨ˆç®—"""

    def forward(self, trajectories):
        """
        Args:
            trajectories: [batch_size, seq_len, 6]
        Returns:
            signatures: [batch_size, 5]
        """
        batch_size, seq_len, _ = trajectories.shape
        device = trajectories.device

        # ãƒãƒƒãƒå…¨ä½“ã§ä¸¦åˆ—è¨ˆç®—
        signatures = torch.zeros(batch_size, 5, device=device, dtype=torch.float32)

        # 1. è»Œé“æ›²ç‡ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
        signatures[:, 0] = self._batch_path_curvature(trajectories[:, :, :2])

        # 2. é€Ÿåº¦æ»‘ã‚‰ã‹ã•ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
        signatures[:, 1] = self._batch_velocity_smoothness(trajectories[:, :, 2:4])

        # 3. åŠ é€Ÿåº¦ã‚¸ãƒ£ãƒ¼ã‚¯ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
        signatures[:, 2] = self._batch_acceleration_jerk(trajectories[:, :, 4:6])

        # 4. é‹å‹•ãƒªã‚ºãƒ ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
        signatures[:, 3] = self._batch_movement_rhythm(trajectories[:, :, 2:4])

        # 5. åŠ›èª¿ç¯€ï¼ˆãƒãƒƒãƒå‡¦ç†ï¼‰
        signatures[:, 4] = self._batch_force_modulation(trajectories[:, :, 4:6])

        return signatures

    def _batch_path_curvature(self, pos_diffs):
        """ãƒãƒƒãƒå‡¦ç†ç‰ˆè»Œé“æ›²ç‡"""
        # pos_diffs: [batch_size, seq_len, 2]
        batch_size, seq_len, _ = pos_diffs.shape

        if seq_len < 3:
            return torch.zeros(batch_size, device=pos_diffs.device)

        # ä½ç½®å¾©å…ƒ
        positions = torch.cumsum(pos_diffs, dim=1)  # [batch_size, seq_len, 2]

        # 3ç‚¹ã§ã®æ›²ç‡è¨ˆç®—
        p1 = positions[:, :-2, :]  # [batch_size, seq_len-2, 2]
        p2 = positions[:, 1:-1, :]  # [batch_size, seq_len-2, 2]
        p3 = positions[:, 2:, :]  # [batch_size, seq_len-2, 2]

        v1 = p2 - p1  # [batch_size, seq_len-2, 2]
        v2 = p3 - p2  # [batch_size, seq_len-2, 2]

        # å¤–ç©
        cross = v1[:, :, 0] * v2[:, :, 1] - v1[:, :, 1] * v2[:, :, 0]  # [batch_size, seq_len-2]

        # ãƒãƒ«ãƒ 
        norms1 = torch.norm(v1, dim=2)  # [batch_size, seq_len-2]
        norms2 = torch.norm(v2, dim=2)  # [batch_size, seq_len-2]
        norms_product = norms1 * norms2  # [batch_size, seq_len-2]

        # ã‚¼ãƒ­é™¤ç®—å›é¿
        valid_mask = norms_product > 1e-6
        curvatures = torch.abs(cross) / (norms_product + 1e-6)

        # ãƒã‚¹ã‚¯ã‚’é©ç”¨ã—ã¦å¹³å‡
        curvatures = curvatures * valid_mask.float()
        valid_counts = valid_mask.float().sum(dim=1)
        valid_counts = torch.clamp(valid_counts, min=1.0)

        return curvatures.sum(dim=1) / valid_counts

    def _batch_velocity_smoothness(self, velocities):
        """ãƒãƒƒãƒå‡¦ç†ç‰ˆé€Ÿåº¦æ»‘ã‚‰ã‹ã•"""
        # velocities: [batch_size, seq_len, 2]
        if velocities.shape[1] < 2:
            return torch.ones(velocities.shape[0], device=velocities.device)

        vel_changes = torch.abs(torch.diff(velocities, dim=1))  # [batch_size, seq_len-1, 2]
        mean_changes = torch.mean(vel_changes, dim=(1, 2))  # [batch_size]

        return 1.0 / (1.0 + mean_changes)

    def _batch_acceleration_jerk(self, accelerations):
        """ãƒãƒƒãƒå‡¦ç†ç‰ˆåŠ é€Ÿåº¦ã‚¸ãƒ£ãƒ¼ã‚¯"""
        # accelerations: [batch_size, seq_len, 2]
        if accelerations.shape[1] < 2:
            return torch.zeros(accelerations.shape[0], device=accelerations.device)

        jerk = torch.abs(torch.diff(accelerations, dim=1))  # [batch_size, seq_len-1, 2]
        return torch.mean(jerk, dim=(1, 2))  # [batch_size]

    def _batch_movement_rhythm(self, velocities):
        """ãƒãƒƒãƒå‡¦ç†ç‰ˆé‹å‹•ãƒªã‚ºãƒ """
        # velocities: [batch_size, seq_len, 2]
        speeds = torch.norm(velocities, dim=2)  # [batch_size, seq_len]

        mean_speeds = torch.mean(speeds, dim=1)  # [batch_size]
        std_speeds = torch.std(speeds, dim=1)  # [batch_size]

        return std_speeds / (mean_speeds + 1e-6)

    def _batch_force_modulation(self, accelerations):
        """ãƒãƒƒãƒå‡¦ç†ç‰ˆåŠ›èª¿ç¯€"""
        # accelerations: [batch_size, seq_len, 2]
        forces = torch.norm(accelerations, dim=2)  # [batch_size, seq_len]

        mean_forces = torch.mean(forces, dim=1)  # [batch_size]
        std_forces = torch.std(forces, dim=1)  # [batch_size]

        return std_forces / (mean_forces + 1e-6)

# ==========================================
# 2. çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å­¦ç¿’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼
# ==========================================
class SignatureGuidedEncoder(nn.Module):
    """çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å­¦ç¿’æ©Ÿèƒ½ä»˜ãã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼"""

    def __init__(self, input_dim, hidden_dim, style_latent_dim, skill_latent_dim, n_layers=2):
        super().__init__()

        # åŸºæœ¬LSTMï¼ˆå¾“æ¥é€šã‚Šï¼‰
        self.lstm = nn.LSTM(input_dim, hidden_dim, n_layers, batch_first=True, dropout=0.1)

        # ã‚¹ã‚¿ã‚¤ãƒ«ãƒ»ã‚¹ã‚­ãƒ«æ½œåœ¨å¤‰æ•°ç”¨ãƒ˜ãƒƒãƒ‰ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        self.fc_mu_style = nn.Linear(hidden_dim, style_latent_dim)
        self.fc_logvar_style = nn.Linear(hidden_dim, style_latent_dim)
        self.fc_mu_skill = nn.Linear(hidden_dim, skill_latent_dim)
        self.fc_logvar_skill = nn.Linear(hidden_dim, skill_latent_dim)

        # ğŸ“ æ–°æ©Ÿèƒ½: çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼äºˆæ¸¬ãƒ˜ãƒƒãƒ‰
        self.signature_predictor = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, 5)  # 5ã¤ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ç‰¹å¾´
        )

    def forward(self, x):
        """
        Args:
            x: [batch_size, seq_len, input_dim] è»Œé“ãƒ‡ãƒ¼ã‚¿
        Returns:
            dict: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å‡ºåŠ›ï¼ˆæ½œåœ¨å¤‰æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ + äºˆæ¸¬ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ï¼‰
        """
        # LSTMå‡¦ç†
        _, (hidden, _) = self.lstm(x)
        last_hidden = hidden[-1]  # [batch_size, hidden_dim]

        # æ½œåœ¨å¤‰æ•°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        mu_style = self.fc_mu_style(last_hidden)
        logvar_style = self.fc_logvar_style(last_hidden)
        mu_skill = self.fc_mu_skill(last_hidden)
        logvar_skill = self.fc_logvar_skill(last_hidden)

        # ğŸ“ æ–°æ©Ÿèƒ½: çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã®äºˆæ¸¬
        predicted_signatures = self.signature_predictor(last_hidden)

        return {
            'mu_style': mu_style,
            'logvar_style': logvar_style,
            'mu_skill': mu_skill,
            'logvar_skill': logvar_skill,
            'predicted_signatures': predicted_signatures  # â† è¿½åŠ å‡ºåŠ›
        }


# ==========================================
# 3. ã‚·ã‚°ãƒãƒãƒ£ãƒ¼å¯¾å¿œãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼
# ==========================================
class SimpleDecoderWithSignature(nn.Module):
    """è»Œé“ + çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã®ä¸¡æ–¹ã‚’å‡ºåŠ›ã™ã‚‹ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼"""

    def __init__(self, output_dim, hidden_dim, style_latent_dim, skill_latent_dim, seq_len, n_layers=2):
        super().__init__()
        self.seq_len = seq_len
        self.output_dim = output_dim

        latent_dim = style_latent_dim + skill_latent_dim

        # ğŸ“ è»Œé“å†æ§‹æˆéƒ¨åˆ†ï¼ˆSimpleDecoderã¨åŒã˜ï¼‰
        self.trajectory_decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim * 2, seq_len * output_dim)
        )

        # ğŸ“ æ–°æ©Ÿèƒ½: çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å†æ§‹æˆéƒ¨åˆ†
        self.signature_decoder = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, 5)  # 5ã¤ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ç‰¹å¾´
        )

    def forward(self, z_style, z_skill):
        """
        Args:
            z_style: [batch_size, style_latent_dim] ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨å¤‰æ•°
            z_skill: [batch_size, skill_latent_dim] ã‚¹ã‚­ãƒ«æ½œåœ¨å¤‰æ•°
        Returns:
            dict: ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å‡ºåŠ›ï¼ˆè»Œé“ + ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ï¼‰
        """
        batch_size = z_style.size(0)
        z = torch.cat([z_style, z_skill], dim=1)  # æ½œåœ¨å¤‰æ•°çµåˆ

        # ğŸ“ è»Œé“å†æ§‹æˆ
        trajectory_output = self.trajectory_decoder(z)
        reconstructed_trajectory = trajectory_output.view(batch_size, self.seq_len, self.output_dim)

        # ğŸ“ çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å†æ§‹æˆ
        reconstructed_signatures = self.signature_decoder(z)

        return {
            'trajectory': reconstructed_trajectory,  # [batch_size, seq_len, output_dim]
            'signatures': reconstructed_signatures  # [batch_size, 5]
        }


# ==========================================
# 4. çµ±åˆVAEãƒ¢ãƒ‡ãƒ«
# ==========================================
class SignatureGuidedVAE(nn.Module):
    """çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼å­¦ç¿’æ©Ÿèƒ½ä»˜ãVAEï¼ˆå®Œå…¨ç‰ˆï¼‰"""

    def __init__(self,
                 input_dim,
                 hidden_dim,
                 style_latent_dim,
                 skill_latent_dim,
                 seq_len,
                 n_layers=2,
                 beta=0.001,
                 contrastive_weight=0.1,
                 signature_weight=0.5,
                 use_triplet=False,
                 ):
        super().__init__()

        # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.beta = beta
        self.contrastive_weight = contrastive_weight
        self.signature_weight = signature_weight

        # ğŸ“ ãƒ¢ãƒ‡ãƒ«æ§‹æˆè¦ç´ 
        self.encoder = SignatureGuidedEncoder(input_dim, hidden_dim, style_latent_dim, skill_latent_dim, n_layers)
        self.decoder = SimpleDecoderWithSignature(input_dim, hidden_dim, style_latent_dim, skill_latent_dim, seq_len,
                                                  n_layers)
        self.signature_calculator = BatchSignatureCalculator()

        # å¯¾ç…§å­¦ç¿’ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        self.contrastive_loss = ContrastiveLoss(temperature=0.07)

    def reparameterize(self, mu, logvar):
        """å†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãƒˆãƒªãƒƒã‚¯"""
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std

    def forward(self, x, subject_ids=None):
        """
        Args:
            x: [batch_size, seq_len, input_dim] å…¥åŠ›è»Œé“
            subject_ids: list è¢«é¨“è€…IDï¼ˆå¯¾ç…§å­¦ç¿’ç”¨ï¼‰
        Returns:
            dict: å…¨ã¦ã®æå¤±ã¨å‡ºåŠ›
        """
        # ğŸ“ 1. ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        encoder_output = self.encoder(x)

        # ğŸ“ 2. æ½œåœ¨å¤‰æ•°ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        z_style = self.reparameterize(encoder_output['mu_style'], encoder_output['logvar_style'])
        z_skill = self.reparameterize(encoder_output['mu_skill'], encoder_output['logvar_skill'])

        # ğŸ“ 3. ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆè»Œé“ + ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ï¼‰
        decoder_output = self.decoder(z_style, z_skill)
        reconstructed_trajectory = decoder_output['trajectory']
        reconstructed_signatures = decoder_output['signatures']

        # ğŸ“ 4. çœŸã®çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ã‚’è¨ˆç®—
        true_signatures = self.signature_calculator(x)

        # ğŸ“ 5. æå¤±è¨ˆç®—
        # 5-1. è»Œé“å†æ§‹æˆæå¤±ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        trajectory_recon_loss = F.mse_loss(reconstructed_trajectory, x)

        # 5-2. KLæå¤±ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        kl_style = -0.5 * torch.mean(torch.sum(
            1 + encoder_output['logvar_style'] - encoder_output['mu_style'].pow(2) - encoder_output[
                'logvar_style'].exp(), dim=1))
        kl_skill = -0.5 * torch.mean(torch.sum(
            1 + encoder_output['logvar_skill'] - encoder_output['mu_skill'].pow(2) - encoder_output[
                'logvar_skill'].exp(), dim=1))
        kl_style = torch.clamp(kl_style, min=0.0)
        kl_skill = torch.clamp(kl_skill, min=0.0)

        # ğŸ“ 5-3. çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼é–¢é€£æå¤±ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ¼äºˆæ¸¬æå¤±
        encoder_signature_loss = F.mse_loss(encoder_output['predicted_signatures'], true_signatures)
        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã®ã‚·ã‚°ãƒãƒãƒ£ãƒ¼å†æ§‹æˆæå¤±
        decoder_signature_loss = F.mse_loss(reconstructed_signatures, true_signatures)

        # 5-4. å¯¾ç…§å­¦ç¿’æå¤±ï¼ˆå¾“æ¥é€šã‚Šï¼‰
        contrastive_loss_val = torch.tensor(0.0, device=x.device)
        if subject_ids is not None and len(set(subject_ids)) > 1:
            contrastive_loss_val = self.contrastive_loss(z_style, subject_ids)

        # ğŸ“ 6. ç·åˆæå¤±
        total_loss = (
                trajectory_recon_loss +  # è»Œé“å†æ§‹æˆ
                self.beta * (kl_style + kl_skill) +  # KLæ­£å‰‡åŒ–
                self.signature_weight * encoder_signature_loss +  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚·ã‚°ãƒãƒãƒ£ãƒ¼å­¦ç¿’
                self.signature_weight * decoder_signature_loss +  # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚·ã‚°ãƒãƒãƒ£ãƒ¼å†æ§‹æˆ
                self.contrastive_weight * contrastive_loss_val  # å¯¾ç…§å­¦ç¿’
        )

        return {
            'total_loss': total_loss,
            'trajectory_recon_loss': trajectory_recon_loss,
            'kl_style': kl_style,
            'kl_skill': kl_skill,
            'encoder_signature_loss': encoder_signature_loss,
            'decoder_signature_loss': decoder_signature_loss,
            'contrastive_loss': contrastive_loss_val,
            'reconstructed_trajectory': reconstructed_trajectory,
            'reconstructed_signatures': reconstructed_signatures,
            'predicted_signatures': encoder_output['predicted_signatures'],
            'true_signatures': true_signatures,
            'z_style': z_style,
            'z_skill': z_skill
        }

    def encode(self, x):
        """è©•ä¾¡ç”¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é–¢æ•°"""
        encoder_output = self.encoder(x)
        z_style = self.reparameterize(encoder_output['mu_style'], encoder_output['logvar_style'])
        z_skill = self.reparameterize(encoder_output['mu_skill'], encoder_output['logvar_skill'])

        return {
            'z_style': z_style,
            'z_skill': z_skill,
            'predicted_signatures': encoder_output['predicted_signatures'],
            **encoder_output
        }

    def decode(self, z_style, z_skill):
        """è©•ä¾¡ç”¨ãƒ‡ã‚³ãƒ¼ãƒ‰é–¢æ•°"""
        return self.decoder(z_style, z_skill)

    def save_model(self, filepath: str):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        torch.save(self.state_dict(), filepath)

    def load_model(self, filepath: str, device=None):
        """ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""
        if device is None:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        state_dict = torch.load(filepath, map_location=device)
        self.load_state_dict(state_dict)
        self.to(device)


# ==========================================
# 5. å¯¾ç…§å­¦ç¿’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ï¼ˆå¾“æ¥é€šã‚Šï¼‰
# ==========================================
class ContrastiveLoss(nn.Module):
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature

    def forward(self, z_style, subject_ids):
        batch_size = z_style.shape[0]
        unique_subjects = list(set(subject_ids))
        if len(unique_subjects) < 2:
            return torch.tensor(0.0, device=z_style.device)

        subject_to_idx = {subj: i for i, subj in enumerate(unique_subjects)}
        labels = torch.tensor([subject_to_idx[subj] for subj in subject_ids], device=z_style.device)

        z_style_norm = F.normalize(z_style, p=2, dim=1)
        sim_matrix = torch.mm(z_style_norm, z_style_norm.t()) / self.temperature
        mask = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()
        mask = mask - torch.eye(batch_size, device=z_style.device)

        exp_sim = torch.exp(sim_matrix)
        sum_exp = torch.sum(exp_sim * (1 - torch.eye(batch_size, device=z_style.device)), dim=1)
        pos_sum = torch.sum(exp_sim * mask, dim=1)
        pos_sum = torch.clamp(pos_sum, min=1e-8)

        loss = -torch.log(pos_sum / (sum_exp + 1e-8))
        return loss.mean()


# ==========================================
# 6. ä½¿ç”¨ä¾‹ã¨ãƒ‡ãƒãƒƒã‚°
# ==========================================
def create_signature_vae_model(config):
    """çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼VAEãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ"""
    return SignatureGuidedVAE(
        input_dim=config['input_dim'],  # 6 (ä½ç½®å·®åˆ†2 + é€Ÿåº¦å·®åˆ†2 + åŠ é€Ÿåº¦å·®åˆ†2)
        hidden_dim=config['hidden_dim'],  # 128
        style_latent_dim=config['style_latent_dim'],  # 16
        skill_latent_dim=config['skill_latent_dim'],  # 8
        seq_len=config['seq_len'],  # 100
        n_layers=config['n_layers'],  # 2
        beta=config['beta'],  # 0.001
        contrastive_weight=config['contrastive_weight'],  # 0.1
        signature_weight=config.get('signature_weight', 0.5)  # 0.5
    )


def debug_model_flow():
    """ãƒ¢ãƒ‡ãƒ«ã®å‡¦ç†ãƒ•ãƒ­ãƒ¼ã‚’ãƒ‡ãƒãƒƒã‚°"""
    print("ğŸ” çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼VAEå‡¦ç†ãƒ•ãƒ­ãƒ¼")
    print("=" * 50)

    print("å…¥åŠ›: [batch_size, seq_len, 6] è»Œé“ãƒ‡ãƒ¼ã‚¿")
    print("  â†“")
    print("ğŸ“ SignatureGuidedEncoder:")
    print("  â”œâ”€ LSTM â†’ [batch_size, hidden_dim]")
    print("  â”œâ”€ æ½œåœ¨å¤‰æ•°ãƒ˜ãƒƒãƒ‰ â†’ mu_style, logvar_style, mu_skill, logvar_skill")
    print("  â””â”€ ã‚·ã‚°ãƒãƒãƒ£ãƒ¼äºˆæ¸¬ãƒ˜ãƒƒãƒ‰ â†’ predicted_signatures [batch_size, 5]")
    print("  â†“")
    print("ğŸ“ å†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–:")
    print("  â””â”€ z_style [batch_size, style_latent_dim], z_skill [batch_size, skill_latent_dim]")
    print("  â†“")
    print("ğŸ“ SimpleDecoderWithSignature:")
    print("  â”œâ”€ è»Œé“ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ â†’ reconstructed_trajectory [batch_size, seq_len, 6]")
    print("  â””â”€ ã‚·ã‚°ãƒãƒãƒ£ãƒ¼ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ â†’ reconstructed_signatures [batch_size, 5]")
    print("  â†“")
    print("ğŸ“ SignatureCalculator:")
    print("  â””â”€ çœŸã®çµ±åˆã‚·ã‚°ãƒãƒãƒ£ãƒ¼ â†’ true_signatures [batch_size, 5]")
    print("  â†“")
    print("ğŸ“ æå¤±è¨ˆç®—:")
    print("  â”œâ”€ è»Œé“å†æ§‹æˆæå¤±: MSE(reconstructed_trajectory, input)")
    print("  â”œâ”€ ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã‚·ã‚°ãƒãƒãƒ£ãƒ¼æå¤±: MSE(predicted_signatures, true_signatures)")
    print("  â”œâ”€ ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚·ã‚°ãƒãƒãƒ£ãƒ¼æå¤±: MSE(reconstructed_signatures, true_signatures)")
    print("  â”œâ”€ KLæå¤±: KL(q(z|x) || p(z))")
    print("  â””â”€ å¯¾ç…§å­¦ç¿’æå¤±: InfoNCE(z_style, subject_ids)")


if __name__ == "__main__":
    debug_model_flow()

    # è¨­å®šä¾‹
    config = {
        'input_dim': 6,
        'hidden_dim': 128,
        'style_latent_dim': 16,
        'skill_latent_dim': 8,
        'seq_len': 100,
        'n_layers': 2,
        'beta': 0.001,
        'contrastive_weight': 0.1,
        'signature_weight': 0.5
    }

    # ãƒ¢ãƒ‡ãƒ«ä½œæˆä¾‹
    model = create_signature_vae_model(config)
    print(f"\nâœ… ãƒ¢ãƒ‡ãƒ«ä½œæˆå®Œäº†")
    print(f"ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {sum(p.numel() for p in model.parameters()):,}")