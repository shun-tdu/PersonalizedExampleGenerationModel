"""å› å­ã‚¹ã‚­ãƒ«æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""

import pandas as pd
import numpy as np
import torch
from typing import Dict, Any, Tuple, List

from torch.distributed import isend
from torch.nn.utils.rnn import pad_sequence

from .base_dataset import BaseExperimentDataset

class FactorScoreMetricsDataset(BaseExperimentDataset):
    """å› å­ã‚¹ã‚­ãƒ«æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    def __init__(self, df: pd.DataFrame, scalers: dict, feature_cols: list, config: Dict[str, Any]):
        super().__init__(config)
        self.df = df
        self.scalers = scalers
        self.feature_cols = feature_cols
        self.load_data()
        self.preprocess()

    def load_data(self):
        # CLAUDE_ADDED: ãƒ–ãƒ­ãƒƒã‚¯æƒ…å ±ã‚‚å«ã‚ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆå„ãƒ–ãƒ­ãƒƒã‚¯ã®å„è©¦è¡Œã‚’åˆ¥ã€…ã«æ‰±ã†ï¼‰
        self.trials = list(self.df.groupby(['subject_id', 'trial_num', 'block']))
        print(f"Dataset initialized with {len(self.trials)} trials")
        print(f"Feature columns: {self.feature_cols}")
        print(f"Available scalers: {list(self.scalers.keys())}")

    def preprocess(self):
        pass

    def __len__(self) -> int:
        return len(self.trials)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, str, torch.Tensor]:
        """æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""

        # 1. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹è©¦è¡Œãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        # CLAUDE_ADDED: ãƒ–ãƒ­ãƒƒã‚¯æƒ…å ±ã‚‚å«ã‚€3ã¤ã®è¦ç´ ã‚’å±•é–‹
        (subject_id, trial_num, block), trial_df = self.trials[idx]

        # CLAUDE_ADDED: è»Œé“ç‰¹å¾´é‡ï¼ˆ6æ¬¡å…ƒï¼šä½ç½®ã€é€Ÿåº¦ã€åŠ é€Ÿåº¦ã®x,yï¼‰
        trajectory_features = ['HandlePosX', 'HandlePosY', 'HandleVelX',
                             'HandleVelY', 'HandleAccX', 'HandleAccY']

        # 2. è»Œé“ãƒ‡ãƒ¼ã‚¿ã‚’æ™‚ç³»åˆ—ã¨ã—ã¦å–å¾— (seq_len, num_features)
        trajectory_data = trial_df[trajectory_features].values

        # CLAUDE_ADDED: å› å­ã‚¹ã‚³ã‚¢ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        factor_score_cols = [col for col in trial_df.columns if col.startswith('factor_') and col.endswith('_score')]

        if factor_score_cols:
            # å› å­ã‚¹ã‚³ã‚¢ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦è¿”ã™
            skill_factors = []
            for col in sorted(factor_score_cols):  # factor_1_score, factor_2_score, ...ã®é †ã«ã‚½ãƒ¼ãƒˆ
                skill_factors.append(trial_df[col].iloc[0] if len(trial_df) > 0 else 0.0)
            skill_factor_tensor = torch.tensor(skill_factors, dtype=torch.float32)  # [factor_num]
        else:
            # å› å­ã‚¹ã‚³ã‚¢ãŒå­˜åœ¨ã—ãªã„å ´åˆã€skill_scoreã®ã¿ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼ï¼‰
            skill_score = trial_df['skill_score'].iloc[0] if len(trial_df) > 0 else 0.0
            skill_factor_tensor = torch.tensor(skill_score, dtype=torch.float32)  # scalar

        # 4. ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›ã—ã¦è¿”ã™
        # trajectory: [seq_len, 6] -> ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹å½¢çŠ¶
        # subject_id: æ–‡å­—åˆ—
        # skill_factor: [factor_num] ã¾ãŸã¯ scalar
        return (
            torch.tensor(trajectory_data, dtype=torch.float32),  # [seq_len, 6]
            subject_id,                                           # string
            skill_factor_tensor                                   # [factor_num] or scalar
        )

    def get_info(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’å–å¾—"""
        info = super().get_info()
        info.update({
            'num_trials': len(self.trials),
            'num_subjects': len(self.df['subject_id'].unique()),
            'feature_columns': self.feature_cols,
        })
        return info


class FactorScoreMetricsNoInterpolateDataset(BaseExperimentDataset):
    """å› å­ã‚¹ã‚­ãƒ«æŒ‡æ¨™æ™‚é–“è£œå®Œãªã—ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    def __init__(self, df: pd.DataFrame, scalers: dict, feature_cols: list, config: Dict[str, Any]):
        super().__init__(config)
        self.df = df
        self.scalers = scalers
        self.feature_cols = feature_cols

        # ãƒ‘ãƒƒãƒå‡¦ç†ã®è¨­å®šã‚’configãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
        patch_config = self.config.get('patch', {})
        self.patch_size = patch_config.get('size', 20)
        self.patch_step = patch_config.get('step', 10)

        print(f"ğŸ’¡ Patching configuration: size={self.patch_size}, step={self.patch_step}")
        if self.patch_step < self.patch_size:
            print(f"   -> Overlap is enabled ({(self.patch_size - self.patch_step) / self.patch_size * 100:.1f}%).")

        self.load_data()
        self.preprocess()

    def load_data(self):
        # CLAUDE_ADDED: ãƒ–ãƒ­ãƒƒã‚¯æƒ…å ±ã‚‚å«ã‚ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆå„ãƒ–ãƒ­ãƒƒã‚¯ã®å„è©¦è¡Œã‚’åˆ¥ã€…ã«æ‰±ã†ï¼‰
        self.trials = list(self.df.groupby(['subject_id', 'trial_num', 'block']))
        print(f"Dataset initialized with {len(self.trials)} trials")
        print(f"Feature columns: {self.feature_cols}")
        print(f"Available scalers: {list(self.scalers.keys())}")

    def preprocess(self):
        pass

    def __len__(self) -> int:
        return len(self.trials)

    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, str, torch.Tensor]:
        """æŒ‡å®šã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""

        # 1. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«å¯¾å¿œã™ã‚‹è©¦è¡Œãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        (subject_id, trial_num, block), trial_df = self.trials[idx]

        # CLAUDE_ADDED: è»Œé“ç‰¹å¾´é‡ï¼ˆ6æ¬¡å…ƒï¼šä½ç½®ã€é€Ÿåº¦ã€åŠ é€Ÿåº¦ã®x,yï¼‰
        trajectory_features = ['HandlePosX', 'HandlePosY', 'HandleVelX',
                             'HandleVelY', 'HandleAccX', 'HandleAccY']

        # 2. è»Œé“ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ› [seq_len, num_features]
        trajectory_tensor = torch.tensor(trial_df[trajectory_features].values,dtype=torch.float32)

        # 3. è»Œé“ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ãƒ‘ãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œ [num_patches, num_features, patch_size]
        patches = trajectory_tensor.unfold(dimension=0, size=self.patch_size, step=self.patch_step)
        patches = patches.permute(0, 2, 1) # [num_patches, patch_size, num_features]

        # 4. å› å­ã‚¹ã‚³ã‚¢ã‚’å–å¾—
        factor_score_cols = [col for col in trial_df.columns if col.startswith('factor_') and col.endswith('_score')]
        if factor_score_cols:
            skill_factors = []
            for col in sorted(factor_score_cols):  # factor_1_score, factor_2_score, ...ã®é †ã«ã‚½ãƒ¼ãƒˆ
                skill_factors.append(trial_df[col].iloc[0] if len(trial_df) > 0 else 0.0)
            skill_factor_tensor = torch.tensor(skill_factors, dtype=torch.float32)  # [factor_num]
        else:
            # å› å­ã‚¹ã‚³ã‚¢ãŒå­˜åœ¨ã—ãªã„å ´åˆã€skill_scoreã®ã¿ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼ï¼‰
            skill_score = trial_df['skill_score'].iloc[0] if len(trial_df) > 0 else 0.0
            skill_factor_tensor = torch.tensor(skill_score, dtype=torch.float32)  # scalar

        return (
            patches,                # [num_patches, patch_size, 6]
            subject_id,             # string
            skill_factor_tensor     # [factor_num] or scalar
        )

    def get_info(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’å–å¾—"""
        info = super().get_info()
        info.update({
            'num_trials': len(self.trials),
            'num_subjects': len(self.df['subject_id'].unique()),
            'feature_columns': self.feature_cols,
            'patch_size': self.patch_size,
            'patch_step': self.patch_step
        })
        return info

def collate_fn_padd(batch:List[Tuple[torch.Tensor, str, torch.Tensor]]) -> Dict[str, Any]:
    """
    å¯å¤‰é•·ã®ãƒ‘ãƒƒãƒåˆ—ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã—ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚’ä½œæˆã™ã‚‹

    Args:
        batch: Datasetã‹ã‚‰è¿”ã•ã‚Œã‚‹(è»Œé“ãƒ‘ãƒƒãƒã€subject_id, ã‚¹ã‚­ãƒ«å› å­ãƒ™ã‚¯ãƒˆãƒ«)ã®ã‚¿ãƒ—ãƒ«ã®ãƒªã‚¹ãƒˆ

    Returns:
        A dict containing:
                    'trajectory': ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°æ¸ˆã¿ã®è»Œé“ãƒ†ãƒ³ã‚½ãƒ« (B, S, P, F)
                    'skill_vector': ã‚¹ã‚­ãƒ«ãƒ™ã‚¯ãƒˆãƒ«ã®ãƒ†ãƒ³ã‚½ãƒ« (B, N_factors)
                    'attention_mask': ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°éƒ¨åˆ†ã‚’ç„¡è¦–ã™ã‚‹ãŸã‚ã®ãƒã‚¹ã‚¯ (B, S)
                    'subject_id': subject_idã®ãƒªã‚¹ãƒˆ
    """
    # 1. ãƒ‡ãƒ¼ã‚¿ã‚’ç¨®é¡ã”ã¨ã«åˆ†å‰²
    # trajectories_listã¯ã€å½¢çŠ¶ãŒ (S_i, P, F) ã®ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒªã‚¹ãƒˆã«ãªã‚‹ (S_iã¯è©¦è¡Œiã®ãƒ‘ãƒƒãƒæ•°)
    trajectories_list, subject_ids, skill_factors = zip(*batch)

    # 2. è»Œé“ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    padded_trajectories = pad_sequence(trajectories_list, batch_first=True, padding_value=0.0)
    # -> å‡ºåŠ›å½¢çŠ¶: (B, S_max, P, F)
    #    B = ãƒãƒƒãƒã‚µã‚¤ã‚º
    #    S_max = ãƒãƒƒãƒå†…ã§æœ€ã‚‚ãƒ‘ãƒƒãƒæ•°ãŒå¤šã„è©¦è¡Œã®ãƒ‘ãƒƒãƒæ•°
    #    P = ãƒ‘ãƒƒãƒã‚µã‚¤ã‚º
    #    F = ç‰¹å¾´é‡æ•° (6)

    # 3. ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚’ä½œæˆ
    original_lengths = [t.size(0) for t in trajectories_list]
    max_len = padded_trajectories.size(1)

    # (B, S_max) ã®å½¢çŠ¶ã®ãƒã‚¹ã‚¯ã‚’ä½œæˆ
    # PyTorchã®Transformerã¯ã€Trueã®éƒ¨åˆ†ã‚’ç„¡è¦–(ãƒã‚¹ã‚¯)ã™ã‚‹
    attention_mask = torch.arange(max_len)[None, :] >= torch.tensor(original_lengths)[:, None]

    # 4. ã‚¹ã‚­ãƒ«å› å­ã‚’1ã¤ã®ãƒ†ãƒ³ã‚½ãƒ«ã«ã¾ã¨ã‚ã‚‹
    skill_factor_tensor = torch.stack(skill_factors)

    # 5.è¾æ›¸å½¢å¼ã§è¿”ã™
    return {
        'trajectory': padded_trajectories,
        'skill_factor': skill_factor_tensor,
        'attention_mask': attention_mask,
        'subject_id': subject_ids
    }
