# ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®è©•ä¾¡å™¨
from typing import List, Dict, Any, Union, Tuple
import numpy as np
import matplotlib.pyplot as plt
import plotly
import plotly.express as px
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans


from base_evaluator import BaseEvaluator
from src.PredictiveLatentSpaceNavigationModel.TransformerBaseEndToEndVAE.evaluator import EnhancedEvaluationResult


class VisualizeStyleSpaceEvaluator(BaseEvaluator):
    """ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ–è©•ä¾¡"""
    def __init__(self, config:Dict[str, Any]):
        super().__init__(config)
        self.min_samples_for_tsne = 30
        style_components = config.get('evaluation').get('style_component')
        self.n_components = style_components if style_components in [2, 3] else 2

    def evaluate(self, model, test_data, result: EnhancedEvaluationResult) -> None:
        """ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ–è©•ä¾¡ã‚’å®Ÿè¡Œ"""
        experiment_id = test_data.get('experiment_id')
        z_style = test_data.get('z_style')
        subject_ids = test_data.get('subject_ids')
        output_dir = test_data.get('output_dir')

        print("=" * 60)
        print("ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®å¯è¦–åŒ–è©•ä¾¡å®Ÿè¡Œ")
        print("=" * 60)

        pca_fig, tsne_fig = self._create_style_latent_space_visualizations(z_style=z_style, subject_ids=subject_ids)

        result.add_visualization("style_pca",pca_fig,
                                 description="ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®PCAå¯è¦–åŒ–",
                                 category="style_analysis")
        result.add_visualization("style_tsne", tsne_fig,
                                 description="ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®t-SNEå¯è¦–åŒ–",
                                 category="style_analysis")

    def get_required_data(self) -> List[str]:
        return ['z_style', 'experiment_id']

    def _create_style_latent_space_visualizations(self, z_style, subject_ids, n_components=2) -> Union[Tuple[plt.Figure,plt.Figure], Tuple[plotly.graph_objs.Figure,plotly.graph_objs.Figure]]:
        """åŒ…æ‹¬çš„å¯è¦–åŒ–ç”Ÿæˆ - ä¸»æˆåˆ†æ¬¡å…ƒãŒ2ã®ã¨ãã¯Matplot Figureã€ 3ã®ã¨ãã¯Plotly Figureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™"""
        print(f"\nğŸ¨ å¯è¦–åŒ–ç”Ÿæˆä¸­...")

        # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—æº–å‚™
        subject_to_idx = {subj: i for i, subj in enumerate(subject_ids)}
        subject_colors = [subject_to_idx[subj] for subj in subject_ids]

        # ä¸»æˆåˆ†æ¬¡å…ƒãŒ2ã®ã¨ãã¯Matplot Figureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™
        if n_components == 2:
            # 1. ã‚¹ã‚¿ã‚¤ãƒ«ç©ºé–“PCA
            fig_pca, ax_pca = plt.subplots(figsize=(10, 8))
            if z_style.shape[1] >= 2:
                pca_style = PCA(n_components=2)
                z_style_pca = pca_style.fit_transform(z_style)

                scatter = ax_pca.scatter(z_style_pca[:, 0], z_style_pca[:, 1],
                                             c=subject_colors, cmap='tab10', alpha=0.7, s=30)
                ax_pca.set_title(f'Style Space PCA\n(Explained: {pca_style.explained_variance_ratio_.sum():.3f})')
                ax_pca.set_xlabel('PC1')
                ax_pca.set_ylabel('PC2')

                # é‡å¿ƒãƒ—ãƒ­ãƒƒãƒˆ
                for i, subject in enumerate(subject_ids):
                    mask = np.array(subject_ids) == subject
                    if np.any(mask):
                        center = np.mean(z_style_pca[mask], axis=0)
                        ax_pca.scatter(center[0], center[1], c='red', s=200, marker='x', linewidth=3)
                        ax_pca.annotate(subject, center, xytext=(5, 5), textcoords='offset points')

            # 2. ã‚¹ã‚¿ã‚¤ãƒ«ç©ºé–“t-SNE
            fig_tsne, ax_tsne = plt.subplots(figsize=(10, 8))
            if len(z_style) >= self.min_samples_for_tsne:
                try:
                    tsne = TSNE(n_components=2, perplexity=min(30, len(z_style) // 4), random_state=42)
                    z_style_tsne = tsne.fit_transform(z_style)

                    ax_tsne.scatter(z_style_tsne[:, 0], z_style_tsne[:, 1],
                                       c=subject_colors, cmap='tab10', alpha=0.7, s=30)
                    ax_tsne.set_title('Style Space t-SNE')
                except Exception as e:
                    ax_tsne.text(0.5, 0.5, f't-SNE Failed: {str(e)}', transform=ax_tsne.transAxes, ha='center')
            else:
                ax_tsne.text(0.5, 0.5, 'Insufficient samples for t-SNE', transform=ax_tsne.transAxes, ha='center')

            return fig_pca, fig_tsne

        elif n_components == 3:
            fig_pca = None
            # 1. ã‚¹ã‚¿ã‚¤ãƒ«ç©ºé–“PCA
            if z_style.shape[1] > 3:
                pca_style = PCA(n_components=3)
                z_style_pca = pca_style.fit_transform(z_style)

                df_pca = pd.DataFrame({
                    "PC1": z_style_pca[:, 0],
                    "PC2": z_style_pca[:, 1],
                    "PC3": z_style_pca[:, 2],
                    "subject_ids":subject_colors
                })

                fig_pca = px.scatter_3d(
                    df_pca,
                    x="PC1",
                    y="PC2",
                    z="PC3",
                    color='subject_ids',
                    title= f'Style Space PCA\n(Explained: {pca_style.explained_variance_ratio_.sum():.3f})',
                    hover_data=['subject_ids']
                )
                fig_pca.update_layout(title_x=0.5)
                fig_pca.update_traces(marker=dict(size=4, opacity=0.8))


            # 2. ã‚¹ã‚¿ã‚¤ãƒ«ç©ºé–“t-SNE
            fig_tsne = None
            if len(z_style) >= self.min_samples_for_tsne:
                try:
                    tsne = TSNE(n_components=3, perplexity=min(30, len(z_style) // 4), random_state=42)
                    z_style_tsne = tsne.fit_transform(z_style)

                    df_tsne = pd.DataFrame({
                        "PC1": z_style_tsne[:, 0],
                        "PC2": z_style_tsne[:, 1],
                        "PC3": z_style_tsne[:, 2],
                        "subject_ids":subject_colors
                    })

                    fig_tsne = px.scatter_3d(
                        df_tsne,
                        x="PC1",
                        y="PC2",
                        z="PC3",
                        color='subject_ids',
                        title=f'Style Space t-SNE(3D)',
                        hover_data=['subject_ids']
                    )
                    fig_tsne.update_layout(title_x=0.5)
                    fig_tsne.update_traces(marker=dict(size=4, opacity=0.8))

                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ç©ºã®Figureã‚’ä½œæˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆã§é€šçŸ¥
                    fig_tsne = plotly.graph_objs.Figure()
                    fig_tsne.add_annotation(text=f"t-SNE Failed: {e}", showarrow=False, font=dict(size=16))
                    fig_tsne.update_layout(title_text="Style Space t-SNE (3D) - Failed")
            else:
                # ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã‚‚åŒæ§˜
                fig_tsne = plotly.graph_objs.Figure()
                fig_tsne.add_annotation(text="Insufficient samples for t-SNE", showarrow=False, font=dict(size=16))
                fig_tsne.update_layout(title_text="Style Space t-SNE (3D) - Skipped")

            return fig_pca, fig_tsne
        else:
            raise ValueError(f"ä¸»æˆåˆ†åˆ†æã®ä¸»æˆåˆ†æ¬¡å…ƒæ•°ãŒä¸é©åˆ‡ã§ã™ï¼2ã‹3ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼")


class StyleClusteringEvaluator(BaseEvaluator):
    """ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“å†…ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ€§èƒ½ã®è©•ä¾¡"""
    def __init__(self, config:Dict[str, Any]):
        pass

    def evaluate(self, model, test_data, result: EnhancedEvaluationResult) -> None:
        """ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è©•ä¾¡ã‚’å®Ÿè¡Œ"""
        z_style = test_data.get('z_style')
        subject_ids = test_data.get('subject_ids')

        print("=" * 60)
        print("ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è©•ä¾¡å®Ÿè¡Œ")
        print("=" * 60)

        # è¢«é¨“è€…æƒ…å ±ã®æº–å‚™
        unique_subjects = list(set(subject_ids))
        n_subjects = len(unique_subjects)

        if n_subjects < self.min_subjects_for_clustering:
            print(f"âš ï¸ è¢«é¨“è€…æ•°ä¸è¶³: {n_subjects} < {self.min_subjects_for_clustering}")
            result.add_metric("clustering_status", 0, "è¢«é¨“è€…æ•°ä¸è¶³", "clustering")
            return

        # çœŸã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«ä½œæˆ
        subject_to_idx = {subj: i for i, subj in enumerate(unique_subjects)}
        true_labels = [subject_to_idx[subj] for subj in subject_ids]

        # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        clustering_results = self._perform_kmeans_clustering(z_style, true_labels, n_subjects)

        # ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢è©•ä¾¡
        silhouette_results = self._perform_silhouette_score_evaluation(z_style, true_labels, n_subjects)

        # èª¿æ•´ãƒ©ãƒ³ãƒ‰æŒ‡æ¨™è©•ä¾¡
        ari_results = self._perform_adjusted_rand_index_evaluation(z_style, true_labels, n_subjects)

        # çµæœã‚’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã«è¿½åŠ 
        self._add_clustering_metrics(result, clustering_results, silhouette_results, ari_results)

        print("âœ… ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è©•ä¾¡å®Œäº†")

    def _perform_kmeans_clustering(self, z_style, true_labels, n_clusters):
        """K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ"""

        try:
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            predicted_labels = kmeans.fit_predict(z_style)

            print(f"ğŸ“Š K-meanså®Œäº†: {n_clusters}ã‚¯ãƒ©ã‚¹ã‚¿")
            return {
                'predicted_labels': predicted_labels,
                'cluster_centers': kmeans.cluster_centers_,
                'inertia': kmeans.inertia_,
                'success': True
            }
        except Exception as e:
            print(f"âŒ K-meansã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}

    def _perform_silhouette_score_evaluation(self, z_style, true_labels, n_clusters):
        """ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢è©•ä¾¡"""
        from sklearn.metrics import silhouette_score, silhouette_samples
        from sklearn.cluster import KMeans

        results = {}

        try:
            # K-meansã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            predicted_labels = kmeans.fit_predict(z_style)

            # å…¨ä½“ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢
            overall_silhouette = silhouette_score(z_style, predicted_labels)

            # ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢
            sample_silhouette = silhouette_samples(z_style, predicted_labels)

            # ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®å¹³å‡ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢
            cluster_silhouettes = {}
            for i in range(n_clusters):
                cluster_mask = predicted_labels == i
                if np.any(cluster_mask):
                    cluster_silhouettes[i] = np.mean(sample_silhouette[cluster_mask])

            # çœŸã®ãƒ©ãƒ™ãƒ«ã§ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆå‚è€ƒå€¤ï¼‰
            true_silhouette = silhouette_score(z_style, true_labels) if len(set(true_labels)) > 1 else 0.0

            print(f"ğŸ¯ ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢:")
            print(f"  äºˆæ¸¬ã‚¯ãƒ©ã‚¹ã‚¿: {overall_silhouette:.4f}")
            print(f"  çœŸã®ãƒ©ãƒ™ãƒ«: {true_silhouette:.4f}")

            # åˆ¤å®š
            if overall_silhouette > 0.7:
                silhouette_status = "å„ªç§€"
            elif overall_silhouette > 0.5:
                silhouette_status = "è‰¯å¥½"
            elif overall_silhouette > 0.25:
                silhouette_status = "æ™®é€š"
            else:
                silhouette_status = "ä¸è‰¯"

            print(f"  åˆ¤å®š: {silhouette_status}")

            results = {
                'overall_silhouette': overall_silhouette,
                'true_label_silhouette': true_silhouette,
                'cluster_silhouettes': cluster_silhouettes,
                'sample_silhouettes': sample_silhouette,
                'silhouette_status': silhouette_status,
                'success': True
            }

        except Exception as e:
            print(f"âŒ ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            results = {'success': False, 'error': str(e)}

        return results

    def _perform_adjusted_rand_index_evaluation(self, z_style, true_labels, n_clusters):
        """èª¿æ•´ãƒ©ãƒ³ãƒ‰æŒ‡æ¨™è©•ä¾¡"""
        from sklearn.metrics import adjusted_rand_score
        from sklearn.cluster import KMeans

        results = {}

        try:
            # K-meansã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
            kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
            predicted_labels = kmeans.fit_predict(z_style)

            # èª¿æ•´ãƒ©ãƒ³ãƒ‰æŒ‡æ¨™è¨ˆç®—
            ari = adjusted_rand_score(true_labels, predicted_labels)

            print(f"ğŸ² èª¿æ•´ãƒ©ãƒ³ãƒ‰æŒ‡æ¨™ (ARI): {ari:.4f}")

            # åˆ¤å®š
            if ari > 0.75:
                ari_status = "å„ªç§€"
            elif ari > 0.5:
                ari_status = "è‰¯å¥½"
            elif ari > 0.25:
                ari_status = "æ™®é€š"
            else:
                ari_status = "ä¸è‰¯"

            print(f"  åˆ¤å®š: {ari_status}")

            # è¿½åŠ ã®åˆ†æ: ã‚¯ãƒ©ã‚¹ã‚¿ç´”åº¦
            cluster_purities = self._calculate_cluster_purity(true_labels, predicted_labels, n_clusters)

            results = {
                'ari': ari,
                'ari_status': ari_status,
                'predicted_labels': predicted_labels,
                'cluster_purities': cluster_purities,
                'success': True
            }

        except Exception as e:
            print(f"âŒ ARIè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            results = {'success': False, 'error': str(e)}

        return results

    def _calculate_cluster_purity(self, true_labels, predicted_labels, n_clusters):
        """ã‚¯ãƒ©ã‚¹ã‚¿ç´”åº¦ã®è¨ˆç®—"""
        purities = {}

        for cluster_id in range(n_clusters):
            cluster_mask = np.array(predicted_labels) == cluster_id
            if np.any(cluster_mask):
                cluster_true_labels = np.array(true_labels)[cluster_mask]
                # æœ€ã‚‚å¤šã„çœŸã®ãƒ©ãƒ™ãƒ«ã®å‰²åˆ
                unique_labels, counts = np.unique(cluster_true_labels, return_counts=True)
                max_count = np.max(counts)
                purity = max_count / len(cluster_true_labels)
                purities[cluster_id] = {
                    'purity': purity,
                    'dominant_label': unique_labels[np.argmax(counts)],
                    'size': len(cluster_true_labels)
                }

        return purities

    def _add_clustering_metrics(self, result, clustering_results, silhouette_results, ari_results):
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’çµæœã«è¿½åŠ """
        # ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if silhouette_results.get('success', False):
            result.add_metric('style_clustering_silhouette',
                              silhouette_results['overall_silhouette'],
                              'ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢', 'clustering')
            result.add_metric('style_clustering_true_silhouette',
                              silhouette_results['true_label_silhouette'],
                              'çœŸã®ãƒ©ãƒ™ãƒ«ã§ã®ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼ˆå‚è€ƒï¼‰', 'clustering')

        # ARI ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if ari_results.get('success', False):
            result.add_metric('style_clustering_ari',
                              ari_results['ari'],
                              'ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨ç©ºé–“ã®èª¿æ•´ãƒ©ãƒ³ãƒ‰æŒ‡æ¨™', 'clustering')

        # K-meansãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if clustering_results.get('success', False):
            result.add_metric('style_clustering_inertia',
                              clustering_results['inertia'],
                              'K-meansã‚¯ãƒ©ã‚¹ã‚¿å†…äºŒä¹—å’Œ', 'clustering')

    def get_required_data(self) -> List[str]:
        return ['z_style', 'subject_ids', 'experiment_id']


class StyleClassificationEvaluator(BaseEvaluator):
    """ã‚¹ã‚¿ã‚¤ãƒ«æ½œåœ¨å¤‰æ•°ã‹ã‚‰ç°¡å˜ãªSVM,MLPã§è¢«é¨“è€…ã®åˆ†é¡ãŒå¯èƒ½åŒ–ã‚’è©•ä¾¡"""
    def __init__(self, config:Dict[str, Any]):
        pass

    def evaluate(self, model, test_data, device) -> EnhancedEvaluationResult:
        pass

    def get_required_data(self) -> List[str]:
        pass


