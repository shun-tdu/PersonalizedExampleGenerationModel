{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ハイブリッドモデル（LSTM + 拡散モデル）の学習と可視化\n",
    "\n",
    "このノートブックでは、時系列データを低周波成分（LSTM）と高周波成分（拡散モデル）に分解して学習するハイブリッドモデルの学習過程を可視化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# パスを追加\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "src_dir = os.path.dirname(current_dir)\n",
    "root_dir = os.path.dirname(src_dir)\n",
    "sys.path.insert(0, root_dir)\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "from src.ImprovedHybridTransformer import HybridTrajectoryModel\n",
    "from src.DataPreprocess.DataPreprocessForOverFitting import load_processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# データの読み込み\n",
    "data_path = '../../data/Datasets/overfitting_dataset.npz'\n",
    "trajectories, conditions = load_processed_data(data_path)\n",
    "\n",
    "print(f\"軌道データ形状: {trajectories.shape}\")\n",
    "print(f\"条件データ形状: {conditions.shape}\")\n",
    "print(f\"軌道データ範囲: [{trajectories.min():.3f}, {trajectories.max():.3f}]\")\n",
    "print(f\"条件データ範囲: [{conditions.min():.3f}, {conditions.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# データの可視化\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 軌道データのサンプルを表示\n",
    "plt.subplot(1, 3, 1)\n",
    "for i in range(min(5, len(trajectories))):\n",
    "    plt.plot(trajectories[i, :, 0], trajectories[i, :, 1], alpha=0.7, label=f'Sample {i+1}')\n",
    "plt.xlabel('X Position')\n",
    "plt.ylabel('Y Position')\n",
    "plt.title('軌道データサンプル')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 条件データのヒストグラム\n",
    "condition_names = ['動作時間', '終点誤差', 'ジャーク']\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+2)\n",
    "    plt.hist(conditions[:, i], bins=20, alpha=0.7)\n",
    "    plt.xlabel(condition_names[i])\n",
    "    plt.ylabel('頻度')\n",
    "    plt.title(f'{condition_names[i]}の分布')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データ分解の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "from src.ImprovedHybridTransformer.data_decomposition import DataDecomposer\n",
    "\n",
    "# データ分解器を初期化\n",
    "decomposer = DataDecomposer(window_size=10)\n",
    "\n",
    "# サンプルデータで分解をテスト\n",
    "sample_trajectories = torch.tensor(trajectories[:5], dtype=torch.float32)\n",
    "low_freq, high_freq = decomposer.decompose(sample_trajectories)\n",
    "\n",
    "# 分解結果の可視化\n",
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(5):\n",
    "    # X軸の分解\n",
    "    plt.subplot(5, 6, i*6 + 1)\n",
    "    plt.plot(sample_trajectories[i, :, 0], label='Original', linewidth=2)\n",
    "    plt.plot(low_freq[i, :, 0], label='Low Freq', linewidth=2)\n",
    "    plt.plot(high_freq[i, :, 0], label='High Freq', alpha=0.7)\n",
    "    plt.title(f'Sample {i+1} - X軸分解')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Y軸の分解\n",
    "    plt.subplot(5, 6, i*6 + 2)\n",
    "    plt.plot(sample_trajectories[i, :, 1], label='Original', linewidth=2)\n",
    "    plt.plot(low_freq[i, :, 1], label='Low Freq', linewidth=2)\n",
    "    plt.plot(high_freq[i, :, 1], label='High Freq', alpha=0.7)\n",
    "    plt.title(f'Sample {i+1} - Y軸分解')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 軌道平面での可視化\n",
    "    plt.subplot(5, 6, i*6 + 3)\n",
    "    plt.plot(sample_trajectories[i, :, 0], sample_trajectories[i, :, 1], 'k-', label='Original', linewidth=2)\n",
    "    plt.plot(low_freq[i, :, 0], low_freq[i, :, 1], 'b-', label='Low Freq', linewidth=2)\n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.title(f'Sample {i+1} - 軌道比較')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 高周波成分の軌道\n",
    "    plt.subplot(5, 6, i*6 + 4)\n",
    "    plt.plot(high_freq[i, :, 0], high_freq[i, :, 1], 'r-', alpha=0.7)\n",
    "    plt.xlabel('X Residual')\n",
    "    plt.ylabel('Y Residual')\n",
    "    plt.title(f'Sample {i+1} - 高周波成分')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # パワースペクトラム\n",
    "    plt.subplot(5, 6, i*6 + 5)\n",
    "    original_fft = np.abs(np.fft.fft(sample_trajectories[i, :, 0]))\n",
    "    low_freq_fft = np.abs(np.fft.fft(low_freq[i, :, 0]))\n",
    "    high_freq_fft = np.abs(np.fft.fft(high_freq[i, :, 0]))\n",
    "    \n",
    "    freqs = np.fft.fftfreq(len(original_fft))\n",
    "    plt.semilogy(freqs[:len(freqs)//2], original_fft[:len(freqs)//2], label='Original')\n",
    "    plt.semilogy(freqs[:len(freqs)//2], low_freq_fft[:len(freqs)//2], label='Low Freq')\n",
    "    plt.semilogy(freqs[:len(freqs)//2], high_freq_fft[:len(freqs)//2], label='High Freq')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Power')\n",
    "    plt.title(f'Sample {i+1} - パワースペクトラム')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 復元誤差\n",
    "    plt.subplot(5, 6, i*6 + 6)\n",
    "    reconstructed = decomposer.reconstruct(low_freq[i:i+1], high_freq[i:i+1])\n",
    "    error = torch.abs(sample_trajectories[i] - reconstructed[0])\n",
    "    plt.plot(error[:, 0], label='X Error')\n",
    "    plt.plot(error[:, 1], label='Y Error')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Reconstruction Error')\n",
    "    plt.title(f'Sample {i+1} - 復元誤差')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.suptitle('データ分解の詳細分析', fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. モデルの初期化と設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# デバイスの設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用デバイス: {device}\")\n",
    "\n",
    "# ハイブリッドモデルの初期化\n",
    "model = HybridTrajectoryModel(\n",
    "    input_dim=2,  # x, y座標\n",
    "    condition_dim=3,  # 動作時間、終点誤差、ジャーク\n",
    "    lstm_hidden_dim=128,\n",
    "    lstm_num_layers=2,\n",
    "    diffusion_hidden_dim=256,\n",
    "    diffusion_num_layers=4,\n",
    "    moving_average_window=10,\n",
    "    num_diffusion_steps=1000\n",
    ").to(device)\n",
    "\n",
    "# モデル情報を表示\n",
    "model_info = model.get_model_info()\n",
    "print(\"\\nモデル情報:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"  {key}: {value:,}\" if isinstance(value, int) else f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# データローダーの準備\n",
    "trajectories_tensor = torch.tensor(trajectories, dtype=torch.float32)\n",
    "conditions_tensor = torch.tensor(conditions, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(trajectories_tensor, conditions_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "# オプティマイザーとスケジューラーの設定\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200, eta_min=1e-6)\n",
    "\n",
    "print(f\"データセットサイズ: {len(dataset)}\")\n",
    "print(f\"バッチ数: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 学習ループ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 学習履歴を記録するリスト\n",
    "train_losses = []\n",
    "low_freq_losses = []\n",
    "high_freq_losses = []\n",
    "learning_rates = []\n",
    "\n",
    "# 学習パラメータ\n",
    "num_epochs = 100\n",
    "log_interval = 10\n",
    "save_interval = 20\n",
    "\n",
    "# 出力ディレクトリの作成\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('outputs/checkpoints', exist_ok=True)\n",
    "os.makedirs('outputs/generated_trajectories', exist_ok=True)\n",
    "\n",
    "print(\"学習開始...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses = []\n",
    "    epoch_low_freq_losses = []\n",
    "    epoch_high_freq_losses = []\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "    \n",
    "    for batch_idx, (batch_trajectories, batch_conditions) in enumerate(progress_bar):\n",
    "        batch_trajectories = batch_trajectories.to(device)\n",
    "        batch_conditions = batch_conditions.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 順方向計算\n",
    "        outputs = model(batch_trajectories, batch_conditions)\n",
    "        \n",
    "        # 損失を取得\n",
    "        total_loss = outputs['total_loss']\n",
    "        low_freq_loss = outputs['low_freq_loss']\n",
    "        high_freq_loss = outputs['high_freq_loss']\n",
    "        \n",
    "        # バックプロパゲーション\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 損失を記録\n",
    "        epoch_losses.append(total_loss.item())\n",
    "        epoch_low_freq_losses.append(low_freq_loss.item())\n",
    "        epoch_high_freq_losses.append(high_freq_loss.item())\n",
    "        \n",
    "        # プログレスバーを更新\n",
    "        progress_bar.set_postfix({\n",
    "            'Total Loss': f'{total_loss.item():.4f}',\n",
    "            'Low Freq': f'{low_freq_loss.item():.4f}',\n",
    "            'High Freq': f'{high_freq_loss.item():.4f}',\n",
    "            'LR': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "        })\n",
    "    \n",
    "    # エポック終了時の処理\n",
    "    avg_loss = np.mean(epoch_losses)\n",
    "    avg_low_freq_loss = np.mean(epoch_low_freq_losses)\n",
    "    avg_high_freq_loss = np.mean(epoch_high_freq_losses)\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    \n",
    "    train_losses.append(avg_loss)\n",
    "    low_freq_losses.append(avg_low_freq_loss)\n",
    "    high_freq_losses.append(avg_high_freq_loss)\n",
    "    learning_rates.append(current_lr)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # ログ出力\n",
    "    if (epoch + 1) % log_interval == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Average Total Loss: {avg_loss:.6f}\")\n",
    "        print(f\"  Average Low Freq Loss: {avg_low_freq_loss:.6f}\")\n",
    "        print(f\"  Average High Freq Loss: {avg_high_freq_loss:.6f}\")\n",
    "        print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "    \n",
    "    # モデル保存\n",
    "    if (epoch + 1) % save_interval == 0:\n",
    "        checkpoint_path = f'outputs/checkpoints/hybrid_model_epoch_{epoch+1}.pth'\n",
    "        model.save_model(checkpoint_path)\n",
    "        print(f\"  Model saved: {checkpoint_path}\")\n",
    "\n",
    "print(\"\\n学習完了!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 学習過程の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 学習曲線の可視化\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 損失曲線\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(train_losses, label='Total Loss', linewidth=2)\n",
    "plt.plot(low_freq_losses, label='Low Freq Loss', linewidth=2)\n",
    "plt.plot(high_freq_losses, label='High Freq Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('学習損失の推移')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "\n",
    "# 学習率の推移\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(learning_rates, linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('学習率の推移')\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "\n",
    "# 損失比率の推移\n",
    "plt.subplot(2, 3, 3)\n",
    "low_freq_ratio = np.array(low_freq_losses) / np.array(train_losses)\n",
    "high_freq_ratio = np.array(high_freq_losses) / np.array(train_losses)\n",
    "plt.plot(low_freq_ratio, label='Low Freq Ratio', linewidth=2)\n",
    "plt.plot(high_freq_ratio, label='High Freq Ratio', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Ratio')\n",
    "plt.title('損失成分比率の推移')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 損失の移動平均\n",
    "plt.subplot(2, 3, 4)\n",
    "window_size = 10\n",
    "if len(train_losses) >= window_size:\n",
    "    train_losses_smooth = np.convolve(train_losses, np.ones(window_size)/window_size, mode='valid')\n",
    "    low_freq_losses_smooth = np.convolve(low_freq_losses, np.ones(window_size)/window_size, mode='valid')\n",
    "    high_freq_losses_smooth = np.convolve(high_freq_losses, np.ones(window_size)/window_size, mode='valid')\n",
    "    \n",
    "    plt.plot(range(window_size-1, len(train_losses)), train_losses_smooth, label='Total Loss (Smooth)', linewidth=2)\n",
    "    plt.plot(range(window_size-1, len(low_freq_losses)), low_freq_losses_smooth, label='Low Freq (Smooth)', linewidth=2)\n",
    "    plt.plot(range(window_size-1, len(high_freq_losses)), high_freq_losses_smooth, label='High Freq (Smooth)', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (Smoothed)')\n",
    "plt.title('損失の移動平均')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.yscale('log')\n",
    "\n",
    "# 最後の数エポックの詳細\n",
    "plt.subplot(2, 3, 5)\n",
    "last_epochs = 20\n",
    "start_idx = max(0, len(train_losses) - last_epochs)\n",
    "plt.plot(range(start_idx, len(train_losses)), train_losses[start_idx:], 'o-', label='Total Loss', linewidth=2)\n",
    "plt.plot(range(start_idx, len(low_freq_losses)), low_freq_losses[start_idx:], 's-', label='Low Freq Loss', linewidth=2)\n",
    "plt.plot(range(start_idx, len(high_freq_losses)), high_freq_losses[start_idx:], '^-', label='High Freq Loss', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'最後の{last_epochs}エポック')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 収束性の分析\n",
    "plt.subplot(2, 3, 6)\n",
    "if len(train_losses) > 1:\n",
    "    loss_diff = np.diff(train_losses)\n",
    "    plt.plot(loss_diff, linewidth=2, alpha=0.7)\n",
    "    plt.axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Difference')\n",
    "plt.title('損失の変化量')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.suptitle('ハイブリッドモデル学習過程の詳細分析', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 学習統計の保存\n",
    "training_stats = {\n",
    "    'final_total_loss': float(train_losses[-1]),\n",
    "    'final_low_freq_loss': float(low_freq_losses[-1]),\n",
    "    'final_high_freq_loss': float(high_freq_losses[-1]),\n",
    "    'min_total_loss': float(min(train_losses)),\n",
    "    'epochs_trained': len(train_losses),\n",
    "    'model_info': model_info\n",
    "}\n",
    "\n",
    "with open('outputs/training_stats.json', 'w') as f:\n",
    "    json.dump(training_stats, f, indent=2)\n",
    "\n",
    "print(\"\\n最終学習統計:\")\n",
    "print(f\"  最終総損失: {training_stats['final_total_loss']:.6f}\")\n",
    "print(f\"  最終低周波損失: {training_stats['final_low_freq_loss']:.6f}\")\n",
    "print(f\"  最終高周波損失: {training_stats['final_high_freq_loss']:.6f}\")\n",
    "print(f\"  最小総損失: {training_stats['min_total_loss']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 生成結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 生成テスト\n",
    "model.eval()\n",
    "\n",
    "# テスト用の条件を準備\n",
    "test_conditions = conditions_tensor[:10].to(device)  # 最初の10個の条件を使用\n",
    "original_trajectories = trajectories_tensor[:10].to(device)\n",
    "\n",
    "# 軌道生成\n",
    "with torch.no_grad():\n",
    "    generated_trajectories = model.generate(\n",
    "        condition=test_conditions,\n",
    "        sequence_length=trajectories.shape[1],\n",
    "        num_samples=3  # 各条件に対して3つのサンプルを生成\n",
    "    )\n",
    "\n",
    "# CPUに移動\n",
    "generated_trajectories = generated_trajectories.cpu().numpy()\n",
    "test_conditions_cpu = test_conditions.cpu().numpy()\n",
    "original_trajectories_cpu = original_trajectories.cpu().numpy()\n",
    "\n",
    "print(f\"生成された軌道の形状: {generated_trajectories.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 生成結果の詳細可視化\n",
    "plt.figure(figsize=(20, 15))\n",
    "\n",
    "num_test_samples = min(5, len(test_conditions_cpu))\n",
    "condition_names = ['動作時間', '終点誤差', 'ジャーク']\n",
    "\n",
    "for i in range(num_test_samples):\n",
    "    # 元の軌道と生成された軌道の比較（軌道平面）\n",
    "    plt.subplot(num_test_samples, 4, i*4 + 1)\n",
    "    plt.plot(original_trajectories_cpu[i, :, 0], original_trajectories_cpu[i, :, 1], \n",
    "             'k-', linewidth=3, label='Original', alpha=0.8)\n",
    "    \n",
    "    # 生成された3つのサンプルを表示\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        plt.plot(generated_trajectories[gen_idx, :, 0], generated_trajectories[gen_idx, :, 1], \n",
    "                '--', linewidth=2, alpha=0.7, label=f'Generated {j+1}')\n",
    "    \n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.title(f'条件 {i+1}: 軌道比較')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    # X軸の時系列比較\n",
    "    plt.subplot(num_test_samples, 4, i*4 + 2)\n",
    "    plt.plot(original_trajectories_cpu[i, :, 0], 'k-', linewidth=3, label='Original')\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        plt.plot(generated_trajectories[gen_idx, :, 0], '--', linewidth=2, alpha=0.7, label=f'Generated {j+1}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('X Position')\n",
    "    plt.title(f'条件 {i+1}: X軸時系列')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Y軸の時系列比較\n",
    "    plt.subplot(num_test_samples, 4, i*4 + 3)\n",
    "    plt.plot(original_trajectories_cpu[i, :, 1], 'k-', linewidth=3, label='Original')\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        plt.plot(generated_trajectories[gen_idx, :, 1], '--', linewidth=2, alpha=0.7, label=f'Generated {j+1}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.title(f'条件 {i+1}: Y軸時系列')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 条件情報の表示\n",
    "    plt.subplot(num_test_samples, 4, i*4 + 4)\n",
    "    condition_values = test_conditions_cpu[i]\n",
    "    bars = plt.bar(condition_names, condition_values, alpha=0.7)\n",
    "    plt.ylabel('値')\n",
    "    plt.title(f'条件 {i+1}: パラメータ')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 各バーに値を表示\n",
    "    for bar, value in zip(bars, condition_values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('ハイブリッドモデル生成結果の詳細比較', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/generated_trajectories/generation_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 成分別分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 生成された軌道の成分分解分析\n",
    "sample_generated = torch.tensor(generated_trajectories[:15], dtype=torch.float32)  # 最初の5つの条件×3サンプル\n",
    "sample_original = torch.tensor(original_trajectories_cpu[:5], dtype=torch.float32)\n",
    "\n",
    "# 元データと生成データの分解\n",
    "original_low, original_high = decomposer.decompose(sample_original)\n",
    "generated_low, generated_high = decomposer.decompose(sample_generated)\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "\n",
    "for i in range(5):\n",
    "    # 低周波成分の比較\n",
    "    plt.subplot(5, 6, i*6 + 1)\n",
    "    plt.plot(original_low[i, :, 0], original_low[i, :, 1], 'k-', linewidth=3, label='Original Low', alpha=0.8)\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        plt.plot(generated_low[gen_idx, :, 0], generated_low[gen_idx, :, 1], \n",
    "                '--', linewidth=2, alpha=0.7, label=f'Generated Low {j+1}')\n",
    "    plt.xlabel('X Low Freq')\n",
    "    plt.ylabel('Y Low Freq')\n",
    "    plt.title(f'条件 {i+1}: 低周波成分')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    # 高周波成分の比較\n",
    "    plt.subplot(5, 6, i*6 + 2)\n",
    "    plt.plot(original_high[i, :, 0], original_high[i, :, 1], 'k-', linewidth=3, label='Original High', alpha=0.8)\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        plt.plot(generated_high[gen_idx, :, 0], generated_high[gen_idx, :, 1], \n",
    "                '--', linewidth=2, alpha=0.7, label=f'Generated High {j+1}')\n",
    "    plt.xlabel('X High Freq')\n",
    "    plt.ylabel('Y High Freq')\n",
    "    plt.title(f'条件 {i+1}: 高周波成分')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 低周波成分のX軸時系列\n",
    "    plt.subplot(5, 6, i*6 + 3)\n",
    "    plt.plot(original_low[i, :, 0], 'k-', linewidth=3, label='Original')\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        plt.plot(generated_low[gen_idx, :, 0], '--', linewidth=2, alpha=0.7, label=f'Gen {j+1}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('X Low Freq')\n",
    "    plt.title(f'条件 {i+1}: 低周波X')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 高周波成分のX軸時系列\n",
    "    plt.subplot(5, 6, i*6 + 4)\n",
    "    plt.plot(original_high[i, :, 0], 'k-', linewidth=3, label='Original')\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        plt.plot(generated_high[gen_idx, :, 0], '--', linewidth=2, alpha=0.7, label=f'Gen {j+1}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('X High Freq')\n",
    "    plt.title(f'条件 {i+1}: 高周波X')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 低周波成分の統計比較\n",
    "    plt.subplot(5, 6, i*6 + 5)\n",
    "    original_low_stats = [\n",
    "        torch.mean(original_low[i]).item(),\n",
    "        torch.std(original_low[i]).item(),\n",
    "        torch.max(original_low[i]).item() - torch.min(original_low[i]).item()\n",
    "    ]\n",
    "    \n",
    "    generated_low_stats = []\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        stats = [\n",
    "            torch.mean(generated_low[gen_idx]).item(),\n",
    "            torch.std(generated_low[gen_idx]).item(),\n",
    "            torch.max(generated_low[gen_idx]).item() - torch.min(generated_low[gen_idx]).item()\n",
    "        ]\n",
    "        generated_low_stats.append(stats)\n",
    "    \n",
    "    x_pos = np.arange(len(original_low_stats))\n",
    "    plt.bar(x_pos - 0.2, original_low_stats, 0.4, label='Original', alpha=0.8)\n",
    "    \n",
    "    gen_means = np.mean(generated_low_stats, axis=0)\n",
    "    gen_stds = np.std(generated_low_stats, axis=0)\n",
    "    plt.bar(x_pos + 0.2, gen_means, 0.4, yerr=gen_stds, label='Generated', alpha=0.8, capsize=5)\n",
    "    \n",
    "    plt.xticks(x_pos, ['Mean', 'Std', 'Range'])\n",
    "    plt.ylabel('値')\n",
    "    plt.title(f'条件 {i+1}: 低周波統計')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 高周波成分の統計比較\n",
    "    plt.subplot(5, 6, i*6 + 6)\n",
    "    original_high_stats = [\n",
    "        torch.mean(torch.abs(original_high[i])).item(),\n",
    "        torch.std(original_high[i]).item(),\n",
    "        torch.max(torch.abs(original_high[i])).item()\n",
    "    ]\n",
    "    \n",
    "    generated_high_stats = []\n",
    "    for j in range(3):\n",
    "        gen_idx = i * 3 + j\n",
    "        stats = [\n",
    "            torch.mean(torch.abs(generated_high[gen_idx])).item(),\n",
    "            torch.std(generated_high[gen_idx]).item(),\n",
    "            torch.max(torch.abs(generated_high[gen_idx])).item()\n",
    "        ]\n",
    "        generated_high_stats.append(stats)\n",
    "    \n",
    "    plt.bar(x_pos - 0.2, original_high_stats, 0.4, label='Original', alpha=0.8)\n",
    "    \n",
    "    gen_means = np.mean(generated_high_stats, axis=0)\n",
    "    gen_stds = np.std(generated_high_stats, axis=0)\n",
    "    plt.bar(x_pos + 0.2, gen_means, 0.4, yerr=gen_stds, label='Generated', alpha=0.8, capsize=5)\n",
    "    \n",
    "    plt.xticks(x_pos, ['Mean Abs', 'Std', 'Max Abs'])\n",
    "    plt.ylabel('値')\n",
    "    plt.title(f'条件 {i+1}: 高周波統計')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('成分別詳細分析: 低周波（LSTM）と高周波（拡散モデル）', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/generated_trajectories/component_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 最終モデル保存と結果サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 最終モデルの保存\n",
    "final_model_path = 'outputs/hybrid_model_final.pth'\n",
    "model.save_model(final_model_path)\n",
    "print(f\"最終モデルを保存しました: {final_model_path}\")\n",
    "\n",
    "# 生成結果の保存\n",
    "np.save('outputs/generated_trajectories/generated_trajectories.npy', generated_trajectories)\n",
    "np.save('outputs/generated_trajectories/test_conditions.npy', test_conditions_cpu)\n",
    "np.save('outputs/generated_trajectories/original_trajectories.npy', original_trajectories_cpu)\n",
    "\n",
    "# 最終結果サマリー\n",
    "final_summary = {\n",
    "    'model_type': 'HybridTrajectoryModel',\n",
    "    'components': {\n",
    "        'low_frequency': 'LSTM',\n",
    "        'high_frequency': 'Diffusion Model (MLP-based)'\n",
    "    },\n",
    "    'training_info': {\n",
    "        'epochs_trained': len(train_losses),\n",
    "        'final_total_loss': float(train_losses[-1]),\n",
    "        'final_low_freq_loss': float(low_freq_losses[-1]),\n",
    "        'final_high_freq_loss': float(high_freq_losses[-1]),\n",
    "        'min_total_loss': float(min(train_losses))\n",
    "    },\n",
    "    'model_architecture': model_info,\n",
    "    'data_info': {\n",
    "        'input_dim': 2,\n",
    "        'condition_dim': 3,\n",
    "        'sequence_length': trajectories.shape[1],\n",
    "        'num_samples': trajectories.shape[0]\n",
    "    },\n",
    "    'generation_test': {\n",
    "        'test_conditions': len(test_conditions_cpu),\n",
    "        'samples_per_condition': 3,\n",
    "        'total_generated': generated_trajectories.shape[0]\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "with open('outputs/final_summary.json', 'w') as f:\n",
    "    json.dump(final_summary, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n=== ハイブリッドモデル学習完了サマリー ===\")\n",
    "print(f\"モデル種類: {final_summary['model_type']}\")\n",
    "print(f\"構成要素:\")\n",
    "print(f\"  - 低周波成分: {final_summary['components']['low_frequency']}\")\n",
    "print(f\"  - 高周波成分: {final_summary['components']['high_frequency']}\")\n",
    "print(f\"\\n学習結果:\")\n",
    "print(f\"  - 学習エポック数: {final_summary['training_info']['epochs_trained']}\")\n",
    "print(f\"  - 最終総損失: {final_summary['training_info']['final_total_loss']:.6f}\")\n",
    "print(f\"  - 最終低周波損失: {final_summary['training_info']['final_low_freq_loss']:.6f}\")\n",
    "print(f\"  - 最終高周波損失: {final_summary['training_info']['final_high_freq_loss']:.6f}\")\n",
    "print(f\"  - 最小総損失: {final_summary['training_info']['min_total_loss']:.6f}\")\n",
    "print(f\"\\nモデルパラメータ数:\")\n",
    "print(f\"  - 総パラメータ数: {model_info['total_parameters']:,}\")\n",
    "print(f\"  - 低周波モデル: {model_info['low_freq_parameters']:,}\")\n",
    "print(f\"  - 高周波モデル: {model_info['high_freq_parameters']:,}\")\n",
    "print(f\"\\n生成テスト:\")\n",
    "print(f\"  - テスト条件数: {final_summary['generation_test']['test_conditions']}\")\n",
    "print(f\"  - 条件あたりサンプル数: {final_summary['generation_test']['samples_per_condition']}\")\n",
    "print(f\"  - 総生成軌道数: {final_summary['generation_test']['total_generated']}\")\n",
    "print(\"\\n全てのファイルがoutputsディレクトリに保存されました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
