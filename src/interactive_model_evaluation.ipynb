{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–è»Œé“ç”Ÿæˆãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡\n",
    "\n",
    "ã“ã®Notebookã§ã¯å„ç¨®è»Œé“ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«è©•ä¾¡ã§ãã¾ã™ã€‚\n",
    "\n",
    "## æ©Ÿèƒ½\n",
    "- ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼‰\n",
    "- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šGUI\n",
    "- å­¦ç¿’å®Ÿè¡Œ\n",
    "- ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆæ¡ä»¶ãƒ™ã‚¯ãƒˆãƒ«æŒ‡å®š/ãƒ©ãƒ³ãƒ€ãƒ é¸æŠï¼‰\n",
    "- è»Œé“å¯è¦–åŒ–ï¼ˆå®Ÿè»Œé“vsç”Ÿæˆè»Œé“ï¼‰\n",
    "- èª¤å·®è¨ˆç®—ãƒ»è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /app\n",
      "Current path added: /app\n"
     ]
    }
   ],
   "source": [
    "# CLAUDE_ADDED\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import subprocess\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆsrcï¼‰ã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "current_path = Path('.').absolute()\n",
    "if str(current_path) not in sys.path:\n",
    "    sys.path.append(str(current_path))\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Current path added: {current_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelEvaluator initialized\n"
     ]
    }
   ],
   "source": [
    "# CLAUDE_ADDED\n",
    "class ModelEvaluator:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'DiffWave': 'DiffWave',\n",
    "            'HybridModel': 'HybridModel', \n",
    "            'HybridTransformer': 'HybridTransformer',\n",
    "            'Transformer': 'Transformer',\n",
    "            'UNet': 'UNet'\n",
    "        }\n",
    "        self.selected_model = None\n",
    "        self.config = None\n",
    "        self.dataset = None\n",
    "        \n",
    "    def load_config(self, model_name):\n",
    "        \"\"\"æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®config.yamlã‚’èª­ã¿è¾¼ã¿\"\"\"\n",
    "        config_path = Path(self.models[model_name]) / 'config.yaml'\n",
    "        if config_path.exists():\n",
    "            with open(config_path, 'r', encoding='utf-8') as f:\n",
    "                self.config = yaml.safe_load(f)\n",
    "            return self.config\n",
    "        else:\n",
    "            print(f\"Config file not found: {config_path}\")\n",
    "            return None\n",
    "    \n",
    "    def load_dataset(self, data_path=\"../data/Datasets/overfitting_dataset.npz\"):\n",
    "        \"\"\"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿\"\"\"\n",
    "        if Path(data_path).exists():\n",
    "            self.dataset = np.load(data_path)\n",
    "            print(f\"Dataset loaded: {list(self.dataset.keys())}\")\n",
    "            return self.dataset\n",
    "        else:\n",
    "            print(f\"Dataset not found: {data_path}\")\n",
    "            return None\n",
    "    \n",
    "    def get_available_checkpoints(self, model_name):\n",
    "        \"\"\"åˆ©ç”¨å¯èƒ½ãªãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—\"\"\"\n",
    "        model_dir = Path(self.models[model_name])\n",
    "        checkpoint_patterns = [\n",
    "            model_dir / \"outputs\" / \"checkpoints\" / \"*.pth\",\n",
    "            model_dir / \"checkpoints\" / \"*.pth\",\n",
    "            Path(\"checkpoints\") / \"*.pth\",\n",
    "            Path(\"outputs/checkpoints\") / \"*.pth\"\n",
    "        ]\n",
    "        \n",
    "        checkpoints = []\n",
    "        for pattern in checkpoint_patterns:\n",
    "            checkpoints.extend(glob.glob(str(pattern)))\n",
    "        \n",
    "        return sorted(list(set(checkpoints)))\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "print(\"ModelEvaluator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ãƒ¢ãƒ‡ãƒ«é¸æŠã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4fe6f349554213b0e4af028ba8fbf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ãƒ¢ãƒ‡ãƒ«é¸æŠ</h3>'), Dropdown(description='ãƒ¢ãƒ‡ãƒ«:', options=('DiffWave', 'HybridModel', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ãƒ¢ãƒ‡ãƒ«é¸æŠUI\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=list(evaluator.models.keys()),\n",
    "    value='DiffWave',\n",
    "    description='ãƒ¢ãƒ‡ãƒ«:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "config_output = widgets.Output()\n",
    "\n",
    "def on_model_change(change):\n",
    "    with config_output:\n",
    "        clear_output(wait=True)\n",
    "        evaluator.selected_model = change['new']\n",
    "        config = evaluator.load_config(change['new'])\n",
    "        if config:\n",
    "            print(f\"âœ“ {change['new']} config loaded\")\n",
    "            create_hyperparameter_widgets(config)\n",
    "        else:\n",
    "            print(f\"âœ— Failed to load {change['new']} config\")\n",
    "\n",
    "model_dropdown.observe(on_model_change, names='value')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>ãƒ¢ãƒ‡ãƒ«é¸æŠ</h3>\"),\n",
    "    model_dropdown,\n",
    "    config_output\n",
    "]))\n",
    "\n",
    "# åˆæœŸè¨­å®š\n",
    "on_model_change({'new': model_dropdown.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49dc4379f455460784162bc365ceaf97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆé–¢æ•°\n",
    "hyperparameter_widgets = {}\n",
    "hyperparameter_container = widgets.VBox()\n",
    "\n",
    "def create_hyperparameter_widgets(config):\n",
    "    \"\"\"è¨­å®šã«åŸºã¥ã„ã¦ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’å‹•çš„ç”Ÿæˆ\"\"\"\n",
    "    global hyperparameter_widgets\n",
    "    hyperparameter_widgets.clear()\n",
    "    \n",
    "    widgets_list = [widgets.HTML(\"<h3>ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š</h3>\")]\n",
    "    \n",
    "    # å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    if 'training' in config:\n",
    "        training_config = config['training']\n",
    "        \n",
    "        hyperparameter_widgets['batch_size'] = widgets.IntSlider(\n",
    "            value=training_config.get('batch_size', 32),\n",
    "            min=8, max=128, step=8,\n",
    "            description='Batch Size:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        hyperparameter_widgets['learning_rate'] = widgets.FloatLogSlider(\n",
    "            value=training_config.get('learning_rate', 1e-4),\n",
    "            base=10, min=-6, max=-2,\n",
    "            description='Learning Rate:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        epochs_key = 'epochs' if 'epochs' in training_config else 'num_epochs'\n",
    "        hyperparameter_widgets['epochs'] = widgets.IntSlider(\n",
    "            value=training_config.get(epochs_key, 100),\n",
    "            min=10, max=500, step=10,\n",
    "            description='Epochs:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        widgets_list.extend([\n",
    "            hyperparameter_widgets['batch_size'],\n",
    "            hyperparameter_widgets['learning_rate'],\n",
    "            hyperparameter_widgets['epochs']\n",
    "        ])\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«å›ºæœ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "    if 'model' in config:\n",
    "        model_config = config['model']\n",
    "        \n",
    "        # DiffWaveå›ºæœ‰\n",
    "        if evaluator.selected_model == 'DiffWave':\n",
    "            hyperparameter_widgets['residual_channels'] = widgets.IntSlider(\n",
    "                value=model_config.get('residual_channels', 64),\n",
    "                min=32, max=256, step=32,\n",
    "                description='Residual Channels:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            hyperparameter_widgets['num_layers'] = widgets.IntSlider(\n",
    "                value=model_config.get('num_layers', 20),\n",
    "                min=10, max=50, step=5,\n",
    "                description='Num Layers:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            widgets_list.extend([\n",
    "                hyperparameter_widgets['residual_channels'],\n",
    "                hyperparameter_widgets['num_layers']\n",
    "            ])\n",
    "        \n",
    "        # Transformerå›ºæœ‰\n",
    "        elif evaluator.selected_model == 'Transformer':\n",
    "            hyperparameter_widgets['d_model'] = widgets.IntSlider(\n",
    "                value=model_config.get('d_model', 256),\n",
    "                min=128, max=512, step=64,\n",
    "                description='D Model:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            hyperparameter_widgets['nhead'] = widgets.IntSlider(\n",
    "                value=model_config.get('nhead', 8),\n",
    "                min=4, max=16, step=2,\n",
    "                description='Num Heads:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            widgets_list.extend([\n",
    "                hyperparameter_widgets['d_model'],\n",
    "                hyperparameter_widgets['nhead']\n",
    "            ])\n",
    "        \n",
    "        # Hybridç³»ãƒ¢ãƒ‡ãƒ«\n",
    "        elif 'Hybrid' in evaluator.selected_model:\n",
    "            hyperparameter_widgets['lstm_hidden_dim'] = widgets.IntSlider(\n",
    "                value=model_config.get('lstm_hidden_dim', 128),\n",
    "                min=64, max=256, step=32,\n",
    "                description='LSTM Hidden Dim:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            hyperparameter_widgets['diffusion_hidden_dim'] = widgets.IntSlider(\n",
    "                value=model_config.get('diffusion_hidden_dim', 256),\n",
    "                min=128, max=512, step=64,\n",
    "                description='Diffusion Hidden Dim:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            widgets_list.extend([\n",
    "                hyperparameter_widgets['lstm_hidden_dim'],\n",
    "                hyperparameter_widgets['diffusion_hidden_dim']\n",
    "            ])\n",
    "        \n",
    "        # UNetå›ºæœ‰\n",
    "        elif evaluator.selected_model == 'UNet':\n",
    "            hyperparameter_widgets['base_channels'] = widgets.IntSlider(\n",
    "                value=model_config.get('base_channels', 128),\n",
    "                min=64, max=256, step=32,\n",
    "                description='Base Channels:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            widgets_list.append(hyperparameter_widgets['base_channels'])\n",
    "    \n",
    "    # æ›´æ–°ãƒœã‚¿ãƒ³\n",
    "    update_config_btn = widgets.Button(\n",
    "        description='è¨­å®šã‚’é©ç”¨',\n",
    "        button_style='success',\n",
    "        icon='check'\n",
    "    )\n",
    "    \n",
    "    def on_update_config(b):\n",
    "        update_config_from_widgets()\n",
    "        print(\"âœ“ è¨­å®šãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ\")\n",
    "    \n",
    "    update_config_btn.on_click(on_update_config)\n",
    "    widgets_list.append(update_config_btn)\n",
    "    \n",
    "    hyperparameter_container.children = widgets_list\n",
    "\n",
    "def update_config_from_widgets():\n",
    "    \"\"\"ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®å€¤ã‹ã‚‰è¨­å®šã‚’æ›´æ–°\"\"\"\n",
    "    if evaluator.config is None:\n",
    "        return\n",
    "    \n",
    "    # è¨“ç·´è¨­å®šã®æ›´æ–°\n",
    "    if 'training' in evaluator.config:\n",
    "        if 'batch_size' in hyperparameter_widgets:\n",
    "            evaluator.config['training']['batch_size'] = hyperparameter_widgets['batch_size'].value\n",
    "        if 'learning_rate' in hyperparameter_widgets:\n",
    "            evaluator.config['training']['learning_rate'] = hyperparameter_widgets['learning_rate'].value\n",
    "        if 'epochs' in hyperparameter_widgets:\n",
    "            epochs_key = 'epochs' if 'epochs' in evaluator.config['training'] else 'num_epochs'\n",
    "            evaluator.config['training'][epochs_key] = hyperparameter_widgets['epochs'].value\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«è¨­å®šã®æ›´æ–°\n",
    "    if 'model' in evaluator.config:\n",
    "        for key, widget in hyperparameter_widgets.items():\n",
    "            if key in ['batch_size', 'learning_rate', 'epochs']:\n",
    "                continue\n",
    "            if key in evaluator.config['model']:\n",
    "                evaluator.config['model'][key] = widget.value\n",
    "\n",
    "display(hyperparameter_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å­¦ç¿’æ©Ÿèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b882678a38c438c83e0ee764f704ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>å­¦ç¿’å®Ÿè¡Œ</h3>'), Button(button_style='primary', description='å­¦ç¿’å®Ÿè¡Œ', icon='play', stâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CLAUDE_ADDED\n",
    "training_output = widgets.Output()\n",
    "\n",
    "def run_training():\n",
    "    \"\"\"é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’ã‚’å®Ÿè¡Œ\"\"\"\n",
    "    if evaluator.selected_model is None or evaluator.config is None:\n",
    "        print(\"ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯è¨­å®šãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "        return\n",
    "    \n",
    "    with training_output:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"ğŸš€ {evaluator.selected_model} ã®å­¦ç¿’ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "        \n",
    "        # è¨­å®šã‚’æ›´æ–°\n",
    "        update_config_from_widgets()\n",
    "        \n",
    "        # ä¸€æ™‚çš„ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ\n",
    "        model_dir = evaluator.models[evaluator.selected_model]\n",
    "        temp_config_path = Path(model_dir) / 'temp_config.yaml'\n",
    "        \n",
    "        with open(temp_config_path, 'w', encoding='utf-8') as f:\n",
    "            yaml.dump(evaluator.config, f, default_flow_style=False, allow_unicode=True)\n",
    "        \n",
    "        try:\n",
    "            # å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ\n",
    "            train_script = Path(model_dir) / 'train.py'\n",
    "            \n",
    "            if train_script.exists():\n",
    "                cmd = f\"cd {model_dir} && python train.py\"\n",
    "                print(f\"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {cmd}\")\n",
    "                print(\"å­¦ç¿’ä¸­... (ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„)\")\n",
    "                \n",
    "                # subprocess ã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’ã‚’å®Ÿè¡Œ\n",
    "                result = subprocess.run(\n",
    "                    cmd, \n",
    "                    shell=True, \n",
    "                    capture_output=True, \n",
    "                    text=True, \n",
    "                    cwd=os.getcwd()\n",
    "                )\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    print(\"âœ“ å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼\")\n",
    "                    if result.stdout:\n",
    "                        print(\"å‡ºåŠ›:\")\n",
    "                        print(result.stdout[-1000:])  # æœ€å¾Œã®1000æ–‡å­—ã®ã¿è¡¨ç¤º\n",
    "                else:\n",
    "                    print(f\"âœ— å­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode})\")\n",
    "                    print(\"ã‚¨ãƒ©ãƒ¼å‡ºåŠ›:\")\n",
    "                    print(result.stderr)\n",
    "            else:\n",
    "                print(f\"âœ— å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {train_script}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— å­¦ç¿’å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\")\n",
    "        \n",
    "        finally:\n",
    "            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "            if temp_config_path.exists():\n",
    "                temp_config_path.unlink()\n",
    "\n",
    "# å­¦ç¿’ãƒœã‚¿ãƒ³\n",
    "train_button = widgets.Button(\n",
    "    description='å­¦ç¿’å®Ÿè¡Œ',\n",
    "    button_style='primary',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "train_button.on_click(lambda b: run_training())\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>å­¦ç¿’å®Ÿè¡Œ</h3>\"),\n",
    "    train_button,\n",
    "    training_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ»å¯è¦–åŒ–æ©Ÿèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e658744d580f4f52b07500a5c0c27651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿</h3>'), Text(value='../data/Datasets/overfitting_dataset.npz', descrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "dataset_path_widget = widgets.Text(\n",
    "    value=\"../data/Datasets/overfitting_dataset.npz\",\n",
    "    description='ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "load_data_button = widgets.Button(\n",
    "    description='ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿',\n",
    "    button_style='info',\n",
    "    icon='download'\n",
    ")\n",
    "\n",
    "data_info_output = widgets.Output()\n",
    "\n",
    "def load_dataset_handler(b):\n",
    "    with data_info_output:\n",
    "        clear_output(wait=True)\n",
    "        dataset = evaluator.load_dataset(dataset_path_widget.value)\n",
    "        if dataset is not None:\n",
    "            print(f\"âœ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿å®Œäº†\")\n",
    "            print(f\"ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹: {list(dataset.keys())}\")\n",
    "            \n",
    "            # ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ã‚’è¡¨ç¤º\n",
    "            for key in dataset.keys():\n",
    "                print(f\"{key}: {dataset[key].shape}\")\n",
    "        else:\n",
    "            print(\"âœ— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
    "\n",
    "load_data_button.on_click(load_dataset_handler)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿</h3>\"),\n",
    "    dataset_path_widget,\n",
    "    load_data_button,\n",
    "    data_info_output\n",
    "]))\n",
    "\n",
    "# åˆæœŸãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "load_dataset_handler(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125f0b2ba76341af8d4a8c883f8d1ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>è»Œé“ç”Ÿæˆãƒ»å¯è¦–åŒ–</h3>'), HBox(children=(Dropdown(description='ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:', options=(), sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆé¸æŠã¨ç”Ÿæˆæ©Ÿèƒ½\n",
    "checkpoint_dropdown = widgets.Dropdown(\n",
    "    options=[],\n",
    "    description='ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "refresh_checkpoints_btn = widgets.Button(\n",
    "    description='ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ›´æ–°',\n",
    "    button_style='info',\n",
    "    icon='refresh'\n",
    ")\n",
    "\n",
    "def refresh_checkpoints(b):\n",
    "    if evaluator.selected_model:\n",
    "        checkpoints = evaluator.get_available_checkpoints(evaluator.selected_model)\n",
    "        checkpoint_dropdown.options = checkpoints\n",
    "        print(f\"âœ“ {len(checkpoints)}å€‹ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ\")\n",
    "    else:\n",
    "        print(\"ãƒ¢ãƒ‡ãƒ«ã‚’å…ˆã«é¸æŠã—ã¦ãã ã•ã„\")\n",
    "\n",
    "refresh_checkpoints_btn.on_click(refresh_checkpoints)\n",
    "\n",
    "# ç”Ÿæˆè¨­å®š - HybridTransformerã®train.pyã«åˆã‚ã›ã¦èª¿æ•´\n",
    "num_samples_widget = widgets.IntSlider(\n",
    "    value=9,  # train.pyã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«åˆã‚ã›ã‚‹\n",
    "    min=1, max=20, step=1,\n",
    "    description='ç”Ÿæˆã‚µãƒ³ãƒ—ãƒ«æ•°:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "condition_mode = widgets.RadioButtons(\n",
    "    options=['ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ', 'æ¡ä»¶æŒ‡å®š'],\n",
    "    value='ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ',\n",
    "    description='æ¡ä»¶è¨­å®š:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# æ¡ä»¶æŒ‡å®šç”¨ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆï¼ˆ5æ¬¡å…ƒã®æ¡ä»¶ãƒ™ã‚¯ãƒˆãƒ«ï¼‰\n",
    "condition_widgets = []\n",
    "for i in range(5):\n",
    "    widget = widgets.FloatSlider(\n",
    "        value=0.0,\n",
    "        min=-3.0, max=3.0, step=0.1,\n",
    "        description=f'æ¡ä»¶{i+1}:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    condition_widgets.append(widget)\n",
    "\n",
    "condition_container = widgets.VBox(condition_widgets)\n",
    "\n",
    "def on_condition_mode_change(change):\n",
    "    if change['new'] == 'æ¡ä»¶æŒ‡å®š':\n",
    "        condition_container.layout.display = 'block'\n",
    "    else:\n",
    "        condition_container.layout.display = 'none'\n",
    "\n",
    "condition_mode.observe(on_condition_mode_change, names='value')\n",
    "condition_container.layout.display = 'none'  # åˆæœŸã¯éè¡¨ç¤º\n",
    "\n",
    "# ç”Ÿæˆãƒ»å¯è¦–åŒ–\n",
    "generate_button = widgets.Button(\n",
    "    description='è»Œé“ç”Ÿæˆãƒ»å¯è¦–åŒ–',\n",
    "    button_style='success',\n",
    "    icon='chart-line'\n",
    ")\n",
    "\n",
    "generation_output = widgets.Output()\n",
    "\n",
    "def get_generate_command(model_name, checkpoint_path, conditions_path, num_samples):\n",
    "    \"\"\"ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ç”Ÿæˆã‚³ãƒãƒ³ãƒ‰ã‚’å–å¾—\"\"\"\n",
    "    model_dir = evaluator.models[model_name]\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹ã‚’ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã«å¤‰æ›\n",
    "    checkpoint_path_obj = Path(checkpoint_path)\n",
    "    model_dir_path = Path(model_dir)\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹ãŒãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å«ã‚€å ´åˆã€ãã‚Œä»¥é™ã®éƒ¨åˆ†ã‚’å–å¾—\n",
    "    if model_dir in str(checkpoint_path):\n",
    "        # \"HybridTransformer/outputs/checkpoints/file.pth\" -> \"outputs/checkpoints/file.pth\"\n",
    "        relative_path = str(checkpoint_path).split(model_dir + \"/\", 1)[-1]\n",
    "    else:\n",
    "        # çµ¶å¯¾ãƒ‘ã‚¹ã®å ´åˆã€ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã‚’è¨ˆç®—\n",
    "        try:\n",
    "            abs_checkpoint = checkpoint_path_obj.absolute()\n",
    "            abs_model_dir = model_dir_path.absolute()\n",
    "            relative_path = abs_checkpoint.relative_to(abs_model_dir)\n",
    "        except ValueError:\n",
    "            # ç›¸å¯¾ãƒ‘ã‚¹è¨ˆç®—ã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨\n",
    "            relative_path = checkpoint_path\n",
    "    \n",
    "    if model_name == 'DiffWave':\n",
    "        cmd = f\"cd {model_dir} && python generate.py --checkpoint {relative_path} --batch_size {num_samples} --use_dummy\"\n",
    "    elif model_name in ['HybridModel', 'HybridTransformer']:\n",
    "        # HybridTransformerã®å ´åˆã€train.pyã®generate_samplesã¨åŒã˜æ–¹å¼ã‚’ä½¿ç”¨\n",
    "        cmd = f\"cd {model_dir} && python train.py --mode generate --model_path {relative_path} --num_samples {num_samples}\"\n",
    "    elif model_name == 'Transformer':\n",
    "        cmd = f\"cd {model_dir} && python generate.py --checkpoint {relative_path} --num_samples {num_samples}\"\n",
    "    elif model_name == 'UNet':\n",
    "        cmd = f\"cd {model_dir} && python generate.py --checkpoint {relative_path} --batch_size {num_samples}\"\n",
    "    else:\n",
    "        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ\n",
    "        cmd = f\"cd {model_dir} && python generate.py --checkpoint {relative_path}\"\n",
    "    \n",
    "    return cmd\n",
    "\n",
    "def generate_and_visualize(b):\n",
    "    with generation_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if evaluator.selected_model is None:\n",
    "            print(\"ãƒ¢ãƒ‡ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "            return\n",
    "        \n",
    "        if not checkpoint_dropdown.value:\n",
    "            print(\"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "            return\n",
    "        \n",
    "        if evaluator.dataset is None:\n",
    "            print(\"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸ¯ {evaluator.selected_model} ã§è»Œé“ç”Ÿæˆã‚’é–‹å§‹...\")\n",
    "        print(f\"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {checkpoint_dropdown.value}\")\n",
    "        \n",
    "        # ãƒ‘ã‚¹è§£æã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±\n",
    "        checkpoint_path = checkpoint_dropdown.value\n",
    "        model_dir = evaluator.models[evaluator.selected_model]\n",
    "        print(f\"ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {model_dir}\")\n",
    "        \n",
    "        if model_dir in str(checkpoint_path):\n",
    "            relative_path = str(checkpoint_path).split(model_dir + \"/\", 1)[-1]\n",
    "            print(f\"å¤‰æ›å¾Œã®ç›¸å¯¾ãƒ‘ã‚¹: {relative_path}\")\n",
    "        else:\n",
    "            print(f\"ãƒ‘ã‚¹å¤‰æ›ãŒå¿…è¦: {checkpoint_path}\")\n",
    "        \n",
    "        try:\n",
    "            # ç”Ÿæˆç”¨ã®æ¡ä»¶ãƒ™ã‚¯ãƒˆãƒ«ã‚’æº–å‚™\n",
    "            if condition_mode.value == 'ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ':\n",
    "                # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«æ¡ä»¶ã‚’é¸æŠ\n",
    "                if 'conditions' in evaluator.dataset:\n",
    "                    conditions = evaluator.dataset['conditions']\n",
    "                    indices = np.random.choice(len(conditions), num_samples_widget.value, replace=False)\n",
    "                    selected_conditions = conditions[indices]\n",
    "                    selected_trajectories = evaluator.dataset['trajectories'][indices]\n",
    "                else:\n",
    "                    print(\"ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«æ¡ä»¶æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“\")\n",
    "                    return\n",
    "            else:\n",
    "                # æ‰‹å‹•ã§æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã‚’ä½¿ç”¨\n",
    "                condition_vector = np.array([w.value for w in condition_widgets])\n",
    "                selected_conditions = np.tile(condition_vector, (num_samples_widget.value, 1))\n",
    "                \n",
    "                # æœ€ã‚‚è¿‘ã„å®Ÿè»Œé“ã‚’æ¤œç´¢ï¼ˆæ¯”è¼ƒç”¨ï¼‰\n",
    "                if 'conditions' in evaluator.dataset:\n",
    "                    distances = np.linalg.norm(evaluator.dataset['conditions'] - condition_vector, axis=1)\n",
    "                    closest_indices = np.argsort(distances)[:num_samples_widget.value]\n",
    "                    selected_trajectories = evaluator.dataset['trajectories'][closest_indices]\n",
    "                else:\n",
    "                    selected_trajectories = None\n",
    "            \n",
    "            # ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ\n",
    "            model_dir = evaluator.models[evaluator.selected_model]\n",
    "            \n",
    "            # HybridTransformerã®å ´åˆã¯train.pyã®generate_samplesé–¢æ•°ã‚’ä½¿ç”¨\n",
    "            if evaluator.selected_model in ['HybridModel', 'HybridTransformer']:\n",
    "                # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ\n",
    "                cmd = get_generate_command(\n",
    "                    evaluator.selected_model, \n",
    "                    checkpoint_dropdown.value, \n",
    "                    None,  # æ¡ä»¶ãƒ‘ã‚¹ã¯ä¸è¦ï¼ˆtrain.pyãŒå†…éƒ¨ã§å‡¦ç†ï¼‰\n",
    "                    num_samples_widget.value\n",
    "                )\n",
    "                \n",
    "                print(f\"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {cmd}\")\n",
    "                \n",
    "                result = subprocess.run(\n",
    "                    cmd,\n",
    "                    shell=True,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    cwd=os.getcwd()\n",
    "                )\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    print(\"âœ“ è»Œé“ç”Ÿæˆå®Œäº†ï¼\")\n",
    "                    if result.stdout:\n",
    "                        print(\"ç”Ÿæˆãƒ­ã‚°:\", result.stdout[-500:])  # æœ€å¾Œã®500æ–‡å­—\n",
    "                    \n",
    "                    # train.pyã§ç”Ÿæˆã•ã‚ŒãŸçµæœã‚’èª­ã¿è¾¼ã‚“ã§ã€notebookå†…ã§å¯è¦–åŒ–\n",
    "                    output_files = [\n",
    "                        f\"{model_dir}/outputs/generated_trajectories/generated_samples.npy\",\n",
    "                        f\"{model_dir}/outputs/generated_trajectories/sampled_conditions.npy\"\n",
    "                    ]\n",
    "                    \n",
    "                    print(\"ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "                    for file_path in output_files:\n",
    "                        if Path(file_path).exists():\n",
    "                            print(f\"  âœ“ {file_path}\")\n",
    "                        else:\n",
    "                            print(f\"  âœ— {file_path} (not found)\")\n",
    "                    \n",
    "                    # notebookå†…ã§å¯è¦–åŒ–ã‚’å®Ÿè¡Œ\n",
    "                    visualize_results(model_dir, selected_trajectories, selected_conditions)\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"âœ— ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode}):\")\n",
    "                    print(\"stderr:\", result.stderr)\n",
    "                    if result.stdout:\n",
    "                        print(\"stdout:\", result.stdout)\n",
    "            \n",
    "            else:\n",
    "                # ä»–ã®ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯å¾“æ¥ã®å‡¦ç†\n",
    "                generate_script = Path(model_dir) / 'generate.py'\n",
    "                \n",
    "                if generate_script.exists():\n",
    "                    # ç”Ÿæˆæ¡ä»¶ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
    "                    temp_conditions_path = Path(model_dir) / 'temp_conditions.npy'\n",
    "                    np.save(temp_conditions_path, selected_conditions)\n",
    "                    \n",
    "                    # ãƒ¢ãƒ‡ãƒ«åˆ¥ã®ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ\n",
    "                    cmd = get_generate_command(\n",
    "                        evaluator.selected_model, \n",
    "                        checkpoint_dropdown.value, \n",
    "                        str(temp_conditions_path),\n",
    "                        num_samples_widget.value\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {cmd}\")\n",
    "                    \n",
    "                    result = subprocess.run(\n",
    "                        cmd,\n",
    "                        shell=True,\n",
    "                        capture_output=True,\n",
    "                        text=True,\n",
    "                        cwd=os.getcwd()\n",
    "                    )\n",
    "                    \n",
    "                    if result.returncode == 0:\n",
    "                        print(\"âœ“ è»Œé“ç”Ÿæˆå®Œäº†ï¼\")\n",
    "                        if result.stdout:\n",
    "                            print(\"ç”Ÿæˆãƒ­ã‚°:\", result.stdout[-500:])  # æœ€å¾Œã®500æ–‡å­—\n",
    "                        \n",
    "                        # ç”Ÿæˆçµæœã‚’èª­ã¿è¾¼ã‚“ã§å¯è¦–åŒ–\n",
    "                        visualize_results(model_dir, selected_trajectories, selected_conditions)\n",
    "                        \n",
    "                    else:\n",
    "                        print(f\"âœ— ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode}):\")\n",
    "                        print(\"stderr:\", result.stderr)\n",
    "                        if result.stdout:\n",
    "                            print(\"stdout:\", result.stdout)\n",
    "                    \n",
    "                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
    "                    if temp_conditions_path.exists():\n",
    "                        temp_conditions_path.unlink()\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"âœ— ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {generate_script}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\")\n",
    "            import traceback\n",
    "            print(\"è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:\")\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "def visualize_results(model_dir, real_trajectories, conditions):\n",
    "    \"\"\"ç”Ÿæˆçµæœã¨å®Ÿè»Œé“ã‚’å¯è¦–åŒ– - notebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤º\"\"\"\n",
    "    # ç”Ÿæˆã•ã‚ŒãŸè»Œé“ã‚’èª­ã¿è¾¼ã¿ - HybridTransformerã®train.pyã«åˆã‚ã›ãŸãƒ‘ã‚¹å„ªå…ˆé †ä½\n",
    "    potential_patterns = [\n",
    "        # HybridTransformerã®train.pyã§ä½¿ç”¨ã•ã‚Œã‚‹ãƒ‘ã‚¹\n",
    "        f\"{model_dir}/outputs/generated_trajectories/generated_samples.npy\",\n",
    "        # ä»–ã®ãƒ¢ãƒ‡ãƒ«ç”¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "        f\"{model_dir}/generated_outputs/data/generated_trajectories.npy\",\n",
    "        f\"{model_dir}/outputs/generated_trajectories/*.npy\",\n",
    "        f\"{model_dir}/generated_outputs/**/*.npy\", \n",
    "        f\"{model_dir}/generated_*.npy\",\n",
    "        f\"{model_dir}/outputs/**/*.npy\"\n",
    "    ]\n",
    "    \n",
    "    generated_files = []\n",
    "    \n",
    "    for pattern in potential_patterns:\n",
    "        if '*' in pattern:\n",
    "            # Globãƒ‘ã‚¿ãƒ¼ãƒ³ã®å ´åˆ\n",
    "            files = list(Path('.').glob(pattern))\n",
    "        else:\n",
    "            # ç›´æ¥ãƒ‘ã‚¹ã®å ´åˆ\n",
    "            file_path = Path(pattern)\n",
    "            if file_path.exists():\n",
    "                files = [file_path]\n",
    "            else:\n",
    "                files = []\n",
    "        \n",
    "        generated_files.extend(files)\n",
    "        if files:  # ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã£ãŸã‚‰å„ªå…ˆçš„ã«ä½¿ç”¨\n",
    "            break\n",
    "    \n",
    "    if not generated_files:\n",
    "        print(\"ç”Ÿæˆã•ã‚ŒãŸè»Œé“ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "        print(\"æ¢ç´¢ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³:\")\n",
    "        for i, pattern in enumerate(potential_patterns):\n",
    "            print(f\"  {i+1}. {pattern}\")\n",
    "        \n",
    "        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹ã‚’ç¢ºèª\n",
    "        print(f\"\\n{model_dir}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹:\")\n",
    "        try:\n",
    "            for item in Path(model_dir).rglob('*.npy'):\n",
    "                print(f\"  - {item}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ¢ç´¢ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return\n",
    "    \n",
    "    # æœ€æ–°ã®ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨\n",
    "    latest_file = max(generated_files, key=lambda x: x.stat().st_mtime)\n",
    "    \n",
    "    try:\n",
    "        generated_trajectories = np.load(latest_file)\n",
    "        print(f\"ç”Ÿæˆè»Œé“èª­ã¿è¾¼ã¿: {latest_file}\")\n",
    "        print(f\"ç”Ÿæˆè»Œé“å½¢çŠ¶: {generated_trajectories.shape}\")\n",
    "        \n",
    "        # æ¡ä»¶ãƒ‡ãƒ¼ã‚¿ã‚‚èª­ã¿è¾¼ã¿ï¼ˆHybridTransformerã®å ´åˆï¼‰\n",
    "        conditions_file = Path(f\"{model_dir}/outputs/generated_trajectories/sampled_conditions.npy\")\n",
    "        if conditions_file.exists():\n",
    "            sampled_conditions = np.load(conditions_file)\n",
    "            print(f\"æ¡ä»¶ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {conditions_file}\")\n",
    "            print(f\"æ¡ä»¶ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {sampled_conditions.shape}\")\n",
    "        else:\n",
    "            sampled_conditions = conditions\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã®æ¤œè¨¼ã¨ä¿®æ­£\n",
    "        if len(generated_trajectories.shape) == 2:\n",
    "            # 2æ¬¡å…ƒã®å ´åˆã€è»Œé“ãƒ‡ãƒ¼ã‚¿ã‹ã©ã†ã‹ç¢ºèª\n",
    "            if generated_trajectories.shape[1] == 2:\n",
    "                # (timesteps, coords) ã®å ´åˆ -> (1, timesteps, coords) ã«å¤‰æ›\n",
    "                generated_trajectories = generated_trajectories[np.newaxis, :, :]\n",
    "                print(f\"2æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã‚’1ã‚µãƒ³ãƒ—ãƒ«è»Œé“ã¨ã—ã¦è§£é‡ˆ: {generated_trajectories.shape}\")\n",
    "            elif generated_trajectories.shape[1] == 5:\n",
    "                # æ¡ä»¶ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼\n",
    "                print(\"âœ— è»Œé“ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªãæ¡ä»¶ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸ\")\n",
    "                return\n",
    "            else:\n",
    "                print(f\"âœ— äºˆæœŸã—ãªã„ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {generated_trajectories.shape}\")\n",
    "                return\n",
    "        elif len(generated_trajectories.shape) == 3:\n",
    "            # 3æ¬¡å…ƒã®å ´åˆã¯æ­£å¸¸\n",
    "            if generated_trajectories.shape[2] != 2:\n",
    "                print(f\"âœ— åº§æ¨™æ¬¡å…ƒãŒ2ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {generated_trajectories.shape}\")\n",
    "                return\n",
    "        else:\n",
    "            print(f\"âœ— ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ‡ãƒ¼ã‚¿æ¬¡å…ƒ: {generated_trajectories.shape}\")\n",
    "            return\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã®èª¿æ•´\n",
    "        if len(generated_trajectories.shape) == 3:\n",
    "            if generated_trajectories.shape[0] > generated_trajectories.shape[1] and generated_trajectories.shape[2] == 2:\n",
    "                # (timesteps, samples, coords) ã®å ´åˆ -> (samples, timesteps, coords)\n",
    "                generated_trajectories = generated_trajectories.transpose(1, 0, 2)\n",
    "                print(f\"è»¸ã‚’å…¥ã‚Œæ›¿ãˆ: {generated_trajectories.shape}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}\")\n",
    "        return\n",
    "    \n",
    "    # notebookå†…ã§HybridTransformerã®train.pyã‚¹ã‚¿ã‚¤ãƒ«ã®å¯è¦–åŒ–\n",
    "    # train.pyã§ã¯å„æ¡ä»¶ã«å¯¾ã—ã¦3ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆã™ã‚‹ã®ã§ã€ãã‚Œã«åˆã‚ã›ã‚‹\n",
    "    num_conditions = num_samples_widget.value\n",
    "    samples_per_condition = 3  # train.pyã«åˆã‚ã›ã¦å›ºå®š\n",
    "    \n",
    "    # å®Ÿéš›ã«ç”Ÿæˆã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’è¨ˆç®—\n",
    "    total_generated = len(generated_trajectories)\n",
    "    actual_conditions = min(num_conditions, total_generated // samples_per_condition)\n",
    "    \n",
    "    # train.pyã®ãƒ—ãƒ­ãƒƒãƒˆæ–¹å¼ã«åˆã‚ã›ã¦ã€æœ€å¤§9å€‹ã®æ¡ä»¶ã‚’3x3ã‚°ãƒªãƒƒãƒ‰ã§è¡¨ç¤º\n",
    "    max_display_samples = min(9, actual_conditions)\n",
    "    \n",
    "    if max_display_samples <= 6:\n",
    "        fig_rows, fig_cols = 2, 3\n",
    "    elif max_display_samples <= 9:\n",
    "        fig_rows, fig_cols = 3, 3\n",
    "    else:\n",
    "        fig_rows, fig_cols = 3, 3\n",
    "        max_display_samples = 9\n",
    "    \n",
    "    # notebookå†…ã§matplotlibã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º\n",
    "    plt.figure(figsize=(5*fig_cols, 4*fig_rows))\n",
    "    \n",
    "    for i in range(max_display_samples):\n",
    "        plt.subplot(fig_rows, fig_cols, i+1)\n",
    "        \n",
    "        # å…ƒã®è»Œé“ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰\n",
    "        if real_trajectories is not None and i < len(real_trajectories):\n",
    "            real_traj = real_trajectories[i]\n",
    "            plt.plot(real_traj[:, 0], real_traj[:, 1], \n",
    "                    'k-', linewidth=3, label='Original', alpha=0.8)\n",
    "        \n",
    "        # ç”Ÿæˆã•ã‚ŒãŸè»Œé“ (train.pyã‚¹ã‚¿ã‚¤ãƒ«: å„æ¡ä»¶ã«3ã¤ã®ã‚µãƒ³ãƒ—ãƒ«)\n",
    "        colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "        for j in range(samples_per_condition):\n",
    "            gen_idx = i * samples_per_condition + j\n",
    "            if gen_idx < len(generated_trajectories):\n",
    "                color = colors[j % len(colors)]\n",
    "                plt.plot(generated_trajectories[gen_idx, :, 0], generated_trajectories[gen_idx, :, 1],\n",
    "                        '-', color=color, linewidth=2, alpha=0.7, label=f'Generated {j+1}')\n",
    "        \n",
    "        plt.xlabel('X Position')\n",
    "        plt.ylabel('Y Position')\n",
    "        plt.title(f'Condition {i+1}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axis('equal')\n",
    "    \n",
    "    # train.pyã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚¿ã‚¤ãƒˆãƒ«\n",
    "    if num_conditions > max_display_samples:\n",
    "        plt.suptitle(f'Generation Results ({max_display_samples}/{num_conditions} samples displayed)', fontsize=16)\n",
    "    else:\n",
    "        plt.suptitle('Generation Results', fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()  # notebookå†…ã§ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º\n",
    "    \n",
    "    # è¿½åŠ ã§çµ±è¨ˆæƒ…å ±ã®ãƒ—ãƒ­ãƒƒãƒˆã‚‚è¡¨ç¤º\n",
    "    create_statistics_plot(generated_trajectories, real_trajectories, sampled_conditions, samples_per_condition)\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º\n",
    "    print(f\"\\nğŸ“Š Generation Statistics:\")\n",
    "    print(f\"  Total generated samples: {total_generated}\")\n",
    "    print(f\"  Conditions displayed: {max_display_samples}\")\n",
    "    print(f\"  Samples per condition: {samples_per_condition}\")\n",
    "    print(f\"  Trajectory length: {generated_trajectories.shape[1]}\")\n",
    "    print(f\"  Coordinate dimensions: {generated_trajectories.shape[2]}\")\n",
    "    \n",
    "    # è»Œé“ã®ç¯„å›²æƒ…å ±\n",
    "    print(f\"\\nğŸ“ Trajectory Range:\")\n",
    "    print(f\"  X: [{generated_trajectories[:,:,0].min():.3f}, {generated_trajectories[:,:,0].max():.3f}]\")\n",
    "    print(f\"  Y: [{generated_trajectories[:,:,1].min():.3f}, {generated_trajectories[:,:,1].max():.3f}]\")\n",
    "    \n",
    "    # èª¤å·®è¨ˆç®—ï¼ˆå®Ÿè»Œé“ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰\n",
    "    if real_trajectories is not None and len(real_trajectories) >= max_display_samples:\n",
    "        # train.pyã‚¹ã‚¿ã‚¤ãƒ«ã«åˆã‚ã›ã¦å„æ¡ä»¶ã®æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã§èª¤å·®è¨ˆç®—\n",
    "        selected_generated = []\n",
    "        for i in range(max_display_samples):\n",
    "            gen_idx = i * samples_per_condition  # å„æ¡ä»¶ã®æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«\n",
    "            if gen_idx < len(generated_trajectories):\n",
    "                selected_generated.append(generated_trajectories[gen_idx])\n",
    "        \n",
    "        if selected_generated:\n",
    "            selected_generated = np.array(selected_generated)\n",
    "            selected_real = real_trajectories[:len(selected_generated)]\n",
    "            \n",
    "            errors = calculate_trajectory_errors(selected_generated, selected_real)\n",
    "            \n",
    "            print(f\"\\nâš ï¸ Error Statistics (first sample per condition):\")\n",
    "            print(f\"  MSE: {errors['mse']:.6f}\")\n",
    "            print(f\"  Endpoint Error: {errors['endpoint_error']:.6f}\")\n",
    "            print(f\"  Path Length Error: {errors['length_error']:.6f}\")\n",
    "            print(f\"  Max Deviation: {errors['max_deviation']:.6f}\")\n",
    "\n",
    "def create_statistics_plot(generated_trajectories, real_trajectories, conditions, samples_per_condition):\n",
    "    \"\"\"çµ±è¨ˆçš„åˆ†æãƒ—ãƒ­ãƒƒãƒˆã‚’notebookå†…ã§è¡¨ç¤º\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # è»Œé“é•·ã®åˆ†å¸ƒ\n",
    "    plt.subplot(2, 3, 1)\n",
    "    generated_lengths = [np.sum(np.sqrt(np.sum(np.diff(traj, axis=0)**2, axis=1))) for traj in generated_trajectories]\n",
    "    \n",
    "    if real_trajectories is not None:\n",
    "        original_lengths = [np.sum(np.sqrt(np.sum(np.diff(traj, axis=0)**2, axis=1))) for traj in real_trajectories]\n",
    "        plt.hist(original_lengths, bins=20, alpha=0.7, label='Original', color='black')\n",
    "    \n",
    "    plt.hist(generated_lengths, bins=20, alpha=0.7, label='Generated', color='red')\n",
    "    plt.xlabel('Path Length')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Path Length Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æœ€å¤§å¤‰ä½ã®åˆ†å¸ƒ\n",
    "    plt.subplot(2, 3, 2)\n",
    "    generated_max_disp = [np.max(np.sqrt(traj[:, 0]**2 + traj[:, 1]**2)) for traj in generated_trajectories]\n",
    "    \n",
    "    if real_trajectories is not None:\n",
    "        original_max_disp = [np.max(np.sqrt(traj[:, 0]**2 + traj[:, 1]**2)) for traj in real_trajectories]\n",
    "        plt.hist(original_max_disp, bins=20, alpha=0.7, label='Original', color='black')\n",
    "    \n",
    "    plt.hist(generated_max_disp, bins=20, alpha=0.7, label='Generated', color='red')\n",
    "    plt.xlabel('Max Displacement')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Max Displacement Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # çµ‚ç‚¹ä½ç½®ã®åˆ†å¸ƒ\n",
    "    plt.subplot(2, 3, 3)\n",
    "    if real_trajectories is not None:\n",
    "        plt.scatter(real_trajectories[:, -1, 0], real_trajectories[:, -1, 1], \n",
    "                   alpha=0.7, label='Original', color='black', s=50)\n",
    "    \n",
    "    plt.scatter(generated_trajectories[:, -1, 0], generated_trajectories[:, -1, 1], \n",
    "               alpha=0.5, label='Generated', color='red', s=30)\n",
    "    plt.xlabel('Endpoint X')\n",
    "    plt.ylabel('Endpoint Y')\n",
    "    plt.title('Endpoint Position Distribution')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    # å„æ¡ä»¶ã§ã®ç”Ÿæˆå¤šæ§˜æ€§ï¼ˆHybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ï¼‰\n",
    "    plt.subplot(2, 3, 4)\n",
    "    num_conditions = len(generated_trajectories) // samples_per_condition\n",
    "    diversities = []\n",
    "    \n",
    "    for i in range(num_conditions):\n",
    "        start_idx = i * samples_per_condition\n",
    "        end_idx = min(start_idx + samples_per_condition, len(generated_trajectories))\n",
    "        gen_samples = generated_trajectories[start_idx:end_idx]\n",
    "        \n",
    "        # ã‚µãƒ³ãƒ—ãƒ«é–“ã®å¹³å‡è·é›¢ã‚’è¨ˆç®—\n",
    "        distances = []\n",
    "        for j in range(len(gen_samples)):\n",
    "            for k in range(j+1, len(gen_samples)):\n",
    "                dist = np.mean(np.sqrt(np.sum((gen_samples[j] - gen_samples[k])**2, axis=1)))\n",
    "                distances.append(dist)\n",
    "        diversities.append(np.mean(distances) if distances else 0)\n",
    "    \n",
    "    plt.bar(range(num_conditions), diversities, alpha=0.7, color='green')\n",
    "    plt.xlabel('Condition Index')\n",
    "    plt.ylabel('Intra-Condition Diversity')\n",
    "    plt.title('Diversity per Condition')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # æ¡ä»¶ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨å¤šæ§˜æ€§ã®é–¢ä¿‚\n",
    "    plt.subplot(2, 3, 5)\n",
    "    if conditions is not None and len(conditions) >= num_conditions:\n",
    "        condition_names = ['Movement Time', 'Endpoint Error', 'Jerk', 'Goal X', 'Goal Y']\n",
    "        for i, name in enumerate(condition_names):\n",
    "            if i < conditions.shape[1]:\n",
    "                plt.scatter(conditions[:num_conditions, i], diversities, alpha=0.7, label=name)\n",
    "        plt.xlabel('Condition Parameter Value')\n",
    "        plt.ylabel('Intra-Condition Diversity')\n",
    "        plt.title('Condition vs Diversity Relationship')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Condition data not available', \n",
    "                ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('Condition vs Diversity Relationship')\n",
    "    \n",
    "    # ã‚µãƒ³ãƒ—ãƒ«æ•°ã®æƒ…å ±\n",
    "    plt.subplot(2, 3, 6)\n",
    "    info_text = f\"\"\"Generation Statistics:\n",
    "\n",
    "Conditions: {num_conditions}\n",
    "Samples per Condition: {samples_per_condition}\n",
    "Total Generated Samples: {len(generated_trajectories)}\n",
    "Sequence Length: {generated_trajectories.shape[1]}\n",
    "Average Intra-Condition Diversity: {np.mean(diversities):.4f}\n",
    "\n",
    "Coordinate Range:\n",
    "X: [{generated_trajectories[:,:,0].min():.2f}, {generated_trajectories[:,:,0].max():.2f}]\n",
    "Y: [{generated_trajectories[:,:,1].min():.2f}, {generated_trajectories[:,:,1].max():.2f}]\"\"\"\n",
    "    \n",
    "    plt.text(0.1, 0.9, info_text, fontsize=11, verticalalignment='top',\n",
    "            transform=plt.gca().transAxes,\n",
    "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "    plt.axis('off')\n",
    "    plt.title('Generation Statistics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Statistical Analysis of Generated Trajectories', fontsize=16, y=1.02)\n",
    "    plt.show()  # notebookå†…ã§ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º\n",
    "\n",
    "def calculate_trajectory_errors(generated, real):\n",
    "    \"\"\"è»Œé“é–“ã®å„ç¨®èª¤å·®ã‚’è¨ˆç®—\"\"\"\n",
    "    errors = {}\n",
    "    \n",
    "    # MSE\n",
    "    mse = np.mean((generated - real) ** 2)\n",
    "    errors['mse'] = mse\n",
    "    \n",
    "    # çµ‚ç‚¹èª¤å·®\n",
    "    endpoint_errors = np.linalg.norm(generated[:, -1] - real[:, -1], axis=1)\n",
    "    errors['endpoint_error'] = np.mean(endpoint_errors)\n",
    "    \n",
    "    # è»Œé“é•·èª¤å·®\n",
    "    gen_lengths = np.sum(np.linalg.norm(np.diff(generated, axis=1), axis=2), axis=1)\n",
    "    real_lengths = np.sum(np.linalg.norm(np.diff(real, axis=1), axis=2), axis=1)\n",
    "    errors['length_error'] = np.mean(np.abs(gen_lengths - real_lengths))\n",
    "    \n",
    "    # æœ€å¤§åå·®\n",
    "    deviations = np.linalg.norm(generated - real, axis=2)\n",
    "    errors['max_deviation'] = np.max(deviations)\n",
    "    \n",
    "    return errors\n",
    "\n",
    "generate_button.on_click(generate_and_visualize)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>è»Œé“ç”Ÿæˆãƒ»å¯è¦–åŒ–</h3>\"),\n",
    "    widgets.HBox([checkpoint_dropdown, refresh_checkpoints_btn]),\n",
    "    num_samples_widget,\n",
    "    condition_mode,\n",
    "    condition_container,\n",
    "    generate_button,\n",
    "    generation_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. å…¨ä½“è©•ä¾¡æ©Ÿèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb70dd82cb849b289dbb63e54e2093e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>å…¨ä½“æ€§èƒ½è©•ä¾¡</h3>'), IntSlider(value=9, description='è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°:', max=30, min=3, step=3â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CLAUDE_ADDED\n",
    "# å…¨ä½“è©•ä¾¡æ©Ÿèƒ½\n",
    "evaluation_samples_widget = widgets.IntSlider(\n",
    "    value=9,  # HybridTransformerã®train.pyã«åˆã‚ã›ã‚‹\n",
    "    min=3, max=30, step=3,  # 3ã®å€æ•°ã§è¨­å®šï¼ˆ3ã‚µãƒ³ãƒ—ãƒ«/æ¡ä»¶ã®ãŸã‚ï¼‰\n",
    "    description='è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "evaluate_button = widgets.Button(\n",
    "    description='å…¨ä½“æ€§èƒ½è©•ä¾¡',\n",
    "    button_style='warning',\n",
    "    icon='chart-bar'\n",
    ")\n",
    "\n",
    "evaluation_output = widgets.Output()\n",
    "\n",
    "def get_evaluation_command(model_name, checkpoint_path, num_samples):\n",
    "    \"\"\"è©•ä¾¡ç”¨ã®ãƒ¢ãƒ‡ãƒ«åˆ¥ã‚³ãƒãƒ³ãƒ‰ã‚’å–å¾— - HybridTransformerã®train.pyã«åˆã‚ã›ã‚‹\"\"\"\n",
    "    model_dir = evaluator.models[model_name]\n",
    "    \n",
    "    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¹ã‚’ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ã«å¤‰æ›\n",
    "    if model_dir in str(checkpoint_path):\n",
    "        relative_path = str(checkpoint_path).split(model_dir + \"/\", 1)[-1]\n",
    "    else:\n",
    "        try:\n",
    "            checkpoint_path_obj = Path(checkpoint_path)\n",
    "            model_dir_path = Path(model_dir)\n",
    "            abs_checkpoint = checkpoint_path_obj.absolute()\n",
    "            abs_model_dir = model_dir_path.absolute()\n",
    "            relative_path = abs_checkpoint.relative_to(abs_model_dir)\n",
    "        except ValueError:\n",
    "            relative_path = checkpoint_path\n",
    "    \n",
    "    if model_name == 'DiffWave':\n",
    "        cmd = f\"cd {model_dir} && python generate.py --checkpoint {relative_path} --batch_size {num_samples} --use_dummy\"\n",
    "    elif model_name in ['HybridModel', 'HybridTransformer']:\n",
    "        # HybridTransformerã®å ´åˆã€train.pyã®generate_samplesã‚’ä½¿ç”¨\n",
    "        cmd = f\"cd {model_dir} && python train.py --mode generate --model_path {relative_path} --num_samples {num_samples}\"\n",
    "    elif model_name == 'Transformer':\n",
    "        cmd = f\"cd {model_dir} && python generate.py --checkpoint {relative_path} --num_samples {num_samples}\"\n",
    "    elif model_name == 'UNet':\n",
    "        cmd = f\"cd {model_dir} && python generate.py --checkpoint {relative_path} --batch_size {num_samples}\"\n",
    "    else:\n",
    "        cmd = f\"cd {model_dir} && python generate.py --checkpoint {relative_path}\"\n",
    "    \n",
    "    return cmd\n",
    "\n",
    "def comprehensive_evaluation(b):\n",
    "    with evaluation_output:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if evaluator.selected_model is None or evaluator.dataset is None:\n",
    "            print(\"ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "            return\n",
    "        \n",
    "        if not checkpoint_dropdown.value:\n",
    "            print(\"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“\")\n",
    "            return\n",
    "        \n",
    "        print(f\"ğŸ“Š {evaluator.selected_model} ã®å…¨ä½“æ€§èƒ½è©•ä¾¡ã‚’é–‹å§‹...\")\n",
    "        \n",
    "        try:\n",
    "            # è©•ä¾¡ç”¨ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠ\n",
    "            n_samples = evaluation_samples_widget.value\n",
    "            total_samples = len(evaluator.dataset['trajectories'])\n",
    "            indices = np.random.choice(total_samples, min(n_samples, total_samples), replace=False)\n",
    "            \n",
    "            test_conditions = evaluator.dataset['conditions'][indices]\n",
    "            test_trajectories = evaluator.dataset['trajectories'][indices]\n",
    "            \n",
    "            print(f\"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(test_conditions)}\")\n",
    "            print(f\"ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ: {checkpoint_dropdown.value}\")\n",
    "            \n",
    "            # ãƒãƒƒãƒç”Ÿæˆå®Ÿè¡Œ\n",
    "            model_dir = evaluator.models[evaluator.selected_model]\n",
    "            \n",
    "            # HybridTransformerã®å ´åˆã¯train.pyã®generate_samplesé–¢æ•°ã‚’ä½¿ç”¨\n",
    "            if evaluator.selected_model in ['HybridModel', 'HybridTransformer']:\n",
    "                # è©•ä¾¡ç”¨ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ\n",
    "                cmd = get_evaluation_command(\n",
    "                    evaluator.selected_model, \n",
    "                    checkpoint_dropdown.value, \n",
    "                    len(test_conditions)\n",
    "                )\n",
    "                \n",
    "                print(f\"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {cmd}\")\n",
    "                \n",
    "                result = subprocess.run(\n",
    "                    cmd,\n",
    "                    shell=True,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    cwd=os.getcwd()\n",
    "                )\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    print(\"âœ“ ãƒãƒƒãƒç”Ÿæˆå®Œäº†\")\n",
    "                    \n",
    "                    # HybridTransformerã®train.pyã§ç”Ÿæˆã•ã‚ŒãŸçµæœã‚’èª­ã¿è¾¼ã¿\n",
    "                    generated_files_patterns = [\n",
    "                        f\"{model_dir}/outputs/generated_trajectories/generated_samples.npy\"\n",
    "                    ]\n",
    "                    \n",
    "                    generated_files = []\n",
    "                    for pattern in generated_files_patterns:\n",
    "                        file_path = Path(pattern)\n",
    "                        if file_path.exists():\n",
    "                            generated_files.append(file_path)\n",
    "                    \n",
    "                    if generated_files:\n",
    "                        latest_file = max(generated_files, key=lambda x: x.stat().st_mtime)\n",
    "                        generated_trajectories = np.load(latest_file)\n",
    "                        \n",
    "                        print(f\"ç”Ÿæˆè»Œé“èª­ã¿è¾¼ã¿: {latest_file}\")\n",
    "                        print(f\"ç”Ÿæˆè»Œé“å½¢çŠ¶: {generated_trajectories.shape}\")\n",
    "                        \n",
    "                        # ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã®èª¿æ•´\n",
    "                        if len(generated_trajectories.shape) == 3:\n",
    "                            if generated_trajectories.shape[0] > generated_trajectories.shape[1] and generated_trajectories.shape[2] == 2:\n",
    "                                generated_trajectories = generated_trajectories.transpose(1, 0, 2)\n",
    "                                print(f\"è»¸ã‚’å…¥ã‚Œæ›¿ãˆ: {generated_trajectories.shape}\")\n",
    "                        \n",
    "                        # HybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ã®è©³ç´°è©•ä¾¡å®Ÿè¡Œï¼ˆnotebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼‰\n",
    "                        detailed_evaluation_hybrid_style(generated_trajectories, test_trajectories, test_conditions)\n",
    "                    else:\n",
    "                        print(\"ç”Ÿæˆã•ã‚ŒãŸè»Œé“ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "                        print(\"æ¢ç´¢ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³:\")\n",
    "                        for i, pattern in enumerate(generated_files_patterns):\n",
    "                            print(f\"  {i+1}. {pattern}\")\n",
    "                else:\n",
    "                    print(f\"âœ— ãƒãƒƒãƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode}):\")\n",
    "                    print(\"stderr:\", result.stderr)\n",
    "                    if result.stdout:\n",
    "                        print(\"stdout:\", result.stdout)\n",
    "            \n",
    "            else:\n",
    "                # ä»–ã®ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã¯å¾“æ¥ã®å‡¦ç†\n",
    "                temp_conditions_path = Path(model_dir) / 'eval_conditions.npy'\n",
    "                np.save(temp_conditions_path, test_conditions)\n",
    "                \n",
    "                # è©•ä¾¡ç”¨ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ\n",
    "                cmd = get_evaluation_command(\n",
    "                    evaluator.selected_model, \n",
    "                    checkpoint_dropdown.value, \n",
    "                    len(test_conditions)\n",
    "                )\n",
    "                \n",
    "                print(f\"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {cmd}\")\n",
    "                \n",
    "                result = subprocess.run(\n",
    "                    cmd,\n",
    "                    shell=True,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    cwd=os.getcwd()\n",
    "                )\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    print(\"âœ“ ãƒãƒƒãƒç”Ÿæˆå®Œäº†\")\n",
    "                    \n",
    "                    # ç”Ÿæˆçµæœã‚’èª­ã¿è¾¼ã¿ - å„ªå…ˆé †ä½ä»˜ãã§æ¤œç´¢\n",
    "                    potential_patterns = [\n",
    "                        f\"{model_dir}/generated_outputs/data/generated_trajectories.npy\",\n",
    "                        f\"{model_dir}/outputs/generated_trajectories/*.npy\",\n",
    "                        f\"{model_dir}/generated_outputs/**/*.npy\",\n",
    "                        f\"{model_dir}/generated_*.npy\",\n",
    "                        f\"{model_dir}/outputs/**/*.npy\"\n",
    "                    ]\n",
    "                    \n",
    "                    generated_files = []\n",
    "                    for pattern in potential_patterns:\n",
    "                        if '*' in pattern:\n",
    "                            files = list(Path('.').glob(pattern))\n",
    "                        else:\n",
    "                            file_path = Path(pattern)\n",
    "                            if file_path.exists():\n",
    "                                files = [file_path]\n",
    "                            else:\n",
    "                                files = []\n",
    "                        \n",
    "                        generated_files.extend(files)\n",
    "                        if files:\n",
    "                            break\n",
    "                    \n",
    "                    if generated_files:\n",
    "                        latest_file = max(generated_files, key=lambda x: x.stat().st_mtime)\n",
    "                        generated_trajectories = np.load(latest_file)\n",
    "                        \n",
    "                        print(f\"ç”Ÿæˆè»Œé“èª­ã¿è¾¼ã¿: {latest_file}\")\n",
    "                        print(f\"ç”Ÿæˆè»Œé“å½¢çŠ¶: {generated_trajectories.shape}\")\n",
    "                        \n",
    "                        # ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã®èª¿æ•´\n",
    "                        if len(generated_trajectories.shape) == 3:\n",
    "                            if generated_trajectories.shape[0] > generated_trajectories.shape[1] and generated_trajectories.shape[2] == 2:\n",
    "                                generated_trajectories = generated_trajectories.transpose(1, 0, 2)\n",
    "                                print(f\"è»¸ã‚’å…¥ã‚Œæ›¿ãˆ: {generated_trajectories.shape}\")\n",
    "                        \n",
    "                        # è©³ç´°è©•ä¾¡å®Ÿè¡Œï¼ˆnotebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼‰\n",
    "                        detailed_evaluation(generated_trajectories, test_trajectories, test_conditions)\n",
    "                    else:\n",
    "                        print(\"ç”Ÿæˆã•ã‚ŒãŸè»Œé“ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "                        print(\"æ¢ç´¢ã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³:\")\n",
    "                        for i, pattern in enumerate(potential_patterns):\n",
    "                            print(f\"  {i+1}. {pattern}\")\n",
    "                else:\n",
    "                    print(f\"âœ— ãƒãƒƒãƒç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ (çµ‚äº†ã‚³ãƒ¼ãƒ‰: {result.returncode}):\")\n",
    "                    print(\"stderr:\", result.stderr)\n",
    "                    if result.stdout:\n",
    "                        print(\"stdout:\", result.stdout)\n",
    "                \n",
    "                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤\n",
    "                if temp_conditions_path.exists():\n",
    "                    temp_conditions_path.unlink()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\")\n",
    "            import traceback\n",
    "            print(\"è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:\")\n",
    "            print(traceback.format_exc())\n",
    "\n",
    "def detailed_evaluation_hybrid_style(generated, real, conditions):\n",
    "    \"\"\"HybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ã®è©³ç´°ãªæ€§èƒ½è©•ä¾¡ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ - notebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤º\"\"\"\n",
    "    print(\"\\nğŸ“ˆ Detailed Evaluation Results (HybridTransformer Style):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # HybridTransformerã§ã¯å„æ¡ä»¶ã«3ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ç”Ÿæˆ\n",
    "    samples_per_condition = 3\n",
    "    total_generated = len(generated)\n",
    "    num_conditions = min(len(real), total_generated // samples_per_condition)\n",
    "    \n",
    "    print(f\"Evaluation samples: {num_conditions}\")\n",
    "    print(f\"Total generated trajectories: {total_generated}\")\n",
    "    print(f\"Samples per condition: {samples_per_condition}\")\n",
    "    print(f\"Trajectory length: {generated.shape[1]}\")\n",
    "    print(f\"Coordinate dimensions: {generated.shape[2]}\")\n",
    "    \n",
    "    # å„æ¡ä»¶ã®æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ã§åŸºæœ¬è©•ä¾¡\n",
    "    selected_generated = []\n",
    "    for i in range(num_conditions):\n",
    "        gen_idx = i * samples_per_condition  # å„æ¡ä»¶ã®æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«\n",
    "        if gen_idx < len(generated):\n",
    "            selected_generated.append(generated[gen_idx])\n",
    "    \n",
    "    selected_generated = np.array(selected_generated)\n",
    "    selected_real = real[:len(selected_generated)]\n",
    "    \n",
    "    # å„ç¨®èª¤å·®è¨ˆç®—\n",
    "    errors = calculate_comprehensive_errors(selected_generated, selected_real)\n",
    "    \n",
    "    print(\"\\nğŸ¯ Trajectory Accuracy:\")\n",
    "    print(f\"  Mean Squared Error (MSE): {errors['mse']:.6f}\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {errors['mae']:.6f}\")\n",
    "    print(f\"  Endpoint Error: {errors['endpoint_error']:.6f} Â± {errors['endpoint_std']:.6f}\")\n",
    "    print(f\"  Max Deviation: {errors['max_deviation']:.6f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“ Trajectory Characteristics:\")\n",
    "    print(f\"  Path Length Error: {errors['length_error']:.6f} Â± {errors['length_std']:.6f}\")\n",
    "    print(f\"  Smoothness (Jerk): {errors['jerk_error']:.6f}\")\n",
    "    print(f\"  Curvature Difference: {errors['curvature_error']:.6f}\")\n",
    "    \n",
    "    # HybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ã®å¤šæ§˜æ€§è©•ä¾¡ï¼ˆå„æ¡ä»¶å†…ã®ã‚µãƒ³ãƒ—ãƒ«é–“å¤šæ§˜æ€§ï¼‰\n",
    "    condition_diversities = []\n",
    "    for i in range(num_conditions):\n",
    "        start_idx = i * samples_per_condition\n",
    "        end_idx = min(start_idx + samples_per_condition, len(generated))\n",
    "        condition_samples = generated[start_idx:end_idx]\n",
    "        \n",
    "        if len(condition_samples) > 1:\n",
    "            diversity_sum = 0\n",
    "            count = 0\n",
    "            for j in range(len(condition_samples)):\n",
    "                for k in range(j+1, len(condition_samples)):\n",
    "                    diversity_sum += np.mean(np.linalg.norm(condition_samples[j] - condition_samples[k], axis=1))\n",
    "                    count += 1\n",
    "            condition_diversity = diversity_sum / count if count > 0 else 0\n",
    "            condition_diversities.append(condition_diversity)\n",
    "        else:\n",
    "            condition_diversities.append(0)\n",
    "    \n",
    "    avg_diversity = np.mean(condition_diversities) if condition_diversities else 0\n",
    "    \n",
    "    print(\"\\nğŸ² Diversity & Consistency (HybridTransformer Style):\")\n",
    "    print(f\"  Average intra-condition diversity: {avg_diversity:.6f}\")\n",
    "    print(f\"  Condition consistency: {errors['condition_consistency']:.6f}\")\n",
    "    print(f\"  Diversity per condition: {np.std(condition_diversities):.6f}\")\n",
    "    \n",
    "    # HybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ã®å¯è¦–åŒ–ï¼ˆnotebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼‰\n",
    "    create_evaluation_plots_hybrid_style(generated, real, conditions, errors, samples_per_condition)\n",
    "    \n",
    "    # è©•ä¾¡ã‚µãƒãƒªãƒ¼ï¼ˆHybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ï¼‰\n",
    "    overall_score = calculate_overall_score_hybrid_style(errors, avg_diversity)\n",
    "    print(f\"\\nâ­ Overall Score (HybridTransformer Style): {overall_score:.2f}/100\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "def detailed_evaluation(generated, real, conditions):\n",
    "    \"\"\"è©³ç´°ãªæ€§èƒ½è©•ä¾¡ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆå¾“æ¥ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰- notebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤º\"\"\"\n",
    "    print(\"\\nğŸ“ˆ è©³ç´°è©•ä¾¡çµæœ:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # åŸºæœ¬çµ±è¨ˆ\n",
    "    n_samples = len(generated)\n",
    "    print(f\"è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°: {n_samples}\")\n",
    "    print(f\"è»Œé“é•·: {generated.shape[1]}\")\n",
    "    print(f\"æ¬¡å…ƒæ•°: {generated.shape[2]}\")\n",
    "    \n",
    "    # å„ç¨®èª¤å·®è¨ˆç®—\n",
    "    errors = calculate_comprehensive_errors(generated, real)\n",
    "    \n",
    "    print(\"\\nğŸ¯ è»Œé“ç²¾åº¦:\")\n",
    "    print(f\"  å¹³å‡äºŒä¹—èª¤å·® (MSE): {errors['mse']:.6f}\")\n",
    "    print(f\"  å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {errors['mae']:.6f}\")\n",
    "    print(f\"  çµ‚ç‚¹èª¤å·®: {errors['endpoint_error']:.6f} Â± {errors['endpoint_std']:.6f}\")\n",
    "    print(f\"  æœ€å¤§åå·®: {errors['max_deviation']:.6f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“ è»Œé“ç‰¹æ€§:\")\n",
    "    print(f\"  è»Œé“é•·èª¤å·®: {errors['length_error']:.6f} Â± {errors['length_std']:.6f}\")\n",
    "    print(f\"  æ»‘ã‚‰ã‹ã• (ã‚¸ãƒ£ãƒ¼ã‚¯): {errors['jerk_error']:.6f}\")\n",
    "    print(f\"  æ›²ç‡å·®: {errors['curvature_error']:.6f}\")\n",
    "    \n",
    "    print(\"\\nğŸ² å¤šæ§˜æ€§ãƒ»ä¸€è²«æ€§:\")\n",
    "    print(f\"  è»Œé“å¤šæ§˜æ€§: {errors['diversity']:.6f}\")\n",
    "    print(f\"  æ¡ä»¶ä¸€è²«æ€§: {errors['condition_consistency']:.6f}\")\n",
    "    \n",
    "    # å¯è¦–åŒ–ï¼ˆnotebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤ºï¼‰\n",
    "    create_evaluation_plots(generated, real, conditions, errors)\n",
    "    \n",
    "    # è©•ä¾¡ã‚µãƒãƒªãƒ¼\n",
    "    overall_score = calculate_overall_score(errors)\n",
    "    print(f\"\\nâ­ ç·åˆã‚¹ã‚³ã‚¢: {overall_score:.2f}/100\")\n",
    "    \n",
    "    return errors\n",
    "\n",
    "def calculate_comprehensive_errors(generated, real):\n",
    "    \"\"\"åŒ…æ‹¬çš„ãªèª¤å·®è¨ˆç®—\"\"\"\n",
    "    errors = {}\n",
    "    \n",
    "    # åŸºæœ¬èª¤å·®\n",
    "    diff = generated - real\n",
    "    errors['mse'] = np.mean(diff ** 2)\n",
    "    errors['mae'] = np.mean(np.abs(diff))\n",
    "    \n",
    "    # çµ‚ç‚¹èª¤å·®\n",
    "    endpoint_errors = np.linalg.norm(generated[:, -1] - real[:, -1], axis=1)\n",
    "    errors['endpoint_error'] = np.mean(endpoint_errors)\n",
    "    errors['endpoint_std'] = np.std(endpoint_errors)\n",
    "    \n",
    "    # æœ€å¤§åå·®\n",
    "    deviations = np.linalg.norm(diff, axis=2)\n",
    "    errors['max_deviation'] = np.max(deviations)\n",
    "    \n",
    "    # è»Œé“é•·\n",
    "    gen_lengths = np.sum(np.linalg.norm(np.diff(generated, axis=1), axis=2), axis=1)\n",
    "    real_lengths = np.sum(np.linalg.norm(np.diff(real, axis=1), axis=2), axis=1)\n",
    "    length_diffs = np.abs(gen_lengths - real_lengths)\n",
    "    errors['length_error'] = np.mean(length_diffs)\n",
    "    errors['length_std'] = np.std(length_diffs)\n",
    "    \n",
    "    # ã‚¸ãƒ£ãƒ¼ã‚¯ï¼ˆæ»‘ã‚‰ã‹ã•ï¼‰\n",
    "    gen_jerk = np.sum(np.linalg.norm(np.diff(generated, n=3, axis=1), axis=2) ** 2, axis=1)\n",
    "    real_jerk = np.sum(np.linalg.norm(np.diff(real, n=3, axis=1), axis=2) ** 2, axis=1)\n",
    "    errors['jerk_error'] = np.mean(np.abs(gen_jerk - real_jerk))\n",
    "    \n",
    "    # æ›²ç‡\n",
    "    def calculate_curvature(traj):\n",
    "        dx = np.diff(traj[:, :, 0], axis=1)\n",
    "        dy = np.diff(traj[:, :, 1], axis=1)\n",
    "        ddx = np.diff(dx, axis=1)\n",
    "        ddy = np.diff(dy, axis=1)\n",
    "        curvature = np.abs(dx[:, :-1] * ddy - dy[:, :-1] * ddx) / (dx[:, :-1]**2 + dy[:, :-1]**2 + 1e-8)**(3/2)\n",
    "        return np.mean(curvature, axis=1)\n",
    "    \n",
    "    gen_curvature = calculate_curvature(generated)\n",
    "    real_curvature = calculate_curvature(real)\n",
    "    errors['curvature_error'] = np.mean(np.abs(gen_curvature - real_curvature))\n",
    "    \n",
    "    # å¤šæ§˜æ€§ï¼ˆç”Ÿæˆè»Œé“é–“ã®å¹³å‡è·é›¢ï¼‰\n",
    "    n_samples = len(generated)\n",
    "    diversity_sum = 0\n",
    "    count = 0\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i+1, n_samples):\n",
    "            diversity_sum += np.mean(np.linalg.norm(generated[i] - generated[j], axis=1))\n",
    "            count += 1\n",
    "    errors['diversity'] = diversity_sum / count if count > 0 else 0\n",
    "    \n",
    "    # æ¡ä»¶ä¸€è²«æ€§ï¼ˆåŒã˜æ¡ä»¶ã§ã®å†ç¾æ€§ï¼‰\n",
    "    errors['condition_consistency'] = 1.0 - (errors['mse'] / (errors['mse'] + 1.0))\n",
    "    \n",
    "    return errors\n",
    "\n",
    "def calculate_overall_score(errors):\n",
    "    \"\"\"ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ100ç‚¹æº€ç‚¹ï¼‰\"\"\"\n",
    "    # å„æŒ‡æ¨™ã‚’0-100ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–\n",
    "    mse_score = max(0, 100 - errors['mse'] * 10000)  # MSEã¯å°ã•ã„ã»ã©è‰¯ã„\n",
    "    endpoint_score = max(0, 100 - errors['endpoint_error'] * 100)\n",
    "    consistency_score = errors['condition_consistency'] * 100\n",
    "    diversity_score = min(100, errors['diversity'] * 50)  # é©åº¦ãªå¤šæ§˜æ€§\n",
    "    \n",
    "    # é‡ã¿ä»˜ã‘å¹³å‡\n",
    "    weights = [0.3, 0.3, 0.2, 0.2]  # MSE, çµ‚ç‚¹, ä¸€è²«æ€§, å¤šæ§˜æ€§\n",
    "    scores = [mse_score, endpoint_score, consistency_score, diversity_score]\n",
    "    \n",
    "    overall = sum(w * s for w, s in zip(weights, scores))\n",
    "    return max(0, min(100, overall))\n",
    "\n",
    "def calculate_overall_score_hybrid_style(errors, avg_diversity):\n",
    "    \"\"\"HybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ç·åˆã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ï¼ˆ100ç‚¹æº€ç‚¹ï¼‰\"\"\"\n",
    "    # å„æŒ‡æ¨™ã‚’0-100ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–\n",
    "    mse_score = max(0, 100 - errors['mse'] * 10000)\n",
    "    endpoint_score = max(0, 100 - errors['endpoint_error'] * 100)\n",
    "    consistency_score = errors['condition_consistency'] * 100\n",
    "    diversity_score = min(100, avg_diversity * 30)  # HybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ã®å¤šæ§˜æ€§è©•ä¾¡\n",
    "    \n",
    "    # é‡ã¿ä»˜ã‘å¹³å‡ï¼ˆHybridTransformerã«é©ã—ãŸã‚¦ã‚§ã‚¤ãƒˆï¼‰\n",
    "    weights = [0.4, 0.3, 0.2, 0.1]  # MSEã‚’é‡è¦–, å¤šæ§˜æ€§ã¯è»½ã‚\n",
    "    scores = [mse_score, endpoint_score, consistency_score, diversity_score]\n",
    "    \n",
    "    overall = sum(w * s for w, s in zip(weights, scores))\n",
    "    return max(0, min(100, overall))\n",
    "\n",
    "def create_evaluation_plots_hybrid_style(generated, real, conditions, errors, samples_per_condition):\n",
    "    \"\"\"HybridTransformerã‚¹ã‚¿ã‚¤ãƒ«ã®è©•ä¾¡çµæœå¯è¦–åŒ– - notebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤º\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    num_conditions = len(real)\n",
    "    \n",
    "    # 1. è»Œé“æ¯”è¼ƒã‚µãƒ³ãƒ—ãƒ« (HybridTransformerã‚¹ã‚¿ã‚¤ãƒ«)\n",
    "    ax = axes[0, 0]\n",
    "    n_show = min(3, num_conditions)\n",
    "    for i in range(n_show):\n",
    "        # å®Ÿè»Œé“\n",
    "        ax.plot(real[i, :, 0], real[i, :, 1], 'k-', linewidth=3, alpha=0.8, label='Real' if i == 0 else \"\")\n",
    "        \n",
    "        # å„æ¡ä»¶ã®3ã¤ã®ã‚µãƒ³ãƒ—ãƒ«\n",
    "        colors = ['red', 'blue', 'green']\n",
    "        for j in range(samples_per_condition):\n",
    "            gen_idx = i * samples_per_condition + j\n",
    "            if gen_idx < len(generated):\n",
    "                color = colors[j % len(colors)]\n",
    "                ax.plot(generated[gen_idx, :, 0], generated[gen_idx, :, 1], \n",
    "                       '--', color=color, linewidth=2, alpha=0.7,\n",
    "                       label=f'Generated {j+1}' if i == 0 else \"\")\n",
    "    \n",
    "    ax.set_title('Trajectory Comparison (HybridTransformer Style)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "    \n",
    "    # 2. æ¡ä»¶å†…å¤šæ§˜æ€§åˆ†å¸ƒ\n",
    "    ax = axes[0, 1]\n",
    "    condition_diversities = []\n",
    "    for i in range(num_conditions):\n",
    "        start_idx = i * samples_per_condition\n",
    "        end_idx = min(start_idx + samples_per_condition, len(generated))\n",
    "        condition_samples = generated[start_idx:end_idx]\n",
    "        \n",
    "        if len(condition_samples) > 1:\n",
    "            diversity_sum = 0\n",
    "            count = 0\n",
    "            for j in range(len(condition_samples)):\n",
    "                for k in range(j+1, len(condition_samples)):\n",
    "                    diversity_sum += np.mean(np.linalg.norm(condition_samples[j] - condition_samples[k], axis=1))\n",
    "                    count += 1\n",
    "            condition_diversity = diversity_sum / count if count > 0 else 0\n",
    "            condition_diversities.append(condition_diversity)\n",
    "        else:\n",
    "            condition_diversities.append(0)\n",
    "    \n",
    "    ax.hist(condition_diversities, bins=15, alpha=0.7, color='purple', edgecolor='black')\n",
    "    ax.axvline(np.mean(condition_diversities), color='red', linestyle='--', linewidth=2, \n",
    "              label=f'Mean: {np.mean(condition_diversities):.4f}')\n",
    "    ax.set_title('Intra-Condition Diversity Distribution')\n",
    "    ax.set_xlabel('Diversity')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. çµ‚ç‚¹èª¤å·®ï¼ˆå„æ¡ä»¶ã®æœ€åˆã®ã‚µãƒ³ãƒ—ãƒ«ï¼‰\n",
    "    ax = axes[0, 2]\n",
    "    selected_generated = []\n",
    "    for i in range(num_conditions):\n",
    "        gen_idx = i * samples_per_condition\n",
    "        if gen_idx < len(generated):\n",
    "            selected_generated.append(generated[gen_idx])\n",
    "    \n",
    "    selected_generated = np.array(selected_generated)\n",
    "    endpoint_errors = np.linalg.norm(selected_generated[:, -1] - real[:len(selected_generated), -1], axis=1)\n",
    "    ax.scatter(range(len(endpoint_errors)), endpoint_errors, alpha=0.6, c='orange')\n",
    "    ax.axhline(np.mean(endpoint_errors), color='red', linestyle='--', linewidth=2, \n",
    "              label=f'Mean: {np.mean(endpoint_errors):.4f}')\n",
    "    ax.set_title('Endpoint Errors (First Sample per Condition)')\n",
    "    ax.set_xlabel('Condition Index')\n",
    "    ax.set_ylabel('Endpoint Error')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. è»Œé“é•·æ¯”è¼ƒ\n",
    "    ax = axes[1, 0]\n",
    "    selected_gen_lengths = np.sum(np.linalg.norm(np.diff(selected_generated, axis=1), axis=2), axis=1)\n",
    "    real_lengths = np.sum(np.linalg.norm(np.diff(real[:len(selected_generated)], axis=1), axis=2), axis=1)\n",
    "    ax.scatter(real_lengths, selected_gen_lengths, alpha=0.6, c='green')\n",
    "    min_len, max_len = min(np.min(real_lengths), np.min(selected_gen_lengths)), max(np.max(real_lengths), np.max(selected_gen_lengths))\n",
    "    ax.plot([min_len, max_len], [min_len, max_len], 'r--', linewidth=2, label='Ideal Line')\n",
    "    ax.set_title('Path Length Comparison')\n",
    "    ax.set_xlabel('Real Path Length')\n",
    "    ax.set_ylabel('Generated Path Length')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. å„æ¡ä»¶ã§ã®å¤šæ§˜æ€§\n",
    "    ax = axes[1, 1]\n",
    "    ax.bar(range(len(condition_diversities)), condition_diversities, alpha=0.7, color='cyan')\n",
    "    ax.set_title('Diversity per Condition')\n",
    "    ax.set_xlabel('Condition Index')\n",
    "    ax.set_ylabel('Intra-Condition Diversity')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. ã‚¹ã‚³ã‚¢è¡¨ç¤º\n",
    "    ax = axes[1, 2]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    avg_diversity = np.mean(condition_diversities) if condition_diversities else 0\n",
    "    overall_score = calculate_overall_score_hybrid_style(errors, avg_diversity)\n",
    "    \n",
    "    score_text = f\"\"\"HybridTransformer Style Evaluation\n",
    "    \n",
    "MSE: {errors['mse']:.6f}\n",
    "Endpoint Error: {errors['endpoint_error']:.4f}\n",
    "Path Length Error: {errors['length_error']:.4f}\n",
    "Jerk Error: {errors['jerk_error']:.4f}\n",
    "Intra-Condition Diversity: {avg_diversity:.4f}\n",
    "Consistency: {errors['condition_consistency']:.4f}\n",
    "\n",
    "Conditions: {num_conditions}\n",
    "Samples per Condition: {samples_per_condition}\n",
    "Total Samples: {len(generated)}\n",
    "\n",
    "Overall Score: {overall_score:.1f}/100\"\"\"\n",
    "    \n",
    "    ax.text(0.1, 0.9, score_text, transform=ax.transAxes,\n",
    "           fontsize=11, verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()  # notebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤º\n",
    "\n",
    "def create_evaluation_plots(generated, real, conditions, errors):\n",
    "    \"\"\"è©•ä¾¡çµæœã®å¯è¦–åŒ–ï¼ˆå¾“æ¥ã‚¹ã‚¿ã‚¤ãƒ«ï¼‰- notebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤º\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. è»Œé“æ¯”è¼ƒã‚µãƒ³ãƒ—ãƒ«\n",
    "    ax = axes[0, 0]\n",
    "    n_show = min(5, len(generated))\n",
    "    for i in range(n_show):\n",
    "        ax.plot(generated[i, :, 0], generated[i, :, 1], 'r-', alpha=0.7, linewidth=1.5, label='Generated' if i == 0 else \"\")\n",
    "        ax.plot(real[i, :, 0], real[i, :, 1], 'b--', alpha=0.7, linewidth=1.5, label='Real' if i == 0 else \"\")\n",
    "    ax.set_title('Trajectory Comparison Samples')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    \n",
    "    # 2. èª¤å·®åˆ†å¸ƒ\n",
    "    ax = axes[0, 1]\n",
    "    point_errors = np.linalg.norm(generated - real, axis=2).flatten()\n",
    "    ax.hist(point_errors, bins=50, alpha=0.7, color='orange', edgecolor='black')\n",
    "    ax.axvline(np.mean(point_errors), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(point_errors):.4f}')\n",
    "    ax.set_title('Point-wise Error Distribution')\n",
    "    ax.set_xlabel('Error')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. çµ‚ç‚¹èª¤å·®\n",
    "    ax = axes[0, 2]\n",
    "    endpoint_errors = np.linalg.norm(generated[:, -1] - real[:, -1], axis=1)\n",
    "    ax.scatter(range(len(endpoint_errors)), endpoint_errors, alpha=0.6, c='purple')\n",
    "    ax.axhline(np.mean(endpoint_errors), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(endpoint_errors):.4f}')\n",
    "    ax.set_title('Endpoint Errors')\n",
    "    ax.set_xlabel('Sample Index')\n",
    "    ax.set_ylabel('Endpoint Error')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. è»Œé“é•·æ¯”è¼ƒ\n",
    "    ax = axes[1, 0]\n",
    "    gen_lengths = np.sum(np.linalg.norm(np.diff(generated, axis=1), axis=2), axis=1)\n",
    "    real_lengths = np.sum(np.linalg.norm(np.diff(real, axis=1), axis=2), axis=1)\n",
    "    ax.scatter(real_lengths, gen_lengths, alpha=0.6, c='green')\n",
    "    min_len, max_len = min(np.min(real_lengths), np.min(gen_lengths)), max(np.max(real_lengths), np.max(gen_lengths))\n",
    "    ax.plot([min_len, max_len], [min_len, max_len], 'r--', linewidth=2, label='Ideal Line')\n",
    "    ax.set_title('Path Length Comparison')\n",
    "    ax.set_xlabel('Real Path Length')\n",
    "    ax.set_ylabel('Generated Path Length')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. æ™‚é–“å¤‰åŒ–èª¤å·®\n",
    "    ax = axes[1, 1]\n",
    "    time_errors = np.mean(np.linalg.norm(generated - real, axis=2), axis=0)\n",
    "    ax.plot(time_errors, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "    ax.set_title('Temporal Error Evolution')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('Average Error')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. ã‚¹ã‚³ã‚¢è¡¨ç¤º\n",
    "    ax = axes[1, 2]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    score_text = f\"\"\"Evaluation Scores\n",
    "    \n",
    "MSE: {errors['mse']:.6f}\n",
    "Endpoint Error: {errors['endpoint_error']:.4f}\n",
    "Path Length Error: {errors['length_error']:.4f}\n",
    "Jerk Error: {errors['jerk_error']:.4f}\n",
    "Diversity: {errors['diversity']:.4f}\n",
    "Consistency: {errors['condition_consistency']:.4f}\n",
    "\n",
    "Overall Score: {calculate_overall_score(errors):.1f}/100\"\"\"\n",
    "    \n",
    "    ax.text(0.1, 0.9, score_text, transform=ax.transAxes,\n",
    "           fontsize=12, verticalalignment='top',\n",
    "           bbox=dict(boxstyle='round', facecolor='lightcyan', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()  # notebookå†…ã§ã‚°ãƒ©ãƒ•è¡¨ç¤º\n",
    "\n",
    "evaluate_button.on_click(comprehensive_evaluation)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>å…¨ä½“æ€§èƒ½è©•ä¾¡</h3>\"),\n",
    "    evaluation_samples_widget,\n",
    "    evaluate_button,\n",
    "    evaluation_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨æ–¹æ³•\n",
    "\n",
    "1. **ãƒ¢ãƒ‡ãƒ«é¸æŠ**: ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰è©•ä¾¡ã—ãŸã„ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ\n",
    "2. **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š**: è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´\n",
    "3. **å­¦ç¿’å®Ÿè¡Œ**: ã€Œå­¦ç¿’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã§æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "4. **ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿**: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦èª­ã¿è¾¼ã¿\n",
    "5. **è»Œé“ç”Ÿæˆ**: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠã—ã¦è»Œé“ç”Ÿæˆãƒ»å¯è¦–åŒ–\n",
    "6. **å…¨ä½“è©•ä¾¡**: å¤§é‡ã‚µãƒ³ãƒ—ãƒ«ã§ã®åŒ…æ‹¬çš„æ€§èƒ½è©•ä¾¡\n",
    "\n",
    "## æ©Ÿèƒ½èª¬æ˜\n",
    "\n",
    "- **ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–UI**: ipywidgetsã«ã‚ˆã‚‹ç›´æ„Ÿçš„ãªæ“ä½œ\n",
    "- **ãƒ¢ãƒ‡ãƒ«æ±ç”¨æ€§**: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã§ä»»æ„ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œ\n",
    "- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å¯è¦–åŒ–**: ç”Ÿæˆè»Œé“ã¨å®Ÿè»Œé“ã®é‡ã­åˆã‚ã›è¡¨ç¤º\n",
    "- **è©³ç´°è©•ä¾¡**: MSEã€çµ‚ç‚¹èª¤å·®ã€è»Œé“é•·ã€ã‚¸ãƒ£ãƒ¼ã‚¯ã€å¤šæ§˜æ€§ãªã©å¤šè§’çš„è©•ä¾¡\n",
    "- **ãƒãƒƒãƒå‡¦ç†**: å¤§é‡ã‚µãƒ³ãƒ—ãƒ«ã§ã®åŠ¹ç‡çš„ãªè©•ä¾¡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
