{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 拡散モデル訓練可視化ノートブック\n",
    "\n",
    "このノートブックでは、個人最適化軌道生成のための拡散モデルの訓練プロセスと結果を可視化します。\n",
    "\n",
    "## 内容\n",
    "1. 環境設定\n",
    "2. モデルアーキテクチャの可視化\n",
    "3. ノイズスケジュールの分析\n",
    "4. 訓練プロセスの可視化\n",
    "5. 生成プロセスの段階的可視化\n",
    "6. 個人特性と軌道の関係分析\n",
    "7. 結果の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# プロジェクトルートをパスに追加\n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ローカルモジュールのインポート\n",
    "from Model import UNet1D\n",
    "from train import DDPMScheduler, TrajectoryDataset, DiffusionTrainer, create_dummy_data\n",
    "from generate import TrajectoryGenerator, load_model\n",
    "\n",
    "# プロット設定\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定と基本パラメータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# デバイス設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'使用デバイス: {device}')\n",
    "\n",
    "# 基本パラメータ\n",
    "CONFIG = {\n",
    "    'input_dim': 2,          # 軌道次元 (x, y)\n",
    "    'condition_dim': 5,      # 個人特性次元 (動作時間、終点誤差、ジャーク等)\n",
    "    'seq_len': 101,          # 軌道の長さ\n",
    "    'time_embed_dim': 128,   # 時間埋め込み次元\n",
    "    'base_channels': 64,     # ベースチャンネル数\n",
    "    'num_timesteps': 1000,   # 拡散ステップ数\n",
    "    'batch_size': 32,        # バッチサイズ\n",
    "    'learning_rate': 1e-4,   # 学習率\n",
    "}\n",
    "\n",
    "print('設定パラメータ:')\n",
    "for key, value in CONFIG.items():\n",
    "    print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. モデルアーキテクチャの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# モデルの作成\n",
    "model = UNet1D(\n",
    "    input_dim=CONFIG['input_dim'],\n",
    "    condition_dim=CONFIG['condition_dim'],\n",
    "    time_embed_dim=CONFIG['time_embed_dim'],\n",
    "    base_channels=CONFIG['base_channels']\n",
    ").to(device)\n",
    "\n",
    "# パラメータ数の計算\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'総パラメータ数: {total_params:,}')\n",
    "print(f'学習可能パラメータ数: {trainable_params:,}')\n",
    "\n",
    "# レイヤー別パラメータ数の分析\n",
    "layer_info = []\n",
    "for name, module in model.named_modules():\n",
    "    if len(list(module.children())) == 0:  # 末端のモジュールのみ\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        if params > 0:\n",
    "            layer_info.append({\n",
    "                'Layer': name,\n",
    "                'Parameters': params,\n",
    "                'Percentage': (params / total_params) * 100\n",
    "            })\n",
    "\n",
    "# パラメータ数の可視化\n",
    "layer_df = pd.DataFrame(layer_info).sort_values('Parameters', ascending=False).head(10)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# バープロット\n",
    "ax1.barh(layer_df['Layer'][::-1], layer_df['Parameters'][::-1])\n",
    "ax1.set_xlabel('パラメータ数')\n",
    "ax1.set_title('レイヤー別パラメータ数（上位10層）')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 円グラフ\n",
    "others_params = total_params - layer_df['Parameters'].sum()\n",
    "pie_data = list(layer_df['Parameters'].head(5)) + [others_params]\n",
    "pie_labels = list(layer_df['Layer'].head(5)) + ['Others']\n",
    "\n",
    "ax2.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('パラメータ分布（上位5層 + その他）')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ノイズスケジュールの分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# DDPMスケジューラの作成\n",
    "scheduler = DDPMScheduler(num_timesteps=CONFIG['num_timesteps'])\n",
    "\n",
    "# タイムステップ\n",
    "timesteps = np.arange(CONFIG['num_timesteps'])\n",
    "\n",
    "# スケジュールパラメータの取得\n",
    "betas = scheduler.betas.numpy()\n",
    "alphas = scheduler.alphas.numpy()\n",
    "alphas_cumprod = scheduler.alphas_cumprod.numpy()\n",
    "sqrt_alphas_cumprod = scheduler.sqrt_alphas_cumprod.numpy()\n",
    "sqrt_one_minus_alphas_cumprod = scheduler.sqrt_one_minus_alphas_cumprod.numpy()\n",
    "\n",
    "# 可視化\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# β スケジュール\n",
    "axes[0, 0].plot(timesteps, betas, linewidth=2)\n",
    "axes[0, 0].set_title('β スケジュール')\n",
    "axes[0, 0].set_xlabel('タイムステップ')\n",
    "axes[0, 0].set_ylabel('β 値')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# α スケジュール\n",
    "axes[0, 1].plot(timesteps, alphas, linewidth=2)\n",
    "axes[0, 1].set_title('α スケジュール')\n",
    "axes[0, 1].set_xlabel('タイムステップ')\n",
    "axes[0, 1].set_ylabel('α 値')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# α 累積積\n",
    "axes[0, 2].plot(timesteps, alphas_cumprod, linewidth=2)\n",
    "axes[0, 2].set_title('α 累積積')\n",
    "axes[0, 2].set_xlabel('タイムステップ')\n",
    "axes[0, 2].set_ylabel('α̅ 値')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# 信号強度\n",
    "axes[1, 0].plot(timesteps, sqrt_alphas_cumprod, label='信号強度', linewidth=2)\n",
    "axes[1, 0].plot(timesteps, sqrt_one_minus_alphas_cumprod, label='ノイズ強度', linewidth=2)\n",
    "axes[1, 0].set_title('信号とノイズの強度')\n",
    "axes[1, 0].set_xlabel('タイムステップ')\n",
    "axes[1, 0].set_ylabel('強度')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# SNR (Signal-to-Noise Ratio)\n",
    "snr = alphas_cumprod / (1 - alphas_cumprod)\n",
    "axes[1, 1].semilogy(timesteps, snr, linewidth=2)\n",
    "axes[1, 1].set_title('信号対雑音比 (SNR)')\n",
    "axes[1, 1].set_xlabel('タイムステップ')\n",
    "axes[1, 1].set_ylabel('SNR (log scale)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# ノイズレベルの分布\n",
    "noise_levels = sqrt_one_minus_alphas_cumprod\n",
    "axes[1, 2].hist(noise_levels, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 2].set_title('ノイズレベルの分布')\n",
    "axes[1, 2].set_xlabel('ノイズレベル')\n",
    "axes[1, 2].set_ylabel('頻度')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 統計情報\n",
    "print(f'β 範囲: [{betas.min():.6f}, {betas.max():.6f}]')\n",
    "print(f'最終ノイズレベル: {sqrt_one_minus_alphas_cumprod[-1]:.6f}')\n",
    "print(f'最終SNR: {snr[-1]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 訓練データの準備と可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ダミーデータの生成\n",
    "print('訓練データを生成中...')\n",
    "train_trajectories, train_conditions = create_dummy_data(\n",
    "    num_samples=1000, \n",
    "    seq_len=CONFIG['seq_len'], \n",
    "    condition_dim=CONFIG['condition_dim']\n",
    ")\n",
    "\n",
    "val_trajectories, val_conditions = create_dummy_data(\n",
    "    num_samples=200, \n",
    "    seq_len=CONFIG['seq_len'], \n",
    "    condition_dim=CONFIG['condition_dim']\n",
    ")\n",
    "\n",
    "# データセットとデータローダーの作成\n",
    "train_dataset = TrajectoryDataset(train_trajectories, train_conditions)\n",
    "val_dataset = TrajectoryDataset(val_trajectories, val_conditions)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f'訓練データ: {len(train_dataset)} サンプル')\n",
    "print(f'バリデーションデータ: {len(val_dataset)} サンプル')\n",
    "\n",
    "# サンプルデータの可視化\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_trajectories, sample_conditions = sample_batch\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    traj = sample_trajectories[i].numpy()\n",
    "    condition = sample_conditions[i].numpy()\n",
    "    \n",
    "    ax.plot(traj[0], traj[1], 'b-', linewidth=2, alpha=0.8)\n",
    "    ax.plot(traj[0, 0], traj[1, 0], 'go', markersize=8, label='Start')\n",
    "    ax.plot(traj[0, -1], traj[1, -1], 'ro', markersize=8, label='End')\n",
    "    \n",
    "    ax.set_title(f'軌道 {i+1}\\n条件: [{condition[0]:.2f}, {condition[1]:.2f}, {condition[2]:.2f}...]')\n",
    "    ax.set_xlabel('X 位置')\n",
    "    ax.set_ylabel('Y 位置')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ノイズ追加プロセスの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# サンプル軌道を選択\n",
    "sample_traj = sample_trajectories[0:1]  # 最初の軌道を選択\n",
    "sample_cond = sample_conditions[0:1]\n",
    "\n",
    "# 異なるタイムステップでのノイズ追加を可視化\n",
    "timesteps_to_show = [0, 100, 300, 500, 700, 900, 999]\n",
    "num_steps = len(timesteps_to_show)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "original_traj = sample_traj[0].numpy()\n",
    "\n",
    "for i, t in enumerate(timesteps_to_show):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "        \n",
    "    ax = axes[i]\n",
    "    \n",
    "    # ノイズを追加\n",
    "    timestep_tensor = torch.tensor([t])\n",
    "    noise = torch.randn_like(sample_traj)\n",
    "    noisy_traj = scheduler.add_noise(sample_traj, noise, timestep_tensor)\n",
    "    noisy_traj_np = noisy_traj[0].numpy()\n",
    "    \n",
    "    # 元の軌道\n",
    "    ax.plot(original_traj[0], original_traj[1], 'b-', linewidth=3, alpha=0.7, label='Original')\n",
    "    \n",
    "    # ノイズ追加後の軌道\n",
    "    ax.plot(noisy_traj_np[0], noisy_traj_np[1], 'r--', linewidth=2, alpha=0.8, label=f'Noisy (t={t})')\n",
    "    \n",
    "    # 開始点と終了点\n",
    "    ax.plot(original_traj[0, 0], original_traj[1, 0], 'go', markersize=8)\n",
    "    ax.plot(original_traj[0, -1], original_traj[1, -1], 'bo', markersize=8)\n",
    "    \n",
    "    # ノイズレベルの表示\n",
    "    noise_level = sqrt_one_minus_alphas_cumprod[t]\n",
    "    signal_level = sqrt_alphas_cumprod[t]\n",
    "    \n",
    "    ax.set_title(f't = {t}\\nノイズ: {noise_level:.3f}, 信号: {signal_level:.3f}')\n",
    "    ax.set_xlabel('X 位置')\n",
    "    ax.set_ylabel('Y 位置')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "# 空のサブプロットを非表示\n",
    "for i in range(num_steps, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ノイズレベルと信号レベルの関係をプロット\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "ax.plot(timesteps_to_show, [sqrt_alphas_cumprod[t] for t in timesteps_to_show], \n",
    "        'b-o', linewidth=2, markersize=8, label='信号レベル')\n",
    "ax.plot(timesteps_to_show, [sqrt_one_minus_alphas_cumprod[t] for t in timesteps_to_show], \n",
    "        'r-o', linewidth=2, markersize=8, label='ノイズレベル')\n",
    "\n",
    "ax.set_xlabel('タイムステップ')\n",
    "ax.set_ylabel('レベル')\n",
    "ax.set_title('ノイズ追加プロセスにおける信号とノイズのレベル')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. モデル訓練の実行と可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 訓練器の作成\n",
    "trainer = DiffusionTrainer(\n",
    "    model=model, \n",
    "    scheduler=scheduler, \n",
    "    device=device, \n",
    "    learning_rate=CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "# 短期間の訓練実行（デモ用）\n",
    "print('デモ用短期訓練を開始...')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "num_demo_epochs = 5  # デモ用に短縮\n",
    "\n",
    "for epoch in range(num_demo_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # 訓練ループ\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_demo_epochs}', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        loss = trainer.train_step(batch)\n",
    "        epoch_loss += loss\n",
    "        progress_bar.set_postfix({'Loss': f'{loss:.4f}'})\n",
    "    \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # バリデーション\n",
    "    val_loss = trainer.validate(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {val_loss:.4f}')\n",
    "\n",
    "print('デモ訓練完了!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 訓練曲線の可視化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "# 損失曲線\n",
    "ax1.plot(epochs, train_losses, 'b-o', linewidth=2, markersize=6, label='訓練損失')\n",
    "ax1.plot(epochs, val_losses, 'r-o', linewidth=2, markersize=6, label='バリデーション損失')\n",
    "ax1.set_xlabel('エポック')\n",
    "ax1.set_ylabel('損失')\n",
    "ax1.set_title('訓練曲線')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 損失の改善率\n",
    "if len(train_losses) > 1:\n",
    "    train_improvement = [(train_losses[i-1] - train_losses[i]) / train_losses[i-1] * 100 \n",
    "                        for i in range(1, len(train_losses))]\n",
    "    val_improvement = [(val_losses[i-1] - val_losses[i]) / val_losses[i-1] * 100 \n",
    "                      for i in range(1, len(val_losses))]\n",
    "    \n",
    "    ax2.plot(epochs[1:], train_improvement, 'b-o', linewidth=2, markersize=6, label='訓練改善率')\n",
    "    ax2.plot(epochs[1:], val_improvement, 'r-o', linewidth=2, markersize=6, label='バリデーション改善率')\n",
    "    ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('エポック')\n",
    "    ax2.set_ylabel('改善率 (%)')\n",
    "    ax2.set_title('損失改善率')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 最終統計\n",
    "print(f'\\n訓練統計:')\n",
    "print(f'  最終訓練損失: {train_losses[-1]:.4f}')\n",
    "print(f'  最終バリデーション損失: {val_losses[-1]:.4f}')\n",
    "if len(train_losses) > 1:\n",
    "    total_train_improvement = (train_losses[0] - train_losses[-1]) / train_losses[0] * 100\n",
    "    total_val_improvement = (val_losses[0] - val_losses[-1]) / val_losses[0] * 100\n",
    "    print(f'  訓練損失改善: {total_train_improvement:.2f}%')\n",
    "    print(f'  バリデーション損失改善: {total_val_improvement:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 軌道生成と逆拡散プロセスの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 軌道ジェネレータの作成\n",
    "generator = TrajectoryGenerator(model, scheduler, device)\n",
    "\n",
    "# サンプル条件を準備\n",
    "sample_conditions = torch.randn(1, CONFIG['condition_dim']).to(device)\n",
    "\n",
    "# 逆拡散プロセスの段階的可視化\n",
    "print('逆拡散プロセスを可視化中...')\n",
    "\n",
    "# 特定のタイムステップでの中間結果を保存\n",
    "timesteps_to_visualize = [999, 800, 600, 400, 200, 100, 50, 20, 0]\n",
    "intermediate_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    shape = (1, 2, CONFIG['seq_len'])\n",
    "    x = torch.randn(shape, device=device)\n",
    "    \n",
    "    for t in range(scheduler.num_timesteps-1, -1, -1):\n",
    "        if t in timesteps_to_visualize:\n",
    "            intermediate_results.append((t, x.clone()))\n",
    "        \n",
    "        t_tensor = torch.full((1,), t, device=device, dtype=torch.long)\n",
    "        predicted_noise = model(x, t_tensor, sample_conditions)\n",
    "        \n",
    "        if t > 0:\n",
    "            sqrt_recip_alpha_t = generator.sqrt_recip_alphas[t]\n",
    "            beta_t = scheduler.betas[t]\n",
    "            sqrt_one_minus_alphas_cumprod_t = generator.sqrt_one_minus_alphas_cumprod[t]\n",
    "            \n",
    "            mean = sqrt_recip_alpha_t * (x - beta_t / sqrt_one_minus_alphas_cumprod_t * predicted_noise)\n",
    "            \n",
    "            alpha_t = scheduler.alphas[t]\n",
    "            alpha_cumprod_t = scheduler.alphas_cumprod[t]\n",
    "            alpha_cumprod_prev = scheduler.alphas_cumprod_prev[t]\n",
    "            \n",
    "            variance = beta_t * (1 - alpha_cumprod_prev) / (1 - alpha_cumprod_t)\n",
    "            sigma = torch.sqrt(variance)\n",
    "            noise = torch.randn_like(x)\n",
    "            \n",
    "            x = mean + sigma * noise\n",
    "        else:\n",
    "            sqrt_recip_alpha_t = generator.sqrt_recip_alphas[t]\n",
    "            beta_t = scheduler.betas[t]\n",
    "            sqrt_one_minus_alphas_cumprod_t = generator.sqrt_one_minus_alphas_cumprod[t]\n",
    "            x = sqrt_recip_alpha_t * (x - beta_t / sqrt_one_minus_alphas_cumprod_t * predicted_noise)\n",
    "\n",
    "    # 最終結果も追加\n",
    "    if 0 not in [result[0] for result in intermediate_results]:\n",
    "        intermediate_results.append((0, x.clone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 逆拡散プロセスの可視化\n",
    "num_steps = len(intermediate_results)\n",
    "cols = 3\n",
    "rows = (num_steps + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "if rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, (timestep, trajectory) in enumerate(intermediate_results):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    traj_np = trajectory[0].cpu().numpy()\n",
    "    \n",
    "    # 軌道をプロット\n",
    "    ax.plot(traj_np[0], traj_np[1], 'b-', linewidth=2, alpha=0.8)\n",
    "    ax.plot(traj_np[0, 0], traj_np[1, 0], 'go', markersize=10, label='Start')\n",
    "    ax.plot(traj_np[0, -1], traj_np[1, -1], 'ro', markersize=10, label='End')\n",
    "    \n",
    "    # タイトルと統計情報\n",
    "    noise_level = sqrt_one_minus_alphas_cumprod[timestep] if timestep < len(sqrt_one_minus_alphas_cumprod) else 0\n",
    "    mean_x, std_x = traj_np[0].mean(), traj_np[0].std()\n",
    "    mean_y, std_y = traj_np[1].mean(), traj_np[1].std()\n",
    "    \n",
    "    ax.set_title(f't = {timestep}\\nノイズレベル: {noise_level:.3f}\\nX: μ={mean_x:.2f}, σ={std_x:.2f}\\nY: μ={mean_y:.2f}, σ={std_y:.2f}')\n",
    "    ax.set_xlabel('X 位置')\n",
    "    ax.set_ylabel('Y 位置')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "# 空のサブプロットを非表示\n",
    "for idx in range(num_steps, rows * cols):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    axes[row, col].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 複数軌道の生成と個人特性の影響分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 異なる個人特性での軌道生成\n",
    "print('異なる個人特性での軌道生成中...')\n",
    "\n",
    "# 多様な個人特性を生成\n",
    "num_conditions = 8\n",
    "varied_conditions = torch.randn(num_conditions, CONFIG['condition_dim']).to(device)\n",
    "\n",
    "# 特性を意図的に変化させる（デモ用）\n",
    "for i in range(num_conditions):\n",
    "    # 第1特性：動作時間（-2から2まで変化）\n",
    "    varied_conditions[i, 0] = -2 + 4 * i / (num_conditions - 1)\n",
    "    # 第2特性：終点誤差（-1.5から1.5まで変化）\n",
    "    varied_conditions[i, 1] = -1.5 + 3 * i / (num_conditions - 1)\n",
    "\n",
    "# 軌道生成\n",
    "with torch.no_grad():\n",
    "    generated_trajectories = generator.generate_trajectories(\n",
    "        conditions=varied_conditions,\n",
    "        seq_len=CONFIG['seq_len'],\n",
    "        method='ddim',\n",
    "        num_inference_steps=50\n",
    "    )\n",
    "\n",
    "# 生成された軌道の可視化\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(num_conditions):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    traj = generated_trajectories[i].cpu().numpy()\n",
    "    condition = varied_conditions[i].cpu().numpy()\n",
    "    \n",
    "    ax.plot(traj[0], traj[1], 'b-', linewidth=2, alpha=0.8)\n",
    "    ax.plot(traj[0, 0], traj[1, 0], 'go', markersize=10, label='Start')\n",
    "    ax.plot(traj[0, -1], traj[1, -1], 'ro', markersize=10, label='End')\n",
    "    \n",
    "    # 軌道統計\n",
    "    total_distance = np.sum(np.sqrt(np.sum(np.diff(traj, axis=1)**2, axis=0)))\n",
    "    end_error = np.sqrt(np.sum(traj[:, -1]**2))\n",
    "    \n",
    "    ax.set_title(f'条件 {i+1}\\n特性1: {condition[0]:.2f}, 特性2: {condition[1]:.2f}\\n距離: {total_distance:.2f}, 終点誤差: {end_error:.2f}')\n",
    "    ax.set_xlabel('X 位置')\n",
    "    ax.set_ylabel('Y 位置')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 軌道特徴量の抽出と分析\n",
    "def extract_trajectory_features(trajectories_tensor):\n",
    "    \"\"\"\n",
    "    軌道から特徴量を抽出\n",
    "    \"\"\"\n",
    "    trajectories = trajectories_tensor.cpu().numpy()\n",
    "    features = {}\n",
    "    \n",
    "    # 移動距離\n",
    "    distances = np.sqrt(np.sum(np.diff(trajectories, axis=2)**2, axis=1))\n",
    "    features['total_distance'] = np.sum(distances, axis=1)\n",
    "    \n",
    "    # 最大速度\n",
    "    velocities = np.sqrt(np.sum(np.diff(trajectories, axis=2)**2, axis=1))\n",
    "    features['max_velocity'] = np.max(velocities, axis=1)\n",
    "    \n",
    "    # 平均速度\n",
    "    features['mean_velocity'] = np.mean(velocities, axis=1)\n",
    "    \n",
    "    # 終点誤差（原点からの距離）\n",
    "    end_points = trajectories[:, :, -1]\n",
    "    features['end_point_error'] = np.sqrt(np.sum(end_points**2, axis=1))\n",
    "    \n",
    "    # 軌道の滑らかさ（加速度の変化）\n",
    "    accelerations = np.diff(velocities, axis=1)\n",
    "    jerks = np.diff(accelerations, axis=1)\n",
    "    features['jerk_mean'] = np.mean(np.abs(jerks), axis=1)\n",
    "    features['jerk_max'] = np.max(np.abs(jerks), axis=1)\n",
    "    \n",
    "    # 軌道の範囲\n",
    "    features['x_range'] = np.ptp(trajectories[:, 0, :], axis=1)\n",
    "    features['y_range'] = np.ptp(trajectories[:, 1, :], axis=1)\n",
    "    \n",
    "    # 軌道の曲率（方向変化）\n",
    "    dx = np.diff(trajectories[:, 0, :], axis=1)\n",
    "    dy = np.diff(trajectories[:, 1, :], axis=1)\n",
    "    angles = np.arctan2(dy, dx)\n",
    "    angle_changes = np.abs(np.diff(angles, axis=1))\n",
    "    features['curvature_mean'] = np.mean(angle_changes, axis=1)\n",
    "    features['curvature_max'] = np.max(angle_changes, axis=1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 特徴量の抽出\n",
    "trajectory_features = extract_trajectory_features(generated_trajectories)\n",
    "conditions_np = varied_conditions.cpu().numpy()\n",
    "\n",
    "# 相関分析\n",
    "feature_names = list(trajectory_features.keys())\n",
    "condition_names = [f'条件_{i+1}' for i in range(CONFIG['condition_dim'])]\n",
    "\n",
    "# データフレーム作成\n",
    "feature_df = pd.DataFrame(trajectory_features)\n",
    "condition_df = pd.DataFrame(conditions_np, columns=condition_names)\n",
    "combined_df = pd.concat([condition_df, feature_df], axis=1)\n",
    "\n",
    "# 相関行列\n",
    "correlation_matrix = combined_df.corr()\n",
    "condition_feature_corr = correlation_matrix.loc[condition_names, feature_names]\n",
    "\n",
    "# 相関ヒートマップ\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "sns.heatmap(condition_feature_corr, \n",
    "           annot=True, \n",
    "           cmap='RdBu_r', \n",
    "           center=0, \n",
    "           square=True,\n",
    "           linewidths=0.5,\n",
    "           ax=ax)\n",
    "ax.set_title('個人特性と軌道特徴の相関関係')\n",
    "ax.set_xlabel('軌道特徴')\n",
    "ax.set_ylabel('個人特性')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 統計サマリー\n",
    "print('\\n軌道特徴の統計サマリー:')\n",
    "print(feature_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. サンプリング手法の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# DDPM vs DDIM の比較\n",
    "print('異なるサンプリング手法の比較...')\n",
    "\n",
    "sample_condition = varied_conditions[:1]  # 同じ条件を使用\n",
    "\n",
    "# DDPM サンプリング（100ステップ）\n",
    "with torch.no_grad():\n",
    "    ddpm_trajectory = generator.generate_trajectories(\n",
    "        conditions=sample_condition,\n",
    "        method='ddpm',\n",
    "        num_inference_steps=100\n",
    "    )\n",
    "\n",
    "# DDIM サンプリング（異なるステップ数）\n",
    "ddim_steps = [10, 25, 50, 100]\n",
    "ddim_trajectories = []\n",
    "\n",
    "for steps in ddim_steps:\n",
    "    with torch.no_grad():\n",
    "        ddim_traj = generator.generate_trajectories(\n",
    "            conditions=sample_condition,\n",
    "            method='ddim',\n",
    "            num_inference_steps=steps\n",
    "        )\n",
    "        ddim_trajectories.append(ddim_traj)\n",
    "\n",
    "# 可視化\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "# DDPM結果\n",
    "ddpm_traj_np = ddpm_trajectory[0].cpu().numpy()\n",
    "axes[0].plot(ddpm_traj_np[0], ddmp_traj_np[1], 'b-', linewidth=2, alpha=0.8)\n",
    "axes[0].plot(ddpm_traj_np[0, 0], ddpm_traj_np[1, 0], 'go', markersize=10)\n",
    "axes[0].plot(ddpm_traj_np[0, -1], ddpm_traj_np[1, -1], 'ro', markersize=10)\n",
    "axes[0].set_title('DDPM\\n(100 steps)')\n",
    "axes[0].set_xlabel('X 位置')\n",
    "axes[0].set_ylabel('Y 位置')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# DDIM結果\n",
    "for i, (steps, ddim_traj) in enumerate(zip(ddim_steps, ddim_trajectories)):\n",
    "    ddim_traj_np = ddim_traj[0].cpu().numpy()\n",
    "    axes[i+1].plot(ddim_traj_np[0], ddim_traj_np[1], 'r-', linewidth=2, alpha=0.8)\n",
    "    axes[i+1].plot(ddim_traj_np[0, 0], ddim_traj_np[1, 0], 'go', markersize=10)\n",
    "    axes[i+1].plot(ddim_traj_np[0, -1], ddim_traj_np[1, -1], 'ro', markersize=10)\n",
    "    axes[i+1].set_title(f'DDIM\\n({steps} steps)')\n",
    "    axes[i+1].set_xlabel('X 位置')\n",
    "    axes[i+1].set_ylabel('Y 位置')\n",
    "    axes[i+1].grid(True, alpha=0.3)\n",
    "    axes[i+1].set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 軌道品質の定量比較\n",
    "methods_trajectories = [ddpm_trajectory] + ddim_trajectories\n",
    "method_names = ['DDPM (100)'] + [f'DDIM ({steps})' for steps in ddim_steps]\n",
    "\n",
    "quality_metrics = []\n",
    "for traj in methods_trajectories:\n",
    "    features = extract_trajectory_features(traj)\n",
    "    quality_metrics.append({\n",
    "        'total_distance': features['total_distance'][0],\n",
    "        'smoothness': 1.0 / (features['jerk_mean'][0] + 1e-6),  # 逆数で滑らかさを表現\n",
    "        'end_error': features['end_point_error'][0]\n",
    "    })\n",
    "\n",
    "# 品質メトリクスの可視化\n",
    "quality_df = pd.DataFrame(quality_metrics, index=method_names)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, metric in enumerate(['total_distance', 'smoothness', 'end_error']):\n",
    "    axes[i].bar(method_names, quality_df[metric], alpha=0.7)\n",
    "    axes[i].set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_ylabel('値')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nサンプリング手法の品質比較:')\n",
    "print(quality_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. まとめと今後の改善点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実験結果のまとめ\n",
    "\n",
    "このノートブックでは、個人最適化軌道生成のための拡散モデルの実装と可視化を行いました。\n",
    "\n",
    "#### 主な成果：\n",
    "1. **モデルアーキテクチャ**: UNetベースの拡散モデルを実装し、個人特性を条件として組み込みました\n",
    "2. **ノイズスケジュール**: DDPMの線形βスケジュールを分析し、適切な信号対雑音比を確認しました\n",
    "3. **訓練プロセス**: 短期デモ訓練で損失の収束を確認しました\n",
    "4. **生成プロセス**: 逆拡散プロセスの段階的可視化により、ノイズから軌道への変換を観察しました\n",
    "5. **個人特性の影響**: 異なる個人特性が生成軌道に与える影響を分析しました\n",
    "6. **サンプリング比較**: DDPMとDDIMの比較により、効率と品質のトレードオフを評価しました\n",
    "\n",
    "#### 今後の改善点：\n",
    "1. **実データの使用**: 実際の軌道測定データでの訓練\n",
    "2. **より長期の訓練**: 十分な収束までの訓練\n",
    "3. **ハイパーパラメータ調整**: 学習率、ネットワーク構造、ノイズスケジュールの最適化\n",
    "4. **評価メトリクス**: より詳細な軌道品質評価指標の導入\n",
    "5. **条件付けの改善**: より効果的な個人特性の組み込み方法\n",
    "6. **生成速度の向上**: より高速なサンプリング手法の探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# 最終的な実験設定とパラメータの保存\n",
    "experiment_summary = {\n",
    "    'model_config': CONFIG,\n",
    "    'total_parameters': total_params,\n",
    "    'training_epochs': len(train_losses),\n",
    "    'final_train_loss': train_losses[-1] if train_losses else None,\n",
    "    'final_val_loss': val_losses[-1] if val_losses else None,\n",
    "    'device': str(device),\n",
    "    'sampling_methods_tested': method_names,\n",
    "    'feature_correlations': condition_feature_corr.to_dict()\n",
    "}\n",
    "\n",
    "print('実験サマリー:')\n",
    "for key, value in experiment_summary.items():\n",
    "    if key != 'feature_correlations':  # 相関行列は長いので除外\n",
    "        print(f'  {key}: {value}')\n",
    "\n",
    "# 実験完了\n",
    "print('\\n🎉 可視化ノートブック完了!')\n",
    "print('このノートブックを参考に、実際のデータでの訓練と更なる改善を行ってください。')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}