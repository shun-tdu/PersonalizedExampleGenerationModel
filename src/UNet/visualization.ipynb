{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«è¨“ç·´å¯è¦–åŒ–ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€å€‹äººæœ€é©åŒ–è»Œé“ç”Ÿæˆã®ãŸã‚ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã¨çµæœã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚\n",
    "\n",
    "## å†…å®¹\n",
    "1. ç’°å¢ƒè¨­å®š\n",
    "2. ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¯è¦–åŒ–\n",
    "3. ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆ†æ\n",
    "4. è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–\n",
    "5. ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã®æ®µéšçš„å¯è¦–åŒ–\n",
    "6. å€‹äººç‰¹æ€§ã¨è»Œé“ã®é–¢ä¿‚åˆ†æ\n",
    "7. çµæœã®è©•ä¾¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "project_root = os.path.abspath('..')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from Model import UNet1D\n",
    "from train import DDPMScheduler, TrajectoryDataset, DiffusionTrainer, create_dummy_data\n",
    "from generate import TrajectoryGenerator, load_model\n",
    "\n",
    "# ãƒ—ãƒ­ãƒƒãƒˆè¨­å®š\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒè¨­å®šã¨åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}')\n",
    "\n",
    "# åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "CONFIG = {\n",
    "    'input_dim': 2,          # è»Œé“æ¬¡å…ƒ (x, y)\n",
    "    'condition_dim': 5,      # å€‹äººç‰¹æ€§æ¬¡å…ƒ (å‹•ä½œæ™‚é–“ã€çµ‚ç‚¹èª¤å·®ã€ã‚¸ãƒ£ãƒ¼ã‚¯ç­‰)\n",
    "    'seq_len': 101,          # è»Œé“ã®é•·ã•\n",
    "    'time_embed_dim': 128,   # æ™‚é–“åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ\n",
    "    'base_channels': 64,     # ãƒ™ãƒ¼ã‚¹ãƒãƒ£ãƒ³ãƒãƒ«æ•°\n",
    "    'num_timesteps': 1000,   # æ‹¡æ•£ã‚¹ãƒ†ãƒƒãƒ—æ•°\n",
    "    'batch_size': 32,        # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    'learning_rate': 1e-4,   # å­¦ç¿’ç‡\n",
    "}\n",
    "\n",
    "print('è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:')\n",
    "for key, value in CONFIG.items():\n",
    "    print(f'  {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ\n",
    "model = UNet1D(\n",
    "    input_dim=CONFIG['input_dim'],\n",
    "    condition_dim=CONFIG['condition_dim'],\n",
    "    time_embed_dim=CONFIG['time_embed_dim'],\n",
    "    base_channels=CONFIG['base_channels']\n",
    ").to(device)\n",
    "\n",
    "# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®è¨ˆç®—\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}')\n",
    "print(f'å­¦ç¿’å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}')\n",
    "\n",
    "# ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®åˆ†æ\n",
    "layer_info = []\n",
    "for name, module in model.named_modules():\n",
    "    if len(list(module.children())) == 0:  # æœ«ç«¯ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿\n",
    "        params = sum(p.numel() for p in module.parameters())\n",
    "        if params > 0:\n",
    "            layer_info.append({\n",
    "                'Layer': name,\n",
    "                'Parameters': params,\n",
    "                'Percentage': (params / total_params) * 100\n",
    "            })\n",
    "\n",
    "# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã®å¯è¦–åŒ–\n",
    "layer_df = pd.DataFrame(layer_info).sort_values('Parameters', ascending=False).head(10)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "ax1.barh(layer_df['Layer'][::-1], layer_df['Parameters'][::-1])\n",
    "ax1.set_xlabel('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°')\n",
    "ax1.set_title('ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ï¼ˆä¸Šä½10å±¤ï¼‰')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# å††ã‚°ãƒ©ãƒ•\n",
    "others_params = total_params - layer_df['Parameters'].sum()\n",
    "pie_data = list(layer_df['Parameters'].head(5)) + [others_params]\n",
    "pie_labels = list(layer_df['Layer'].head(5)) + ['Others']\n",
    "\n",
    "ax2.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒï¼ˆä¸Šä½5å±¤ + ãã®ä»–ï¼‰')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# DDPMã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ä½œæˆ\n",
    "scheduler = DDPMScheduler(num_timesteps=CONFIG['num_timesteps'])\n",
    "\n",
    "# ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—\n",
    "timesteps = np.arange(CONFIG['num_timesteps'])\n",
    "\n",
    "# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å–å¾—\n",
    "betas = scheduler.betas.numpy()\n",
    "alphas = scheduler.alphas.numpy()\n",
    "alphas_cumprod = scheduler.alphas_cumprod.numpy()\n",
    "sqrt_alphas_cumprod = scheduler.sqrt_alphas_cumprod.numpy()\n",
    "sqrt_one_minus_alphas_cumprod = scheduler.sqrt_one_minus_alphas_cumprod.numpy()\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Î² ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«\n",
    "axes[0, 0].plot(timesteps, betas, linewidth=2)\n",
    "axes[0, 0].set_title('Î² ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«')\n",
    "axes[0, 0].set_xlabel('ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—')\n",
    "axes[0, 0].set_ylabel('Î² å€¤')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Î± ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«\n",
    "axes[0, 1].plot(timesteps, alphas, linewidth=2)\n",
    "axes[0, 1].set_title('Î± ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«')\n",
    "axes[0, 1].set_xlabel('ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—')\n",
    "axes[0, 1].set_ylabel('Î± å€¤')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Î± ç´¯ç©ç©\n",
    "axes[0, 2].plot(timesteps, alphas_cumprod, linewidth=2)\n",
    "axes[0, 2].set_title('Î± ç´¯ç©ç©')\n",
    "axes[0, 2].set_xlabel('ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—')\n",
    "axes[0, 2].set_ylabel('Î±Ì… å€¤')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# ä¿¡å·å¼·åº¦\n",
    "axes[1, 0].plot(timesteps, sqrt_alphas_cumprod, label='ä¿¡å·å¼·åº¦', linewidth=2)\n",
    "axes[1, 0].plot(timesteps, sqrt_one_minus_alphas_cumprod, label='ãƒã‚¤ã‚ºå¼·åº¦', linewidth=2)\n",
    "axes[1, 0].set_title('ä¿¡å·ã¨ãƒã‚¤ã‚ºã®å¼·åº¦')\n",
    "axes[1, 0].set_xlabel('ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—')\n",
    "axes[1, 0].set_ylabel('å¼·åº¦')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# SNR (Signal-to-Noise Ratio)\n",
    "snr = alphas_cumprod / (1 - alphas_cumprod)\n",
    "axes[1, 1].semilogy(timesteps, snr, linewidth=2)\n",
    "axes[1, 1].set_title('ä¿¡å·å¯¾é›‘éŸ³æ¯” (SNR)')\n",
    "axes[1, 1].set_xlabel('ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—')\n",
    "axes[1, 1].set_ylabel('SNR (log scale)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®åˆ†å¸ƒ\n",
    "noise_levels = sqrt_one_minus_alphas_cumprod\n",
    "axes[1, 2].hist(noise_levels, bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 2].set_title('ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®åˆ†å¸ƒ')\n",
    "axes[1, 2].set_xlabel('ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«')\n",
    "axes[1, 2].set_ylabel('é »åº¦')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# çµ±è¨ˆæƒ…å ±\n",
    "print(f'Î² ç¯„å›²: [{betas.min():.6f}, {betas.max():.6f}]')\n",
    "print(f'æœ€çµ‚ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {sqrt_one_minus_alphas_cumprod[-1]:.6f}')\n",
    "print(f'æœ€çµ‚SNR: {snr[-1]:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ\n",
    "print('è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...')\n",
    "train_trajectories, train_conditions = create_dummy_data(\n",
    "    num_samples=1000, \n",
    "    seq_len=CONFIG['seq_len'], \n",
    "    condition_dim=CONFIG['condition_dim']\n",
    ")\n",
    "\n",
    "val_trajectories, val_conditions = create_dummy_data(\n",
    "    num_samples=200, \n",
    "    seq_len=CONFIG['seq_len'], \n",
    "    condition_dim=CONFIG['condition_dim']\n",
    ")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ\n",
    "train_dataset = TrajectoryDataset(train_trajectories, train_conditions)\n",
    "val_dataset = TrajectoryDataset(val_trajectories, val_conditions)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f'è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(train_dataset)} ã‚µãƒ³ãƒ—ãƒ«')\n",
    "print(f'ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿: {len(val_dataset)} ã‚µãƒ³ãƒ—ãƒ«')\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_trajectories, sample_conditions = sample_batch\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    traj = sample_trajectories[i].numpy()\n",
    "    condition = sample_conditions[i].numpy()\n",
    "    \n",
    "    ax.plot(traj[0], traj[1], 'b-', linewidth=2, alpha=0.8)\n",
    "    ax.plot(traj[0, 0], traj[1, 0], 'go', markersize=8, label='Start')\n",
    "    ax.plot(traj[0, -1], traj[1, -1], 'ro', markersize=8, label='End')\n",
    "    \n",
    "    ax.set_title(f'è»Œé“ {i+1}\\næ¡ä»¶: [{condition[0]:.2f}, {condition[1]:.2f}, {condition[2]:.2f}...]')\n",
    "    ax.set_xlabel('X ä½ç½®')\n",
    "    ax.set_ylabel('Y ä½ç½®')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ãƒã‚¤ã‚ºè¿½åŠ ãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ã‚µãƒ³ãƒ—ãƒ«è»Œé“ã‚’é¸æŠ\n",
    "sample_traj = sample_trajectories[0:1]  # æœ€åˆã®è»Œé“ã‚’é¸æŠ\n",
    "sample_cond = sample_conditions[0:1]\n",
    "\n",
    "# ç•°ãªã‚‹ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ãƒã‚¤ã‚ºè¿½åŠ ã‚’å¯è¦–åŒ–\n",
    "timesteps_to_show = [0, 100, 300, 500, 700, 900, 999]\n",
    "num_steps = len(timesteps_to_show)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "original_traj = sample_traj[0].numpy()\n",
    "\n",
    "for i, t in enumerate(timesteps_to_show):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "        \n",
    "    ax = axes[i]\n",
    "    \n",
    "    # ãƒã‚¤ã‚ºã‚’è¿½åŠ \n",
    "    timestep_tensor = torch.tensor([t])\n",
    "    noise = torch.randn_like(sample_traj)\n",
    "    noisy_traj = scheduler.add_noise(sample_traj, noise, timestep_tensor)\n",
    "    noisy_traj_np = noisy_traj[0].numpy()\n",
    "    \n",
    "    # å…ƒã®è»Œé“\n",
    "    ax.plot(original_traj[0], original_traj[1], 'b-', linewidth=3, alpha=0.7, label='Original')\n",
    "    \n",
    "    # ãƒã‚¤ã‚ºè¿½åŠ å¾Œã®è»Œé“\n",
    "    ax.plot(noisy_traj_np[0], noisy_traj_np[1], 'r--', linewidth=2, alpha=0.8, label=f'Noisy (t={t})')\n",
    "    \n",
    "    # é–‹å§‹ç‚¹ã¨çµ‚äº†ç‚¹\n",
    "    ax.plot(original_traj[0, 0], original_traj[1, 0], 'go', markersize=8)\n",
    "    ax.plot(original_traj[0, -1], original_traj[1, -1], 'bo', markersize=8)\n",
    "    \n",
    "    # ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã®è¡¨ç¤º\n",
    "    noise_level = sqrt_one_minus_alphas_cumprod[t]\n",
    "    signal_level = sqrt_alphas_cumprod[t]\n",
    "    \n",
    "    ax.set_title(f't = {t}\\nãƒã‚¤ã‚º: {noise_level:.3f}, ä¿¡å·: {signal_level:.3f}')\n",
    "    ax.set_xlabel('X ä½ç½®')\n",
    "    ax.set_ylabel('Y ä½ç½®')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "# ç©ºã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’éè¡¨ç¤º\n",
    "for i in range(num_steps, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«ã¨ä¿¡å·ãƒ¬ãƒ™ãƒ«ã®é–¢ä¿‚ã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "ax.plot(timesteps_to_show, [sqrt_alphas_cumprod[t] for t in timesteps_to_show], \n",
    "        'b-o', linewidth=2, markersize=8, label='ä¿¡å·ãƒ¬ãƒ™ãƒ«')\n",
    "ax.plot(timesteps_to_show, [sqrt_one_minus_alphas_cumprod[t] for t in timesteps_to_show], \n",
    "        'r-o', linewidth=2, markersize=8, label='ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«')\n",
    "\n",
    "ax.set_xlabel('ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—')\n",
    "ax.set_ylabel('ãƒ¬ãƒ™ãƒ«')\n",
    "ax.set_title('ãƒã‚¤ã‚ºè¿½åŠ ãƒ—ãƒ­ã‚»ã‚¹ã«ãŠã‘ã‚‹ä¿¡å·ã¨ãƒã‚¤ã‚ºã®ãƒ¬ãƒ™ãƒ«')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®å®Ÿè¡Œã¨å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# è¨“ç·´å™¨ã®ä½œæˆ\n",
    "trainer = DiffusionTrainer(\n",
    "    model=model, \n",
    "    scheduler=scheduler, \n",
    "    device=device, \n",
    "    learning_rate=CONFIG['learning_rate']\n",
    ")\n",
    "\n",
    "# çŸ­æœŸé–“ã®è¨“ç·´å®Ÿè¡Œï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰\n",
    "print('ãƒ‡ãƒ¢ç”¨çŸ­æœŸè¨“ç·´ã‚’é–‹å§‹...')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "num_demo_epochs = 5  # ãƒ‡ãƒ¢ç”¨ã«çŸ­ç¸®\n",
    "\n",
    "for epoch in range(num_demo_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # è¨“ç·´ãƒ«ãƒ¼ãƒ—\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_demo_epochs}', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        loss = trainer.train_step(batch)\n",
    "        epoch_loss += loss\n",
    "        progress_bar.set_postfix({'Loss': f'{loss:.4f}'})\n",
    "    \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "    val_loss = trainer.validate(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {val_loss:.4f}')\n",
    "\n",
    "print('ãƒ‡ãƒ¢è¨“ç·´å®Œäº†!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# è¨“ç·´æ›²ç·šã®å¯è¦–åŒ–\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "# æå¤±æ›²ç·š\n",
    "ax1.plot(epochs, train_losses, 'b-o', linewidth=2, markersize=6, label='è¨“ç·´æå¤±')\n",
    "ax1.plot(epochs, val_losses, 'r-o', linewidth=2, markersize=6, label='ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æå¤±')\n",
    "ax1.set_xlabel('ã‚¨ãƒãƒƒã‚¯')\n",
    "ax1.set_ylabel('æå¤±')\n",
    "ax1.set_title('è¨“ç·´æ›²ç·š')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# æå¤±ã®æ”¹å–„ç‡\n",
    "if len(train_losses) > 1:\n",
    "    train_improvement = [(train_losses[i-1] - train_losses[i]) / train_losses[i-1] * 100 \n",
    "                        for i in range(1, len(train_losses))]\n",
    "    val_improvement = [(val_losses[i-1] - val_losses[i]) / val_losses[i-1] * 100 \n",
    "                      for i in range(1, len(val_losses))]\n",
    "    \n",
    "    ax2.plot(epochs[1:], train_improvement, 'b-o', linewidth=2, markersize=6, label='è¨“ç·´æ”¹å–„ç‡')\n",
    "    ax2.plot(epochs[1:], val_improvement, 'r-o', linewidth=2, markersize=6, label='ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ”¹å–„ç‡')\n",
    "    ax2.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('ã‚¨ãƒãƒƒã‚¯')\n",
    "    ax2.set_ylabel('æ”¹å–„ç‡ (%)')\n",
    "    ax2.set_title('æå¤±æ”¹å–„ç‡')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# æœ€çµ‚çµ±è¨ˆ\n",
    "print(f'\\nè¨“ç·´çµ±è¨ˆ:')\n",
    "print(f'  æœ€çµ‚è¨“ç·´æå¤±: {train_losses[-1]:.4f}')\n",
    "print(f'  æœ€çµ‚ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æå¤±: {val_losses[-1]:.4f}')\n",
    "if len(train_losses) > 1:\n",
    "    total_train_improvement = (train_losses[0] - train_losses[-1]) / train_losses[0] * 100\n",
    "    total_val_improvement = (val_losses[0] - val_losses[-1]) / val_losses[0] * 100\n",
    "    print(f'  è¨“ç·´æå¤±æ”¹å–„: {total_train_improvement:.2f}%')\n",
    "    print(f'  ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æå¤±æ”¹å–„: {total_val_improvement:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. è»Œé“ç”Ÿæˆã¨é€†æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# è»Œé“ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®ä½œæˆ\n",
    "generator = TrajectoryGenerator(model, scheduler, device)\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«æ¡ä»¶ã‚’æº–å‚™\n",
    "sample_conditions = torch.randn(1, CONFIG['condition_dim']).to(device)\n",
    "\n",
    "# é€†æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã®æ®µéšçš„å¯è¦–åŒ–\n",
    "print('é€†æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã‚’å¯è¦–åŒ–ä¸­...')\n",
    "\n",
    "# ç‰¹å®šã®ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ä¸­é–“çµæœã‚’ä¿å­˜\n",
    "timesteps_to_visualize = [999, 800, 600, 400, 200, 100, 50, 20, 0]\n",
    "intermediate_results = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    shape = (1, 2, CONFIG['seq_len'])\n",
    "    x = torch.randn(shape, device=device)\n",
    "    \n",
    "    for t in range(scheduler.num_timesteps-1, -1, -1):\n",
    "        if t in timesteps_to_visualize:\n",
    "            intermediate_results.append((t, x.clone()))\n",
    "        \n",
    "        t_tensor = torch.full((1,), t, device=device, dtype=torch.long)\n",
    "        predicted_noise = model(x, t_tensor, sample_conditions)\n",
    "        \n",
    "        if t > 0:\n",
    "            sqrt_recip_alpha_t = generator.sqrt_recip_alphas[t]\n",
    "            beta_t = scheduler.betas[t]\n",
    "            sqrt_one_minus_alphas_cumprod_t = generator.sqrt_one_minus_alphas_cumprod[t]\n",
    "            \n",
    "            mean = sqrt_recip_alpha_t * (x - beta_t / sqrt_one_minus_alphas_cumprod_t * predicted_noise)\n",
    "            \n",
    "            alpha_t = scheduler.alphas[t]\n",
    "            alpha_cumprod_t = scheduler.alphas_cumprod[t]\n",
    "            alpha_cumprod_prev = scheduler.alphas_cumprod_prev[t]\n",
    "            \n",
    "            variance = beta_t * (1 - alpha_cumprod_prev) / (1 - alpha_cumprod_t)\n",
    "            sigma = torch.sqrt(variance)\n",
    "            noise = torch.randn_like(x)\n",
    "            \n",
    "            x = mean + sigma * noise\n",
    "        else:\n",
    "            sqrt_recip_alpha_t = generator.sqrt_recip_alphas[t]\n",
    "            beta_t = scheduler.betas[t]\n",
    "            sqrt_one_minus_alphas_cumprod_t = generator.sqrt_one_minus_alphas_cumprod[t]\n",
    "            x = sqrt_recip_alpha_t * (x - beta_t / sqrt_one_minus_alphas_cumprod_t * predicted_noise)\n",
    "\n",
    "    # æœ€çµ‚çµæœã‚‚è¿½åŠ \n",
    "    if 0 not in [result[0] for result in intermediate_results]:\n",
    "        intermediate_results.append((0, x.clone()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# é€†æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã®å¯è¦–åŒ–\n",
    "num_steps = len(intermediate_results)\n",
    "cols = 3\n",
    "rows = (num_steps + cols - 1) // cols\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "if rows == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "\n",
    "for idx, (timestep, trajectory) in enumerate(intermediate_results):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    traj_np = trajectory[0].cpu().numpy()\n",
    "    \n",
    "    # è»Œé“ã‚’ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "    ax.plot(traj_np[0], traj_np[1], 'b-', linewidth=2, alpha=0.8)\n",
    "    ax.plot(traj_np[0, 0], traj_np[1, 0], 'go', markersize=10, label='Start')\n",
    "    ax.plot(traj_np[0, -1], traj_np[1, -1], 'ro', markersize=10, label='End')\n",
    "    \n",
    "    # ã‚¿ã‚¤ãƒˆãƒ«ã¨çµ±è¨ˆæƒ…å ±\n",
    "    noise_level = sqrt_one_minus_alphas_cumprod[timestep] if timestep < len(sqrt_one_minus_alphas_cumprod) else 0\n",
    "    mean_x, std_x = traj_np[0].mean(), traj_np[0].std()\n",
    "    mean_y, std_y = traj_np[1].mean(), traj_np[1].std()\n",
    "    \n",
    "    ax.set_title(f't = {timestep}\\nãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«: {noise_level:.3f}\\nX: Î¼={mean_x:.2f}, Ïƒ={std_x:.2f}\\nY: Î¼={mean_y:.2f}, Ïƒ={std_y:.2f}')\n",
    "    ax.set_xlabel('X ä½ç½®')\n",
    "    ax.set_ylabel('Y ä½ç½®')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "# ç©ºã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’éè¡¨ç¤º\n",
    "for idx in range(num_steps, rows * cols):\n",
    "    row = idx // cols\n",
    "    col = idx % cols\n",
    "    axes[row, col].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. è¤‡æ•°è»Œé“ã®ç”Ÿæˆã¨å€‹äººç‰¹æ€§ã®å½±éŸ¿åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# ç•°ãªã‚‹å€‹äººç‰¹æ€§ã§ã®è»Œé“ç”Ÿæˆ\n",
    "print('ç•°ãªã‚‹å€‹äººç‰¹æ€§ã§ã®è»Œé“ç”Ÿæˆä¸­...')\n",
    "\n",
    "# å¤šæ§˜ãªå€‹äººç‰¹æ€§ã‚’ç”Ÿæˆ\n",
    "num_conditions = 8\n",
    "varied_conditions = torch.randn(num_conditions, CONFIG['condition_dim']).to(device)\n",
    "\n",
    "# ç‰¹æ€§ã‚’æ„å›³çš„ã«å¤‰åŒ–ã•ã›ã‚‹ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰\n",
    "for i in range(num_conditions):\n",
    "    # ç¬¬1ç‰¹æ€§ï¼šå‹•ä½œæ™‚é–“ï¼ˆ-2ã‹ã‚‰2ã¾ã§å¤‰åŒ–ï¼‰\n",
    "    varied_conditions[i, 0] = -2 + 4 * i / (num_conditions - 1)\n",
    "    # ç¬¬2ç‰¹æ€§ï¼šçµ‚ç‚¹èª¤å·®ï¼ˆ-1.5ã‹ã‚‰1.5ã¾ã§å¤‰åŒ–ï¼‰\n",
    "    varied_conditions[i, 1] = -1.5 + 3 * i / (num_conditions - 1)\n",
    "\n",
    "# è»Œé“ç”Ÿæˆ\n",
    "with torch.no_grad():\n",
    "    generated_trajectories = generator.generate_trajectories(\n",
    "        conditions=varied_conditions,\n",
    "        seq_len=CONFIG['seq_len'],\n",
    "        method='ddim',\n",
    "        num_inference_steps=50\n",
    "    )\n",
    "\n",
    "# ç”Ÿæˆã•ã‚ŒãŸè»Œé“ã®å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(num_conditions):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    traj = generated_trajectories[i].cpu().numpy()\n",
    "    condition = varied_conditions[i].cpu().numpy()\n",
    "    \n",
    "    ax.plot(traj[0], traj[1], 'b-', linewidth=2, alpha=0.8)\n",
    "    ax.plot(traj[0, 0], traj[1, 0], 'go', markersize=10, label='Start')\n",
    "    ax.plot(traj[0, -1], traj[1, -1], 'ro', markersize=10, label='End')\n",
    "    \n",
    "    # è»Œé“çµ±è¨ˆ\n",
    "    total_distance = np.sum(np.sqrt(np.sum(np.diff(traj, axis=1)**2, axis=0)))\n",
    "    end_error = np.sqrt(np.sum(traj[:, -1]**2))\n",
    "    \n",
    "    ax.set_title(f'æ¡ä»¶ {i+1}\\nç‰¹æ€§1: {condition[0]:.2f}, ç‰¹æ€§2: {condition[1]:.2f}\\nè·é›¢: {total_distance:.2f}, çµ‚ç‚¹èª¤å·®: {end_error:.2f}')\n",
    "    ax.set_xlabel('X ä½ç½®')\n",
    "    ax.set_ylabel('Y ä½ç½®')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# è»Œé“ç‰¹å¾´é‡ã®æŠ½å‡ºã¨åˆ†æ\n",
    "def extract_trajectory_features(trajectories_tensor):\n",
    "    \"\"\"\n",
    "    è»Œé“ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º\n",
    "    \"\"\"\n",
    "    trajectories = trajectories_tensor.cpu().numpy()\n",
    "    features = {}\n",
    "    \n",
    "    # ç§»å‹•è·é›¢\n",
    "    distances = np.sqrt(np.sum(np.diff(trajectories, axis=2)**2, axis=1))\n",
    "    features['total_distance'] = np.sum(distances, axis=1)\n",
    "    \n",
    "    # æœ€å¤§é€Ÿåº¦\n",
    "    velocities = np.sqrt(np.sum(np.diff(trajectories, axis=2)**2, axis=1))\n",
    "    features['max_velocity'] = np.max(velocities, axis=1)\n",
    "    \n",
    "    # å¹³å‡é€Ÿåº¦\n",
    "    features['mean_velocity'] = np.mean(velocities, axis=1)\n",
    "    \n",
    "    # çµ‚ç‚¹èª¤å·®ï¼ˆåŸç‚¹ã‹ã‚‰ã®è·é›¢ï¼‰\n",
    "    end_points = trajectories[:, :, -1]\n",
    "    features['end_point_error'] = np.sqrt(np.sum(end_points**2, axis=1))\n",
    "    \n",
    "    # è»Œé“ã®æ»‘ã‚‰ã‹ã•ï¼ˆåŠ é€Ÿåº¦ã®å¤‰åŒ–ï¼‰\n",
    "    accelerations = np.diff(velocities, axis=1)\n",
    "    jerks = np.diff(accelerations, axis=1)\n",
    "    features['jerk_mean'] = np.mean(np.abs(jerks), axis=1)\n",
    "    features['jerk_max'] = np.max(np.abs(jerks), axis=1)\n",
    "    \n",
    "    # è»Œé“ã®ç¯„å›²\n",
    "    features['x_range'] = np.ptp(trajectories[:, 0, :], axis=1)\n",
    "    features['y_range'] = np.ptp(trajectories[:, 1, :], axis=1)\n",
    "    \n",
    "    # è»Œé“ã®æ›²ç‡ï¼ˆæ–¹å‘å¤‰åŒ–ï¼‰\n",
    "    dx = np.diff(trajectories[:, 0, :], axis=1)\n",
    "    dy = np.diff(trajectories[:, 1, :], axis=1)\n",
    "    angles = np.arctan2(dy, dx)\n",
    "    angle_changes = np.abs(np.diff(angles, axis=1))\n",
    "    features['curvature_mean'] = np.mean(angle_changes, axis=1)\n",
    "    features['curvature_max'] = np.max(angle_changes, axis=1)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# ç‰¹å¾´é‡ã®æŠ½å‡º\n",
    "trajectory_features = extract_trajectory_features(generated_trajectories)\n",
    "conditions_np = varied_conditions.cpu().numpy()\n",
    "\n",
    "# ç›¸é–¢åˆ†æ\n",
    "feature_names = list(trajectory_features.keys())\n",
    "condition_names = [f'æ¡ä»¶_{i+1}' for i in range(CONFIG['condition_dim'])]\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ\n",
    "feature_df = pd.DataFrame(trajectory_features)\n",
    "condition_df = pd.DataFrame(conditions_np, columns=condition_names)\n",
    "combined_df = pd.concat([condition_df, feature_df], axis=1)\n",
    "\n",
    "# ç›¸é–¢è¡Œåˆ—\n",
    "correlation_matrix = combined_df.corr()\n",
    "condition_feature_corr = correlation_matrix.loc[condition_names, feature_names]\n",
    "\n",
    "# ç›¸é–¢ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "sns.heatmap(condition_feature_corr, \n",
    "           annot=True, \n",
    "           cmap='RdBu_r', \n",
    "           center=0, \n",
    "           square=True,\n",
    "           linewidths=0.5,\n",
    "           ax=ax)\n",
    "ax.set_title('å€‹äººç‰¹æ€§ã¨è»Œé“ç‰¹å¾´ã®ç›¸é–¢é–¢ä¿‚')\n",
    "ax.set_xlabel('è»Œé“ç‰¹å¾´')\n",
    "ax.set_ylabel('å€‹äººç‰¹æ€§')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# çµ±è¨ˆã‚µãƒãƒªãƒ¼\n",
    "print('\\nè»Œé“ç‰¹å¾´ã®çµ±è¨ˆã‚µãƒãƒªãƒ¼:')\n",
    "print(feature_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# DDPM vs DDIM ã®æ¯”è¼ƒ\n",
    "print('ç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¯”è¼ƒ...')\n",
    "\n",
    "sample_condition = varied_conditions[:1]  # åŒã˜æ¡ä»¶ã‚’ä½¿ç”¨\n",
    "\n",
    "# DDPM ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ100ã‚¹ãƒ†ãƒƒãƒ—ï¼‰\n",
    "with torch.no_grad():\n",
    "    ddpm_trajectory = generator.generate_trajectories(\n",
    "        conditions=sample_condition,\n",
    "        method='ddpm',\n",
    "        num_inference_steps=100\n",
    "    )\n",
    "\n",
    "# DDIM ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç•°ãªã‚‹ã‚¹ãƒ†ãƒƒãƒ—æ•°ï¼‰\n",
    "ddim_steps = [10, 25, 50, 100]\n",
    "ddim_trajectories = []\n",
    "\n",
    "for steps in ddim_steps:\n",
    "    with torch.no_grad():\n",
    "        ddim_traj = generator.generate_trajectories(\n",
    "            conditions=sample_condition,\n",
    "            method='ddim',\n",
    "            num_inference_steps=steps\n",
    "        )\n",
    "        ddim_trajectories.append(ddim_traj)\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "\n",
    "# DDPMçµæœ\n",
    "ddpm_traj_np = ddpm_trajectory[0].cpu().numpy()\n",
    "axes[0].plot(ddpm_traj_np[0], ddmp_traj_np[1], 'b-', linewidth=2, alpha=0.8)\n",
    "axes[0].plot(ddpm_traj_np[0, 0], ddpm_traj_np[1, 0], 'go', markersize=10)\n",
    "axes[0].plot(ddpm_traj_np[0, -1], ddpm_traj_np[1, -1], 'ro', markersize=10)\n",
    "axes[0].set_title('DDPM\\n(100 steps)')\n",
    "axes[0].set_xlabel('X ä½ç½®')\n",
    "axes[0].set_ylabel('Y ä½ç½®')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_aspect('equal')\n",
    "\n",
    "# DDIMçµæœ\n",
    "for i, (steps, ddim_traj) in enumerate(zip(ddim_steps, ddim_trajectories)):\n",
    "    ddim_traj_np = ddim_traj[0].cpu().numpy()\n",
    "    axes[i+1].plot(ddim_traj_np[0], ddim_traj_np[1], 'r-', linewidth=2, alpha=0.8)\n",
    "    axes[i+1].plot(ddim_traj_np[0, 0], ddim_traj_np[1, 0], 'go', markersize=10)\n",
    "    axes[i+1].plot(ddim_traj_np[0, -1], ddim_traj_np[1, -1], 'ro', markersize=10)\n",
    "    axes[i+1].set_title(f'DDIM\\n({steps} steps)')\n",
    "    axes[i+1].set_xlabel('X ä½ç½®')\n",
    "    axes[i+1].set_ylabel('Y ä½ç½®')\n",
    "    axes[i+1].grid(True, alpha=0.3)\n",
    "    axes[i+1].set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# è»Œé“å“è³ªã®å®šé‡æ¯”è¼ƒ\n",
    "methods_trajectories = [ddpm_trajectory] + ddim_trajectories\n",
    "method_names = ['DDPM (100)'] + [f'DDIM ({steps})' for steps in ddim_steps]\n",
    "\n",
    "quality_metrics = []\n",
    "for traj in methods_trajectories:\n",
    "    features = extract_trajectory_features(traj)\n",
    "    quality_metrics.append({\n",
    "        'total_distance': features['total_distance'][0],\n",
    "        'smoothness': 1.0 / (features['jerk_mean'][0] + 1e-6),  # é€†æ•°ã§æ»‘ã‚‰ã‹ã•ã‚’è¡¨ç¾\n",
    "        'end_error': features['end_point_error'][0]\n",
    "    })\n",
    "\n",
    "# å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®å¯è¦–åŒ–\n",
    "quality_df = pd.DataFrame(quality_metrics, index=method_names)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for i, metric in enumerate(['total_distance', 'smoothness', 'end_error']):\n",
    "    axes[i].bar(method_names, quality_df[metric], alpha=0.7)\n",
    "    axes[i].set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_ylabel('å€¤')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã®å“è³ªæ¯”è¼ƒ:')\n",
    "print(quality_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ã¾ã¨ã‚ã¨ä»Šå¾Œã®æ”¹å–„ç‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®Ÿé¨“çµæœã®ã¾ã¨ã‚\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€å€‹äººæœ€é©åŒ–è»Œé“ç”Ÿæˆã®ãŸã‚ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã¨å¯è¦–åŒ–ã‚’è¡Œã„ã¾ã—ãŸã€‚\n",
    "\n",
    "#### ä¸»ãªæˆæœï¼š\n",
    "1. **ãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: UNetãƒ™ãƒ¼ã‚¹ã®æ‹¡æ•£ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè£…ã—ã€å€‹äººç‰¹æ€§ã‚’æ¡ä»¶ã¨ã—ã¦çµ„ã¿è¾¼ã¿ã¾ã—ãŸ\n",
    "2. **ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«**: DDPMã®ç·šå½¢Î²ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆ†æã—ã€é©åˆ‡ãªä¿¡å·å¯¾é›‘éŸ³æ¯”ã‚’ç¢ºèªã—ã¾ã—ãŸ\n",
    "3. **è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹**: çŸ­æœŸãƒ‡ãƒ¢è¨“ç·´ã§æå¤±ã®åæŸã‚’ç¢ºèªã—ã¾ã—ãŸ\n",
    "4. **ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹**: é€†æ‹¡æ•£ãƒ—ãƒ­ã‚»ã‚¹ã®æ®µéšçš„å¯è¦–åŒ–ã«ã‚ˆã‚Šã€ãƒã‚¤ã‚ºã‹ã‚‰è»Œé“ã¸ã®å¤‰æ›ã‚’è¦³å¯Ÿã—ã¾ã—ãŸ\n",
    "5. **å€‹äººç‰¹æ€§ã®å½±éŸ¿**: ç•°ãªã‚‹å€‹äººç‰¹æ€§ãŒç”Ÿæˆè»Œé“ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æã—ã¾ã—ãŸ\n",
    "6. **ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¯”è¼ƒ**: DDPMã¨DDIMã®æ¯”è¼ƒã«ã‚ˆã‚Šã€åŠ¹ç‡ã¨å“è³ªã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’è©•ä¾¡ã—ã¾ã—ãŸ\n",
    "\n",
    "#### ä»Šå¾Œã®æ”¹å–„ç‚¹ï¼š\n",
    "1. **å®Ÿãƒ‡ãƒ¼ã‚¿ã®ä½¿ç”¨**: å®Ÿéš›ã®è»Œé“æ¸¬å®šãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´\n",
    "2. **ã‚ˆã‚Šé•·æœŸã®è¨“ç·´**: ååˆ†ãªåæŸã¾ã§ã®è¨“ç·´\n",
    "3. **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´**: å­¦ç¿’ç‡ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã€ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æœ€é©åŒ–\n",
    "4. **è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹**: ã‚ˆã‚Šè©³ç´°ãªè»Œé“å“è³ªè©•ä¾¡æŒ‡æ¨™ã®å°å…¥\n",
    "5. **æ¡ä»¶ä»˜ã‘ã®æ”¹å–„**: ã‚ˆã‚ŠåŠ¹æœçš„ãªå€‹äººç‰¹æ€§ã®çµ„ã¿è¾¼ã¿æ–¹æ³•\n",
    "6. **ç”Ÿæˆé€Ÿåº¦ã®å‘ä¸Š**: ã‚ˆã‚Šé«˜é€Ÿãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ‰‹æ³•ã®æ¢ç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAUDE_ADDED\n",
    "# æœ€çµ‚çš„ãªå®Ÿé¨“è¨­å®šã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ä¿å­˜\n",
    "experiment_summary = {\n",
    "    'model_config': CONFIG,\n",
    "    'total_parameters': total_params,\n",
    "    'training_epochs': len(train_losses),\n",
    "    'final_train_loss': train_losses[-1] if train_losses else None,\n",
    "    'final_val_loss': val_losses[-1] if val_losses else None,\n",
    "    'device': str(device),\n",
    "    'sampling_methods_tested': method_names,\n",
    "    'feature_correlations': condition_feature_corr.to_dict()\n",
    "}\n",
    "\n",
    "print('å®Ÿé¨“ã‚µãƒãƒªãƒ¼:')\n",
    "for key, value in experiment_summary.items():\n",
    "    if key != 'feature_correlations':  # ç›¸é–¢è¡Œåˆ—ã¯é•·ã„ã®ã§é™¤å¤–\n",
    "        print(f'  {key}: {value}')\n",
    "\n",
    "# å®Ÿé¨“å®Œäº†\n",
    "print('\\nğŸ‰ å¯è¦–åŒ–ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Œäº†!')\n",
    "print('ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å‚è€ƒã«ã€å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´ã¨æ›´ãªã‚‹æ”¹å–„ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}